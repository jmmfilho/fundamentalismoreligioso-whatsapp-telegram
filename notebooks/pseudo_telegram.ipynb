{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tomotopy as tp\n",
        "from gensim import corpora\n",
        "from gensim.models import CoherenceModel\n",
        "from tqdm import tqdm\n",
        "\n",
        "#plot\n",
        "import matplotlib\n",
        "matplotlib.use(\"TkAgg\")  # Define o backend ANTES de importar pyplot\n",
        "\n",
        "import matplotlib.pyplot as plt  # Só importar depois de definir o backend\n",
        "\n",
        "from nltk import tokenize\n",
        "import pandas as pd\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "from unidecode import unidecode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('../datasets/fakeTelegram.BR_2022.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "557586"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date_message</th>\n",
              "      <th>id_member_anonymous</th>\n",
              "      <th>id_group_anonymous</th>\n",
              "      <th>media</th>\n",
              "      <th>media_type</th>\n",
              "      <th>media_url</th>\n",
              "      <th>has_media</th>\n",
              "      <th>has_media_url</th>\n",
              "      <th>trava_zap</th>\n",
              "      <th>text_content_anonymous</th>\n",
              "      <th>dataset_info_id</th>\n",
              "      <th>date_system</th>\n",
              "      <th>score_sentiment</th>\n",
              "      <th>score_misinformation</th>\n",
              "      <th>id_message</th>\n",
              "      <th>id_persona</th>\n",
              "      <th>message_type</th>\n",
              "      <th>messenger</th>\n",
              "      <th>media_name</th>\n",
              "      <th>media_md5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-10-05 06:25:04</td>\n",
              "      <td>1078cc958f0febe28f4d03207660715f</td>\n",
              "      <td>12283e08a2eb5789201e105b34489ee7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Então é Fato Renato o áudio que eu ouvi no wha...</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-10-05 06:25:28.863641</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16385</td>\n",
              "      <td>Wanda Silva</td>\n",
              "      <td>Texto</td>\n",
              "      <td>telegram</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-10-05 06:25:08</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12283e08a2eb5789201e105b34489ee7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Saiu no YouTube do presidente a 8 horas atrás,...</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-10-05 06:25:28.926311</td>\n",
              "      <td>0.0644</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16386</td>\n",
              "      <td>Wanda Silva</td>\n",
              "      <td>Texto</td>\n",
              "      <td>telegram</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-10-05 06:26:28</td>\n",
              "      <td>92a2d8fd7144074f659d1d29dc3751da</td>\n",
              "      <td>9f2d7394334eb224c061c9740b5748fc</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>É isso, nossa parte já foi quase toda feita. N...</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-10-05 06:26:29.361949</td>\n",
              "      <td>-0.3551</td>\n",
              "      <td>0.157242</td>\n",
              "      <td>16366</td>\n",
              "      <td>Wanda Silva</td>\n",
              "      <td>Texto</td>\n",
              "      <td>telegram</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-10-05 06:27:28</td>\n",
              "      <td>d60aa38f62b4977426b70944af4aff72</td>\n",
              "      <td>c8f2de56550ed0bf85249608b7ead93d</td>\n",
              "      <td>94dca4cda503100ebfda7ce2bcc060eb.jpg</td>\n",
              "      <td>image/jpg</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>GENTE ACHEI ELES EM UMA SEITA MAÇONÁRICA</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-10-05 06:27:29.935624</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19281</td>\n",
              "      <td>Wanda Silva</td>\n",
              "      <td>Imagem</td>\n",
              "      <td>telegram</td>\n",
              "      <td>NaN</td>\n",
              "      <td>94dca4cda503100ebfda7ce2bcc060eb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-10-05 06:27:44</td>\n",
              "      <td>cd6979b0b5265f08468fa1689b6300ce</td>\n",
              "      <td>e56ec342fc599ebb4ed89655eb6f03aa</td>\n",
              "      <td>5ad5c8bbe9da93a37fecf3e5aa5b0637.jpg</td>\n",
              "      <td>image/jpg</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-10-05 06:28:29.316325</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>507185</td>\n",
              "      <td>Wanda Silva</td>\n",
              "      <td>Imagem</td>\n",
              "      <td>telegram</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5ad5c8bbe9da93a37fecf3e5aa5b0637</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          date_message               id_member_anonymous  \\\n",
              "0  2022-10-05 06:25:04  1078cc958f0febe28f4d03207660715f   \n",
              "1  2022-10-05 06:25:08                               NaN   \n",
              "2  2022-10-05 06:26:28  92a2d8fd7144074f659d1d29dc3751da   \n",
              "3  2022-10-05 06:27:28  d60aa38f62b4977426b70944af4aff72   \n",
              "4  2022-10-05 06:27:44  cd6979b0b5265f08468fa1689b6300ce   \n",
              "\n",
              "                 id_group_anonymous                                 media  \\\n",
              "0  12283e08a2eb5789201e105b34489ee7                                   NaN   \n",
              "1  12283e08a2eb5789201e105b34489ee7                                   NaN   \n",
              "2  9f2d7394334eb224c061c9740b5748fc                                   NaN   \n",
              "3  c8f2de56550ed0bf85249608b7ead93d  94dca4cda503100ebfda7ce2bcc060eb.jpg   \n",
              "4  e56ec342fc599ebb4ed89655eb6f03aa  5ad5c8bbe9da93a37fecf3e5aa5b0637.jpg   \n",
              "\n",
              "  media_type media_url  has_media  has_media_url  trava_zap  \\\n",
              "0        NaN       NaN      False          False      False   \n",
              "1        NaN       NaN      False          False      False   \n",
              "2        NaN       NaN      False          False      False   \n",
              "3  image/jpg       NaN       True          False      False   \n",
              "4  image/jpg       NaN       True          False      False   \n",
              "\n",
              "                              text_content_anonymous  dataset_info_id  \\\n",
              "0  Então é Fato Renato o áudio que eu ouvi no wha...                5   \n",
              "1  Saiu no YouTube do presidente a 8 horas atrás,...                5   \n",
              "2  É isso, nossa parte já foi quase toda feita. N...                5   \n",
              "3           GENTE ACHEI ELES EM UMA SEITA MAÇONÁRICA                5   \n",
              "4                                                NaN                5   \n",
              "\n",
              "                  date_system  score_sentiment  score_misinformation  \\\n",
              "0  2022-10-05 06:25:28.863641           0.0000                   NaN   \n",
              "1  2022-10-05 06:25:28.926311           0.0644                   NaN   \n",
              "2  2022-10-05 06:26:29.361949          -0.3551              0.157242   \n",
              "3  2022-10-05 06:27:29.935624           0.0000                   NaN   \n",
              "4  2022-10-05 06:28:29.316325              NaN                   NaN   \n",
              "\n",
              "   id_message   id_persona message_type messenger media_name  \\\n",
              "0       16385  Wanda Silva        Texto  telegram        NaN   \n",
              "1       16386  Wanda Silva        Texto  telegram        NaN   \n",
              "2       16366  Wanda Silva        Texto  telegram        NaN   \n",
              "3       19281  Wanda Silva       Imagem  telegram        NaN   \n",
              "4      507185  Wanda Silva       Imagem  telegram        NaN   \n",
              "\n",
              "                          media_md5  \n",
              "0                               NaN  \n",
              "1                               NaN  \n",
              "2                               NaN  \n",
              "3  94dca4cda503100ebfda7ce2bcc060eb  \n",
              "4  5ad5c8bbe9da93a37fecf3e5aa5b0637  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "ids_para_remover = ['b73c0b674b28d87375d78dcae2f1a21f','62b3aa83e4df122e48cb1f97583e403f',\n",
        "                    '893874da7344daaa00b8b5b3dc295b59','38737f3c7a07586c4efbfa39aa345705',\n",
        "                    'da4cbbc1b7b1192ad83bcdae613ac2c3', 'bf66a467459264e0d33e4c8518a82827',\n",
        "                    '46e009035e6150d656d0c194db88fb07','811541f6ce49347d1798e8dd2d3cbf83',\n",
        "                    '1d2a0a63333d12ad188e9e6f7f2e0419','7c379613d4da713fe959d8c7ddc11ce2',\n",
        "                    'debe17fd10d504076d2df8682f63bfc6','e9713ae04a02a810d6f33dd956f42794',\n",
        "                    'd6c77928db26721ce46aca2d549780f0','8e53464d3b01eea3e39d07e51ecbb1b4',\n",
        "                    'bacd40da04dd7d13f646993bdcf8e79d','2273d1167a6212812d95dc8fadbae78e',\n",
        "                    'cd3bb1bdf75be7595e6373171a5c2225','add8c1ba533c5e5450d92c061a5ee7bf',\n",
        "                    'e198f90df1995528531dd43db0c935ea', '06dc9ac55ed64caab2bd97e9ab717302',\n",
        "                    'c0110feb539d212836605b66192722dd','f71912700ac5331415408ce229681359',\n",
        "                    '2ee692357a9c948351c43a9540e859ae', '25b66278176dabe814dfc25a405a2470',\n",
        "                    '08b21cb1e7de74ef5fe1085230075523']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date_message</th>\n",
              "      <th>id_member_anonymous</th>\n",
              "      <th>id_group_anonymous</th>\n",
              "      <th>media</th>\n",
              "      <th>media_type</th>\n",
              "      <th>media_url</th>\n",
              "      <th>has_media</th>\n",
              "      <th>has_media_url</th>\n",
              "      <th>trava_zap</th>\n",
              "      <th>text_content_anonymous</th>\n",
              "      <th>dataset_info_id</th>\n",
              "      <th>date_system</th>\n",
              "      <th>score_sentiment</th>\n",
              "      <th>score_misinformation</th>\n",
              "      <th>id_message</th>\n",
              "      <th>id_persona</th>\n",
              "      <th>message_type</th>\n",
              "      <th>messenger</th>\n",
              "      <th>media_name</th>\n",
              "      <th>media_md5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-10-05 06:25:04</td>\n",
              "      <td>1078cc958f0febe28f4d03207660715f</td>\n",
              "      <td>12283e08a2eb5789201e105b34489ee7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Então é Fato Renato o áudio que eu ouvi no wha...</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-10-05 06:25:28.863641</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16385</td>\n",
              "      <td>Wanda Silva</td>\n",
              "      <td>Texto</td>\n",
              "      <td>telegram</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-10-05 06:25:08</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12283e08a2eb5789201e105b34489ee7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Saiu no YouTube do presidente a 8 horas atrás,...</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-10-05 06:25:28.926311</td>\n",
              "      <td>0.0644</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16386</td>\n",
              "      <td>Wanda Silva</td>\n",
              "      <td>Texto</td>\n",
              "      <td>telegram</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-10-05 06:26:28</td>\n",
              "      <td>92a2d8fd7144074f659d1d29dc3751da</td>\n",
              "      <td>9f2d7394334eb224c061c9740b5748fc</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>É isso, nossa parte já foi quase toda feita. N...</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-10-05 06:26:29.361949</td>\n",
              "      <td>-0.3551</td>\n",
              "      <td>0.157242</td>\n",
              "      <td>16366</td>\n",
              "      <td>Wanda Silva</td>\n",
              "      <td>Texto</td>\n",
              "      <td>telegram</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-10-05 06:27:28</td>\n",
              "      <td>d60aa38f62b4977426b70944af4aff72</td>\n",
              "      <td>c8f2de56550ed0bf85249608b7ead93d</td>\n",
              "      <td>94dca4cda503100ebfda7ce2bcc060eb.jpg</td>\n",
              "      <td>image/jpg</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>GENTE ACHEI ELES EM UMA SEITA MAÇONÁRICA</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-10-05 06:27:29.935624</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19281</td>\n",
              "      <td>Wanda Silva</td>\n",
              "      <td>Imagem</td>\n",
              "      <td>telegram</td>\n",
              "      <td>NaN</td>\n",
              "      <td>94dca4cda503100ebfda7ce2bcc060eb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-10-05 06:27:44</td>\n",
              "      <td>cd6979b0b5265f08468fa1689b6300ce</td>\n",
              "      <td>e56ec342fc599ebb4ed89655eb6f03aa</td>\n",
              "      <td>5ad5c8bbe9da93a37fecf3e5aa5b0637.jpg</td>\n",
              "      <td>image/jpg</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-10-05 06:28:29.316325</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>507185</td>\n",
              "      <td>Wanda Silva</td>\n",
              "      <td>Imagem</td>\n",
              "      <td>telegram</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5ad5c8bbe9da93a37fecf3e5aa5b0637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557581</th>\n",
              "      <td>2022-11-11 12:06:15</td>\n",
              "      <td>333e9869f23dbd4682d1be382d9c1e59</td>\n",
              "      <td>e56ec342fc599ebb4ed89655eb6f03aa</td>\n",
              "      <td>25e43b6a58b848c43ad5b5f9e979822a.jpg</td>\n",
              "      <td>url</td>\n",
              "      <td>https://terrabrasilnoticias.com/2022/11/bndes-...</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>BNDES tem lucro de R$ 9,6 bilhões no terceiro ...</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-11-16 14:49:39.146502</td>\n",
              "      <td>0.1027</td>\n",
              "      <td>NaN</td>\n",
              "      <td>575796</td>\n",
              "      <td>Wanda Silva</td>\n",
              "      <td>Url</td>\n",
              "      <td>telegram</td>\n",
              "      <td>NaN</td>\n",
              "      <td>25e43b6a58b848c43ad5b5f9e979822a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557582</th>\n",
              "      <td>2022-11-11 12:09:08</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5b10d7739171149be6d9961e3350c071</td>\n",
              "      <td>657949d03e4088f6b332e2686ccd3221.jpg</td>\n",
              "      <td>url</td>\n",
              "      <td>https://youtu.be/8g1Vz9_0xVk</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>https://youtu.be/8g1Vz9_0xVk</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-11-16 14:49:39.847434</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1286443</td>\n",
              "      <td>Wanda Silva</td>\n",
              "      <td>Url</td>\n",
              "      <td>telegram</td>\n",
              "      <td>NaN</td>\n",
              "      <td>657949d03e4088f6b332e2686ccd3221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557583</th>\n",
              "      <td>2022-11-11 12:09:47</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1590a03f43b5ba4b6147a1c5e1dd357b</td>\n",
              "      <td>a21848a61045380a6483866daed0ca0e.jpg</td>\n",
              "      <td>image/jpg</td>\n",
              "      <td>https://t.me/vemprasruas</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>Empresários, demitam os petistas primeiro.\\n\\n...</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-11-16 14:49:39.922279</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13294</td>\n",
              "      <td>Wanda Silva</td>\n",
              "      <td>Imagem</td>\n",
              "      <td>telegram</td>\n",
              "      <td>NaN</td>\n",
              "      <td>a21848a61045380a6483866daed0ca0e</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557584</th>\n",
              "      <td>2022-11-11 12:09:46</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5b10d7739171149be6d9961e3350c071</td>\n",
              "      <td>a21848a61045380a6483866daed0ca0e.jpg</td>\n",
              "      <td>image/jpg</td>\n",
              "      <td>https://t.me/vemprasruas</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>Empresários, demitam os petistas primeiro.\\n\\n...</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-11-16 14:49:39.992932</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1286444</td>\n",
              "      <td>Wanda Silva</td>\n",
              "      <td>Imagem</td>\n",
              "      <td>telegram</td>\n",
              "      <td>NaN</td>\n",
              "      <td>a21848a61045380a6483866daed0ca0e</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557585</th>\n",
              "      <td>2022-11-11 12:09:48</td>\n",
              "      <td>NaN</td>\n",
              "      <td>b11f2df64ac19aad47a50accf32052d6</td>\n",
              "      <td>a21848a61045380a6483866daed0ca0e.jpg</td>\n",
              "      <td>image/jpg</td>\n",
              "      <td>https://t.me/vemprasruas</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>Empresários, demitam os petistas primeiro.\\n\\n...</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-11-16 14:49:40.064006</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>192127</td>\n",
              "      <td>Wanda Silva</td>\n",
              "      <td>Imagem</td>\n",
              "      <td>telegram</td>\n",
              "      <td>NaN</td>\n",
              "      <td>a21848a61045380a6483866daed0ca0e</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>556968 rows × 20 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               date_message               id_member_anonymous  \\\n",
              "0       2022-10-05 06:25:04  1078cc958f0febe28f4d03207660715f   \n",
              "1       2022-10-05 06:25:08                               NaN   \n",
              "2       2022-10-05 06:26:28  92a2d8fd7144074f659d1d29dc3751da   \n",
              "3       2022-10-05 06:27:28  d60aa38f62b4977426b70944af4aff72   \n",
              "4       2022-10-05 06:27:44  cd6979b0b5265f08468fa1689b6300ce   \n",
              "...                     ...                               ...   \n",
              "557581  2022-11-11 12:06:15  333e9869f23dbd4682d1be382d9c1e59   \n",
              "557582  2022-11-11 12:09:08                               NaN   \n",
              "557583  2022-11-11 12:09:47                               NaN   \n",
              "557584  2022-11-11 12:09:46                               NaN   \n",
              "557585  2022-11-11 12:09:48                               NaN   \n",
              "\n",
              "                      id_group_anonymous  \\\n",
              "0       12283e08a2eb5789201e105b34489ee7   \n",
              "1       12283e08a2eb5789201e105b34489ee7   \n",
              "2       9f2d7394334eb224c061c9740b5748fc   \n",
              "3       c8f2de56550ed0bf85249608b7ead93d   \n",
              "4       e56ec342fc599ebb4ed89655eb6f03aa   \n",
              "...                                  ...   \n",
              "557581  e56ec342fc599ebb4ed89655eb6f03aa   \n",
              "557582  5b10d7739171149be6d9961e3350c071   \n",
              "557583  1590a03f43b5ba4b6147a1c5e1dd357b   \n",
              "557584  5b10d7739171149be6d9961e3350c071   \n",
              "557585  b11f2df64ac19aad47a50accf32052d6   \n",
              "\n",
              "                                       media media_type  \\\n",
              "0                                        NaN        NaN   \n",
              "1                                        NaN        NaN   \n",
              "2                                        NaN        NaN   \n",
              "3       94dca4cda503100ebfda7ce2bcc060eb.jpg  image/jpg   \n",
              "4       5ad5c8bbe9da93a37fecf3e5aa5b0637.jpg  image/jpg   \n",
              "...                                      ...        ...   \n",
              "557581  25e43b6a58b848c43ad5b5f9e979822a.jpg        url   \n",
              "557582  657949d03e4088f6b332e2686ccd3221.jpg        url   \n",
              "557583  a21848a61045380a6483866daed0ca0e.jpg  image/jpg   \n",
              "557584  a21848a61045380a6483866daed0ca0e.jpg  image/jpg   \n",
              "557585  a21848a61045380a6483866daed0ca0e.jpg  image/jpg   \n",
              "\n",
              "                                                media_url  has_media  \\\n",
              "0                                                     NaN      False   \n",
              "1                                                     NaN      False   \n",
              "2                                                     NaN      False   \n",
              "3                                                     NaN       True   \n",
              "4                                                     NaN       True   \n",
              "...                                                   ...        ...   \n",
              "557581  https://terrabrasilnoticias.com/2022/11/bndes-...       True   \n",
              "557582                       https://youtu.be/8g1Vz9_0xVk       True   \n",
              "557583                           https://t.me/vemprasruas       True   \n",
              "557584                           https://t.me/vemprasruas       True   \n",
              "557585                           https://t.me/vemprasruas       True   \n",
              "\n",
              "        has_media_url  trava_zap  \\\n",
              "0               False      False   \n",
              "1               False      False   \n",
              "2               False      False   \n",
              "3               False      False   \n",
              "4               False      False   \n",
              "...               ...        ...   \n",
              "557581           True      False   \n",
              "557582           True      False   \n",
              "557583           True      False   \n",
              "557584           True      False   \n",
              "557585           True      False   \n",
              "\n",
              "                                   text_content_anonymous  dataset_info_id  \\\n",
              "0       Então é Fato Renato o áudio que eu ouvi no wha...                5   \n",
              "1       Saiu no YouTube do presidente a 8 horas atrás,...                5   \n",
              "2       É isso, nossa parte já foi quase toda feita. N...                5   \n",
              "3                GENTE ACHEI ELES EM UMA SEITA MAÇONÁRICA                5   \n",
              "4                                                     NaN                5   \n",
              "...                                                   ...              ...   \n",
              "557581  BNDES tem lucro de R$ 9,6 bilhões no terceiro ...                5   \n",
              "557582                       https://youtu.be/8g1Vz9_0xVk                5   \n",
              "557583  Empresários, demitam os petistas primeiro.\\n\\n...                5   \n",
              "557584  Empresários, demitam os petistas primeiro.\\n\\n...                5   \n",
              "557585  Empresários, demitam os petistas primeiro.\\n\\n...                5   \n",
              "\n",
              "                       date_system  score_sentiment  score_misinformation  \\\n",
              "0       2022-10-05 06:25:28.863641           0.0000                   NaN   \n",
              "1       2022-10-05 06:25:28.926311           0.0644                   NaN   \n",
              "2       2022-10-05 06:26:29.361949          -0.3551              0.157242   \n",
              "3       2022-10-05 06:27:29.935624           0.0000                   NaN   \n",
              "4       2022-10-05 06:28:29.316325              NaN                   NaN   \n",
              "...                            ...              ...                   ...   \n",
              "557581  2022-11-16 14:49:39.146502           0.1027                   NaN   \n",
              "557582  2022-11-16 14:49:39.847434           0.0000                   NaN   \n",
              "557583  2022-11-16 14:49:39.922279           0.0000                   NaN   \n",
              "557584  2022-11-16 14:49:39.992932           0.0000                   NaN   \n",
              "557585  2022-11-16 14:49:40.064006           0.0000                   NaN   \n",
              "\n",
              "        id_message   id_persona message_type messenger media_name  \\\n",
              "0            16385  Wanda Silva        Texto  telegram        NaN   \n",
              "1            16386  Wanda Silva        Texto  telegram        NaN   \n",
              "2            16366  Wanda Silva        Texto  telegram        NaN   \n",
              "3            19281  Wanda Silva       Imagem  telegram        NaN   \n",
              "4           507185  Wanda Silva       Imagem  telegram        NaN   \n",
              "...            ...          ...          ...       ...        ...   \n",
              "557581      575796  Wanda Silva          Url  telegram        NaN   \n",
              "557582     1286443  Wanda Silva          Url  telegram        NaN   \n",
              "557583       13294  Wanda Silva       Imagem  telegram        NaN   \n",
              "557584     1286444  Wanda Silva       Imagem  telegram        NaN   \n",
              "557585      192127  Wanda Silva       Imagem  telegram        NaN   \n",
              "\n",
              "                               media_md5  \n",
              "0                                    NaN  \n",
              "1                                    NaN  \n",
              "2                                    NaN  \n",
              "3       94dca4cda503100ebfda7ce2bcc060eb  \n",
              "4       5ad5c8bbe9da93a37fecf3e5aa5b0637  \n",
              "...                                  ...  \n",
              "557581  25e43b6a58b848c43ad5b5f9e979822a  \n",
              "557582  657949d03e4088f6b332e2686ccd3221  \n",
              "557583  a21848a61045380a6483866daed0ca0e  \n",
              "557584  a21848a61045380a6483866daed0ca0e  \n",
              "557585  a21848a61045380a6483866daed0ca0e  \n",
              "\n",
              "[556968 rows x 20 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Filtrar o DataFrame para remover as linhas com esses IDs\n",
        "df_filtrado = df[~df['id_member_anonymous'].isin(ids_para_remover)]\n",
        "df_filtrado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "443759"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Removendo linhas com valores NaN na coluna 'text_content_anonymous'\n",
        "df_filtrado = df_filtrado.dropna(subset=['text_content_anonymous'])\n",
        "\n",
        "# Removendo trava_zap\n",
        "df_filtrado = df_filtrado[df_filtrado['trava_zap'] == False]\n",
        "\n",
        "\n",
        "\n",
        "#df_filtrado = df_filtrado[0:100]\n",
        "len(df_filtrado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to C:\\Users\\Melissa\n",
            "[nltk_data]     Felipe\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to C:\\Users\\Melissa\n",
            "[nltk_data]     Felipe\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to C:\\Users\\Melissa\n",
            "[nltk_data]     Felipe\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('portuguese'))\n",
        "\n",
        "custom_stopwords = {\n",
        "    't', 'be', 'nao', 'youtu', 'vai', 'av', 'ja', 'to', 'the', 'this', 'i', 'and', \n",
        "    'you', 'y', 'www', 'sao', 'pois', 'contra', 'user', 'ai', 'so', 'gente', 'voce', 'of', \n",
        "    'ola', 'gift', 'card', 'kwaivideo', 'r', 'bom', 'q', 'vc', 'vcs', 'pra','ta', 'phone', 'ok', 'la',\n",
        "    'sera', 'ha', 'aqui', 'ate', 'dia', 'mc', 'im', 'tmj', 'pix', 'g', 'diz', 'ti', 'etc', 'tudo', \n",
        "    'todo', 'toda', 'youtube', 'g1', 'm', 'instagram', 'fb', 'in', 'link', 'was', 'blocked', 'kk'\n",
        "}\n",
        "\n",
        "stop_words.update(custom_stopwords)\n",
        "\n",
        "def preprocess_text(text):\n",
        "\n",
        "    # Função para extrair e substituir o domínio da URL\n",
        "    def substituir_dominios(texto):\n",
        "        # Função para extrair e substituir o domínio da URL\n",
        "        def extrair_dominio(url):\n",
        "            # Remove o protocolo (http://, https://, etc.) e o \"www.\" se presente\n",
        "            dominio = re.sub(r'^https?://(?:www\\.)?|www\\.', '', url)\n",
        "            # Remove o caminho e parâmetros da URL\n",
        "            dominio = re.split(r'[/?#]', dominio)[0]\n",
        "            # Retorna a parte principal do domínio (antes do primeiro ponto)\n",
        "            return dominio.split('.')[0]\n",
        "\n",
        "        # Substitui URLs por seus domínios principais\n",
        "        return re.sub(r'https?://(?:www\\.)?\\S+|www\\.\\S+', lambda match: extrair_dominio(match.group(0)), texto)\n",
        "\n",
        "    # Substituir domínios\n",
        "    text = substituir_dominios(text)\n",
        "\n",
        "    # Converte para minúsculas\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove acentos\n",
        "    text = unidecode(text)\n",
        "\n",
        "    #Remover Pontuação\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # Remove URLs e menções\n",
        "    #text = re.sub(r'http\\S+|www\\S+|https\\S+|@\\w+', '', text)\n",
        "\n",
        "    # Substitui emojis repetidos por apenas um\n",
        "    text = re.sub(r'([\\U00010000-\\U0010FFFF])\\1+', r'\\1', text)\n",
        "    text = re.sub(r'([\\U0001F600-\\U0001F64F]|[\\U0001F300-\\U0001F5FF]|[\\U0001F680-\\U0001F6FF]|[\\U0001F700-\\U0001F77F]|[\\U0001F780-\\U0001F7FF]|[\\U0001F800-\\U0001F8FF]|[\\U0001F900-\\U0001F9FF]|[\\U0001FA00-\\U0001FA6F]|[\\U0001FA70-\\U0001FAFF])\\1+', r'\\1', text)\n",
        "\n",
        "\n",
        "    # Remove espaços em branco extras (início ou final) e múltiplos espaços no meio do texto\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # Remove pontuações e caracteres especiais\n",
        "    #text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    # Ajusta risadas \"kkk\" ou mais para \"kk\"\n",
        "    text = re.sub(r'k{2,}|K{2,}', 'kk', text)\n",
        "\n",
        "    # Ajusta risadas \"haha\" ou mais para \"haha\"\n",
        "    text = re.sub(r'(ha){2,}', 'haha', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Ajusta risadas \"kaka\" ou mais para \"kaka\"\n",
        "    text = re.sub(r'(ka){2,}', 'kaka', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Remove as stopwords\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "\n",
        "\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date_message</th>\n",
              "      <th>id_member_anonymous</th>\n",
              "      <th>id_group_anonymous</th>\n",
              "      <th>media</th>\n",
              "      <th>media_type</th>\n",
              "      <th>media_url</th>\n",
              "      <th>has_media</th>\n",
              "      <th>has_media_url</th>\n",
              "      <th>trava_zap</th>\n",
              "      <th>text_content_anonymous</th>\n",
              "      <th>...</th>\n",
              "      <th>date_system</th>\n",
              "      <th>score_sentiment</th>\n",
              "      <th>score_misinformation</th>\n",
              "      <th>id_message</th>\n",
              "      <th>id_persona</th>\n",
              "      <th>message_type</th>\n",
              "      <th>messenger</th>\n",
              "      <th>media_name</th>\n",
              "      <th>media_md5</th>\n",
              "      <th>text_processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-10-05 06:25:04</td>\n",
              "      <td>1078cc958f0febe28f4d03207660715f</td>\n",
              "      <td>12283e08a2eb5789201e105b34489ee7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Então é Fato Renato o áudio que eu ouvi no wha...</td>\n",
              "      <td>...</td>\n",
              "      <td>2022-10-05 06:25:28.863641</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16385</td>\n",
              "      <td>Wanda Silva</td>\n",
              "      <td>Texto</td>\n",
              "      <td>telegram</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>entao fato renato audio ouvi whatsapp ocorreu ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-10-05 06:25:08</td>\n",
              "      <td>NaN</td>\n",
              "      <td>12283e08a2eb5789201e105b34489ee7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Saiu no YouTube do presidente a 8 horas atrás,...</td>\n",
              "      <td>...</td>\n",
              "      <td>2022-10-05 06:25:28.926311</td>\n",
              "      <td>0.0644</td>\n",
              "      <td>NaN</td>\n",
              "      <td>16386</td>\n",
              "      <td>Wanda Silva</td>\n",
              "      <td>Texto</td>\n",
              "      <td>telegram</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>saiu presidente 8 horas atras infelizmente con...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-10-05 06:26:28</td>\n",
              "      <td>92a2d8fd7144074f659d1d29dc3751da</td>\n",
              "      <td>9f2d7394334eb224c061c9740b5748fc</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>É isso, nossa parte já foi quase toda feita. N...</td>\n",
              "      <td>...</td>\n",
              "      <td>2022-10-05 06:26:29.361949</td>\n",
              "      <td>-0.3551</td>\n",
              "      <td>0.157242</td>\n",
              "      <td>16366</td>\n",
              "      <td>Wanda Silva</td>\n",
              "      <td>Texto</td>\n",
              "      <td>telegram</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>parte quase feita segundo turno completamos pa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-10-05 06:27:28</td>\n",
              "      <td>d60aa38f62b4977426b70944af4aff72</td>\n",
              "      <td>c8f2de56550ed0bf85249608b7ead93d</td>\n",
              "      <td>94dca4cda503100ebfda7ce2bcc060eb.jpg</td>\n",
              "      <td>image/jpg</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>GENTE ACHEI ELES EM UMA SEITA MAÇONÁRICA</td>\n",
              "      <td>...</td>\n",
              "      <td>2022-10-05 06:27:29.935624</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19281</td>\n",
              "      <td>Wanda Silva</td>\n",
              "      <td>Imagem</td>\n",
              "      <td>telegram</td>\n",
              "      <td>NaN</td>\n",
              "      <td>94dca4cda503100ebfda7ce2bcc060eb</td>\n",
              "      <td>achei seita maconarica</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2022-10-05 06:28:30</td>\n",
              "      <td>NaN</td>\n",
              "      <td>b52442a5fbc459ae590dca0d215e32f9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Kķkkkkk to rindo até agora....Quem disse q ia ...</td>\n",
              "      <td>...</td>\n",
              "      <td>2022-10-05 06:29:29.046694</td>\n",
              "      <td>0.7003</td>\n",
              "      <td>0.197813</td>\n",
              "      <td>2735</td>\n",
              "      <td>Wanda Silva</td>\n",
              "      <td>Texto</td>\n",
              "      <td>telegram</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>rindo agoraquem disse ia fazer acordo diabo pr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          date_message               id_member_anonymous  \\\n",
              "0  2022-10-05 06:25:04  1078cc958f0febe28f4d03207660715f   \n",
              "1  2022-10-05 06:25:08                               NaN   \n",
              "2  2022-10-05 06:26:28  92a2d8fd7144074f659d1d29dc3751da   \n",
              "3  2022-10-05 06:27:28  d60aa38f62b4977426b70944af4aff72   \n",
              "5  2022-10-05 06:28:30                               NaN   \n",
              "\n",
              "                 id_group_anonymous                                 media  \\\n",
              "0  12283e08a2eb5789201e105b34489ee7                                   NaN   \n",
              "1  12283e08a2eb5789201e105b34489ee7                                   NaN   \n",
              "2  9f2d7394334eb224c061c9740b5748fc                                   NaN   \n",
              "3  c8f2de56550ed0bf85249608b7ead93d  94dca4cda503100ebfda7ce2bcc060eb.jpg   \n",
              "5  b52442a5fbc459ae590dca0d215e32f9                                   NaN   \n",
              "\n",
              "  media_type media_url  has_media  has_media_url  trava_zap  \\\n",
              "0        NaN       NaN      False          False      False   \n",
              "1        NaN       NaN      False          False      False   \n",
              "2        NaN       NaN      False          False      False   \n",
              "3  image/jpg       NaN       True          False      False   \n",
              "5        NaN       NaN      False          False      False   \n",
              "\n",
              "                              text_content_anonymous  ...  \\\n",
              "0  Então é Fato Renato o áudio que eu ouvi no wha...  ...   \n",
              "1  Saiu no YouTube do presidente a 8 horas atrás,...  ...   \n",
              "2  É isso, nossa parte já foi quase toda feita. N...  ...   \n",
              "3           GENTE ACHEI ELES EM UMA SEITA MAÇONÁRICA  ...   \n",
              "5  Kķkkkkk to rindo até agora....Quem disse q ia ...  ...   \n",
              "\n",
              "                  date_system score_sentiment  score_misinformation  \\\n",
              "0  2022-10-05 06:25:28.863641          0.0000                   NaN   \n",
              "1  2022-10-05 06:25:28.926311          0.0644                   NaN   \n",
              "2  2022-10-05 06:26:29.361949         -0.3551              0.157242   \n",
              "3  2022-10-05 06:27:29.935624          0.0000                   NaN   \n",
              "5  2022-10-05 06:29:29.046694          0.7003              0.197813   \n",
              "\n",
              "   id_message   id_persona message_type messenger media_name  \\\n",
              "0       16385  Wanda Silva        Texto  telegram        NaN   \n",
              "1       16386  Wanda Silva        Texto  telegram        NaN   \n",
              "2       16366  Wanda Silva        Texto  telegram        NaN   \n",
              "3       19281  Wanda Silva       Imagem  telegram        NaN   \n",
              "5        2735  Wanda Silva        Texto  telegram        NaN   \n",
              "\n",
              "                          media_md5  \\\n",
              "0                               NaN   \n",
              "1                               NaN   \n",
              "2                               NaN   \n",
              "3  94dca4cda503100ebfda7ce2bcc060eb   \n",
              "5                               NaN   \n",
              "\n",
              "                                      text_processed  \n",
              "0  entao fato renato audio ouvi whatsapp ocorreu ...  \n",
              "1  saiu presidente 8 horas atras infelizmente con...  \n",
              "2  parte quase feita segundo turno completamos pa...  \n",
              "3                             achei seita maconarica  \n",
              "5  rindo agoraquem disse ia fazer acordo diabo pr...  \n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "df_geral = df_filtrado.copy()\n",
        "\n",
        "# Aplicar o pré-processamento à coluna de texto\n",
        "df_geral['text_processed'] = df_geral['text_content_anonymous'].apply(preprocess_text)\n",
        "\n",
        "df_geral.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calculando a diversidade dos tópicos\n",
        "A diversidade de tópicos mede quantas palavras únicas existem entre os top-N termos de todos os tópicos. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def topic_diversity(model, top_n=10):\n",
        "    topic_words = []\n",
        "    for k in range(model.k):  \n",
        "        words = [word for word, _ in model.get_topic_words(k, top_n=top_n)]  \n",
        "        topic_words.extend(words)\n",
        "    unique_words = set(topic_words)\n",
        "    return len(unique_words) / (top_n * model.k)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### IRBO \n",
        "\n",
        "IRBO avalia quanto os tópicos são distintos entre si, usando o Rank-Biased Overlap (RBO) invertido. Quanto maior o IRBO, mais diferentes são os tópicos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import rbo\n",
        "\n",
        "def compute_irbo_ptm(model, top_n=10):\n",
        "    topics = []\n",
        "    for k in range(model.k):\n",
        "        topic_terms = [word for word, _ in model.get_topic_words(k, top_n=top_n)]\n",
        "        topics.append(topic_terms)\n",
        "\n",
        "    n = len(topics)\n",
        "    total_irbo = 0\n",
        "    count = 0\n",
        "\n",
        "    for i in range(n):\n",
        "        for j in range(i + 1, n):\n",
        "            rbo_score = rbo.RankingSimilarity(topics[i], topics[j]).rbo()\n",
        "            total_irbo += (1 - rbo_score)  # IRBO = 1 - RBO\n",
        "            count += 1\n",
        "\n",
        "    return total_irbo / count if count > 0 else 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Processamento\n",
        "token_espaco = tokenize.WhitespaceTokenizer()\n",
        "token_pontuacao = tokenize.WordPunctTokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_coherence_ptm(texts, id2word, coherence, start=2, limit=30, step=2):\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    topic_range = list(range(start, limit, step))\n",
        "\n",
        "    for num_topics in tqdm(topic_range, desc=f\"Treinando PTModel ({coherence})\"):\n",
        "        model = tp.PTModel(k=num_topics, seed=42)\n",
        "        for doc in texts:\n",
        "            model.add_doc(doc)\n",
        "        model.train(100)\n",
        "        model_list.append(model)\n",
        "\n",
        "        # Coherence do gensim precisa de tópicos no formato: lista de listas de palavras\n",
        "        topics = []\n",
        "        for k in range(model.k):\n",
        "            topic_words = [word for word, _ in model.get_topic_words(k, top_n=10)]\n",
        "            topics.append(topic_words)\n",
        "\n",
        "        coh_model = CoherenceModel(topics=topics, texts=texts, dictionary=id2word, coherence=coherence)\n",
        "        coherence_score = coh_model.get_coherence()\n",
        "        coherence_values.append(coherence_score)\n",
        "\n",
        "    optimal_index = coherence_values.index(max(coherence_values))\n",
        "    optimal_num_topics = topic_range[optimal_index]\n",
        "\n",
        "    return optimal_num_topics, model_list, coherence_values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def processar_texto(texto):\n",
        "    texto = texto.lower()\n",
        "    palavras_texto = token_espaco.tokenize(texto)\n",
        "    palavras_texto = token_pontuacao.tokenize(' '.join(palavras_texto))\n",
        "    return [palavra for palavra in palavras_texto]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modelando os Tópicos sem filtro "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "texto_processado = df_geral['text_processed'].apply(processar_texto)\n",
        "\n",
        "# Corpus e Dicionário (para CoherenceModel do gensim)\n",
        "id2word = corpora.Dictionary(texto_processado)\n",
        "corpus = [id2word.doc2bow(text) for text in texto_processado]\n",
        "texts = texto_processado.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Treinando PTModel (c_v):   0%|          | 0/14 [00:00<?, ?it/s]C:\\Users\\Melissa Felipe\\AppData\\Local\\Temp\\ipykernel_8628\\2436467606.py:10: RuntimeWarning: The training result may differ even with fixed seed if `workers` != 1.\n",
            "  model.train(100)\n",
            "Treinando PTModel (c_v): 100%|██████████| 14/14 [1:05:19<00:00, 279.98s/it]\n",
            "Treinando PTModel (u_mass): 100%|██████████| 14/14 [1:01:25<00:00, 263.28s/it]\n",
            "Treinando PTModel (c_uci): 100%|██████████| 14/14 [1:06:05<00:00, 283.26s/it]\n",
            "Treinando PTModel (c_npmi): 100%|██████████| 14/14 [1:05:52<00:00, 282.32s/it]\n"
          ]
        }
      ],
      "source": [
        "def calculate_ptm_coherence_for_metrics(texts, id2word, metrics, start=2, limit=30, step=2):\n",
        "    results = {}\n",
        "    for metric in metrics:\n",
        "        num_topics, model_list, coherence_values = compute_coherence_ptm(\n",
        "            texts=texts,\n",
        "            id2word=id2word,\n",
        "            coherence=metric,\n",
        "            start=start,\n",
        "            limit=limit,\n",
        "            step=step\n",
        "        )\n",
        "        results[metric] = {\n",
        "            'num_topics': num_topics,\n",
        "            'model_list': model_list,\n",
        "            'coherence_values': coherence_values\n",
        "        }\n",
        "    return results\n",
        "\n",
        "metrics = ['c_v', 'u_mass', 'c_uci', 'c_npmi']\n",
        "\n",
        "ptm_coherence_results = calculate_ptm_coherence_for_metrics(\n",
        "    texts=texto_processado.tolist(),\n",
        "    id2word=id2word,\n",
        "    metrics=metrics,\n",
        "    start=2,\n",
        "    limit=30,\n",
        "    step=2\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Resultados de Coerência para C_V:\n",
            "Qtd. tópicos = 2 -> Coerência = 0.423\n",
            "Qtd. tópicos = 4 -> Coerência = 0.4015\n",
            "Qtd. tópicos = 6 -> Coerência = 0.5568\n",
            "Qtd. tópicos = 8 -> Coerência = 0.4695\n",
            "Qtd. tópicos = 10 -> Coerência = 0.5098\n",
            "Qtd. tópicos = 12 -> Coerência = 0.5096\n",
            "Qtd. tópicos = 14 -> Coerência = 0.5035\n",
            "Qtd. tópicos = 16 -> Coerência = 0.5623\n",
            "Qtd. tópicos = 18 -> Coerência = 0.5592\n",
            "Qtd. tópicos = 20 -> Coerência = 0.515\n",
            "Qtd. tópicos = 22 -> Coerência = 0.5486\n",
            "Qtd. tópicos = 24 -> Coerência = 0.567\n",
            "Qtd. tópicos = 26 -> Coerência = 0.5159\n",
            "Qtd. tópicos = 28 -> Coerência = 0.5897\n",
            "Melhor número de tópicos segundo C_V: 28\n",
            "\n",
            "Resultados de Coerência para U_MASS:\n",
            "Qtd. tópicos = 2 -> Coerência = -3.4423\n",
            "Qtd. tópicos = 4 -> Coerência = -5.3086\n",
            "Qtd. tópicos = 6 -> Coerência = -3.825\n",
            "Qtd. tópicos = 8 -> Coerência = -6.2338\n",
            "Qtd. tópicos = 10 -> Coerência = -4.6999\n",
            "Qtd. tópicos = 12 -> Coerência = -4.8487\n",
            "Qtd. tópicos = 14 -> Coerência = -5.0896\n",
            "Qtd. tópicos = 16 -> Coerência = -4.6374\n",
            "Qtd. tópicos = 18 -> Coerência = -5.1208\n",
            "Qtd. tópicos = 20 -> Coerência = -5.0418\n",
            "Qtd. tópicos = 22 -> Coerência = -5.1642\n",
            "Qtd. tópicos = 24 -> Coerência = -4.26\n",
            "Qtd. tópicos = 26 -> Coerência = -5.1555\n",
            "Qtd. tópicos = 28 -> Coerência = -4.4782\n",
            "Melhor número de tópicos segundo U_MASS: 2\n",
            "\n",
            "Resultados de Coerência para C_UCI:\n",
            "Qtd. tópicos = 2 -> Coerência = -2.0901\n",
            "Qtd. tópicos = 4 -> Coerência = -2.6196\n",
            "Qtd. tópicos = 6 -> Coerência = -0.5204\n",
            "Qtd. tópicos = 8 -> Coerência = -3.1526\n",
            "Qtd. tópicos = 10 -> Coerência = -1.4434\n",
            "Qtd. tópicos = 12 -> Coerência = -1.7974\n",
            "Qtd. tópicos = 14 -> Coerência = -1.9106\n",
            "Qtd. tópicos = 16 -> Coerência = -1.5223\n",
            "Qtd. tópicos = 18 -> Coerência = -1.9301\n",
            "Qtd. tópicos = 20 -> Coerência = -1.925\n",
            "Qtd. tópicos = 22 -> Coerência = -1.9131\n",
            "Qtd. tópicos = 24 -> Coerência = -0.9451\n",
            "Qtd. tópicos = 26 -> Coerência = -1.5913\n",
            "Qtd. tópicos = 28 -> Coerência = -1.631\n",
            "Melhor número de tópicos segundo C_UCI: 6\n",
            "\n",
            "Resultados de Coerência para C_NPMI:\n",
            "Qtd. tópicos = 2 -> Coerência = -0.0802\n",
            "Qtd. tópicos = 4 -> Coerência = -0.0254\n",
            "Qtd. tópicos = 6 -> Coerência = 0.1302\n",
            "Qtd. tópicos = 8 -> Coerência = 0.0137\n",
            "Qtd. tópicos = 10 -> Coerência = 0.0631\n",
            "Qtd. tópicos = 12 -> Coerência = 0.0506\n",
            "Qtd. tópicos = 14 -> Coerência = 0.0301\n",
            "Qtd. tópicos = 16 -> Coerência = 0.07\n",
            "Qtd. tópicos = 18 -> Coerência = 0.0422\n",
            "Qtd. tópicos = 20 -> Coerência = 0.0418\n",
            "Qtd. tópicos = 22 -> Coerência = 0.0473\n",
            "Qtd. tópicos = 24 -> Coerência = 0.0946\n",
            "Qtd. tópicos = 26 -> Coerência = 0.0398\n",
            "Qtd. tópicos = 28 -> Coerência = 0.057\n",
            "Melhor número de tópicos segundo C_NPMI: 6\n"
          ]
        }
      ],
      "source": [
        "# Mostrar resultados\n",
        "for metric in metrics:\n",
        "    print(f\"\\nResultados de Coerência para {metric.upper()}:\")\n",
        "    for m, cv in zip(range(2, 30, 2), ptm_coherence_results[metric]['coherence_values']):\n",
        "        print(f\"Qtd. tópicos = {m} -> Coerência = {round(cv, 4)}\")\n",
        "    print(f\"Melhor número de tópicos segundo {metric.upper()}: {ptm_coherence_results[metric]['num_topics']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tópico</th>\n",
              "      <th>Palavras</th>\n",
              "      <th>Pesos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>grupo, canal, abaixo, verdade, vpn, poder, 3, ...</td>\n",
              "      <td>[0.015988091006875038, 0.012962390668690205, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>13, intervencao, 22, militar, rua, pau, mao, b...</td>\n",
              "      <td>[0.12448844313621521, 0.05460965633392334, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>55, militar, batalhao, sp, rua, centro, comand...</td>\n",
              "      <td>[0.022184057161211967, 0.011170903220772743, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>telegram, ganhar, welcome, professional, group...</td>\n",
              "      <td>[0.02615315653383732, 0.017487330362200737, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>bolsonaro, brasil, todos, lula, presidente, es...</td>\n",
              "      <td>[0.012264122255146503, 0.00819872785359621, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>tse, superior, brazil, following, decision, co...</td>\n",
              "      <td>[0.024527493864297867, 0.022596294060349464, 0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Tópico                                           Palavras  \\\n",
              "0       0  grupo, canal, abaixo, verdade, vpn, poder, 3, ...   \n",
              "1       1  13, intervencao, 22, militar, rua, pau, mao, b...   \n",
              "2       2  55, militar, batalhao, sp, rua, centro, comand...   \n",
              "3       3  telegram, ganhar, welcome, professional, group...   \n",
              "4       4  bolsonaro, brasil, todos, lula, presidente, es...   \n",
              "5       5  tse, superior, brazil, following, decision, co...   \n",
              "\n",
              "                                               Pesos  \n",
              "0  [0.015988091006875038, 0.012962390668690205, 0...  \n",
              "1  [0.12448844313621521, 0.05460965633392334, 0.0...  \n",
              "2  [0.022184057161211967, 0.011170903220772743, 0...  \n",
              "3  [0.02615315653383732, 0.017487330362200737, 0....  \n",
              "4  [0.012264122255146503, 0.00819872785359621, 0....  \n",
              "5  [0.024527493864297867, 0.022596294060349464, 0...  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Escolha da métrica\n",
        "chosen_metric = 'c_npmi'  # ou 'c_v', 'u_mass', 'c_uci'\n",
        "\n",
        "# Obter o melhor modelo treinado\n",
        "best_index = ptm_coherence_results[chosen_metric]['coherence_values'].index(\n",
        "    max(ptm_coherence_results[chosen_metric]['coherence_values'])\n",
        ")\n",
        "best_model = ptm_coherence_results[chosen_metric]['model_list'][best_index]\n",
        "\n",
        "# Gerar DataFrame com tópicos\n",
        "def get_topics_dataframe(model, top_n=10):\n",
        "    topics_data = []\n",
        "    for topic_id in range(model.k):\n",
        "        words_probs = model.get_topic_words(topic_id, top_n=top_n)\n",
        "        topic_words = [word for word, prob in words_probs]\n",
        "        topic_probs = [prob for word, prob in words_probs]\n",
        "        topics_data.append({\n",
        "            'Tópico': topic_id,\n",
        "            'Palavras': ', '.join(topic_words),\n",
        "            'Pesos': topic_probs\n",
        "        })\n",
        "    return pd.DataFrame(topics_data)\n",
        "\n",
        "df_topicos = get_topics_dataframe(best_model)\n",
        "\n",
        "df_topicos.to_csv('./resultados_pseudo/telegram/pseudo_telegram_c_npmi.csv', index=False)\n",
        "df_topicos.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diversidade de Tópicos: 0.9\n",
            "IRBO médio entre tópicos: 0.9806\n"
          ]
        }
      ],
      "source": [
        "div = topic_diversity(best_model)\n",
        "print(f\"Diversidade de Tópicos: {round(div, 4)}\")\n",
        "\n",
        "irbo_score = compute_irbo_ptm(best_model)\n",
        "print(f\"IRBO médio entre tópicos: {round(irbo_score, 4)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diversidade de Tópicos: 0.7893\n",
            "IRBO médio entre tópicos: 0.9788\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tópico</th>\n",
              "      <th>Palavras</th>\n",
              "      <th>Pesos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>ruas, povo, armadas, forcas, quarteis, pode, p...</td>\n",
              "      <td>[0.01540481485426426, 0.01347713079303503, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>proibido, lula, bolsonaro, dizer, apoiadores, ...</td>\n",
              "      <td>[0.02882852964103222, 0.027155514806509018, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>reais, pl, 88888888, ptb, tmealexeconomia, tra...</td>\n",
              "      <td>[0.02544431947171688, 0.022112907841801643, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>ganhar, comecar, dinheiro, comigo, pode, bot, ...</td>\n",
              "      <td>[0.06236105412244797, 0.05637528747320175, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>55, brasil, grupos, 1, silva, souza, bolsonaro...</td>\n",
              "      <td>[0.18220603466033936, 0.007251132745295763, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>13, lula, presidente, vota, bolsonaro, rola, c...</td>\n",
              "      <td>[0.7298851013183594, 0.03948638588190079, 0.03...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>km, br, cidade, local, turno, sul, nova, pesso...</td>\n",
              "      <td>[0.0082227298989892, 0.00807548500597477, 0.00...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>milhoes, bilhoes, caso, escandalo, pt, preso, ...</td>\n",
              "      <td>[0.02420990727841854, 0.0157306008040905, 0.01...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>intervencao, militar, pau, mao, federal, presi...</td>\n",
              "      <td>[0.31642836332321167, 0.1376071572303772, 0.10...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>vpn, b, with, yn, bilan, men, erkaklari, sex, ...</td>\n",
              "      <td>[0.05719416216015816, 0.03432958573102951, 0.0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Tópico                                           Palavras  \\\n",
              "0       0  ruas, povo, armadas, forcas, quarteis, pode, p...   \n",
              "1       1  proibido, lula, bolsonaro, dizer, apoiadores, ...   \n",
              "2       2  reais, pl, 88888888, ptb, tmealexeconomia, tra...   \n",
              "3       3  ganhar, comecar, dinheiro, comigo, pode, bot, ...   \n",
              "4       4  55, brasil, grupos, 1, silva, souza, bolsonaro...   \n",
              "5       5  13, lula, presidente, vota, bolsonaro, rola, c...   \n",
              "6       6  km, br, cidade, local, turno, sul, nova, pesso...   \n",
              "7       7  milhoes, bilhoes, caso, escandalo, pt, preso, ...   \n",
              "8       8  intervencao, militar, pau, mao, federal, presi...   \n",
              "9       9  vpn, b, with, yn, bilan, men, erkaklari, sex, ...   \n",
              "\n",
              "                                               Pesos  \n",
              "0  [0.01540481485426426, 0.01347713079303503, 0.0...  \n",
              "1  [0.02882852964103222, 0.027155514806509018, 0....  \n",
              "2  [0.02544431947171688, 0.022112907841801643, 0....  \n",
              "3  [0.06236105412244797, 0.05637528747320175, 0.0...  \n",
              "4  [0.18220603466033936, 0.007251132745295763, 0....  \n",
              "5  [0.7298851013183594, 0.03948638588190079, 0.03...  \n",
              "6  [0.0082227298989892, 0.00807548500597477, 0.00...  \n",
              "7  [0.02420990727841854, 0.0157306008040905, 0.01...  \n",
              "8  [0.31642836332321167, 0.1376071572303772, 0.10...  \n",
              "9  [0.05719416216015816, 0.03432958573102951, 0.0...  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Escolha da métrica\n",
        "chosen_metric = 'c_v'  # ou 'c_v', 'u_mass', 'c_uci'\n",
        "\n",
        "# Obter o melhor modelo treinado\n",
        "best_index = ptm_coherence_results[chosen_metric]['coherence_values'].index(\n",
        "    max(ptm_coherence_results[chosen_metric]['coherence_values'])\n",
        ")\n",
        "best_model = ptm_coherence_results[chosen_metric]['model_list'][best_index]\n",
        "\n",
        "# Gerar DataFrame com tópicos\n",
        "def get_topics_dataframe(model, top_n=10):\n",
        "    topics_data = []\n",
        "    for topic_id in range(model.k):\n",
        "        words_probs = model.get_topic_words(topic_id, top_n=top_n)\n",
        "        topic_words = [word for word, prob in words_probs]\n",
        "        topic_probs = [prob for word, prob in words_probs]\n",
        "        topics_data.append({\n",
        "            'Tópico': topic_id,\n",
        "            'Palavras': ', '.join(topic_words),\n",
        "            'Pesos': topic_probs\n",
        "        })\n",
        "    return pd.DataFrame(topics_data)\n",
        "\n",
        "df_topicos = get_topics_dataframe(best_model)\n",
        "\n",
        "df_topicos.to_csv('./resultados_pseudo/telegram/pseudo_telegram_c_v.csv', index=False)\n",
        "\n",
        "div = topic_diversity(best_model)\n",
        "print(f\"Diversidade de Tópicos: {round(div, 4)}\")\n",
        "\n",
        "irbo_score = compute_irbo_ptm(best_model)\n",
        "print(f\"IRBO médio entre tópicos: {round(irbo_score, 4)}\")\n",
        "\n",
        "df_topicos.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tópico</th>\n",
              "      <th>Palavras</th>\n",
              "      <th>Pesos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>grupo, canal, abaixo, verdade, vpn, poder, 3, ...</td>\n",
              "      <td>[0.015988091006875038, 0.012962390668690205, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>13, intervencao, 22, militar, rua, pau, mao, b...</td>\n",
              "      <td>[0.12448844313621521, 0.05460965633392334, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>55, militar, batalhao, sp, rua, centro, comand...</td>\n",
              "      <td>[0.022184057161211967, 0.011170903220772743, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>telegram, ganhar, welcome, professional, group...</td>\n",
              "      <td>[0.02615315653383732, 0.017487330362200737, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>bolsonaro, brasil, todos, lula, presidente, es...</td>\n",
              "      <td>[0.012264122255146503, 0.00819872785359621, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>tse, superior, brazil, following, decision, co...</td>\n",
              "      <td>[0.024527493864297867, 0.022596294060349464, 0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Tópico                                           Palavras  \\\n",
              "0       0  grupo, canal, abaixo, verdade, vpn, poder, 3, ...   \n",
              "1       1  13, intervencao, 22, militar, rua, pau, mao, b...   \n",
              "2       2  55, militar, batalhao, sp, rua, centro, comand...   \n",
              "3       3  telegram, ganhar, welcome, professional, group...   \n",
              "4       4  bolsonaro, brasil, todos, lula, presidente, es...   \n",
              "5       5  tse, superior, brazil, following, decision, co...   \n",
              "\n",
              "                                               Pesos  \n",
              "0  [0.015988091006875038, 0.012962390668690205, 0...  \n",
              "1  [0.12448844313621521, 0.05460965633392334, 0.0...  \n",
              "2  [0.022184057161211967, 0.011170903220772743, 0...  \n",
              "3  [0.02615315653383732, 0.017487330362200737, 0....  \n",
              "4  [0.012264122255146503, 0.00819872785359621, 0....  \n",
              "5  [0.024527493864297867, 0.022596294060349464, 0...  "
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Escolha da métrica\n",
        "chosen_metric = 'c_uci'  # ou 'c_v', 'u_mass', 'c_uci'\n",
        "\n",
        "# Obter o melhor modelo treinado\n",
        "best_index = ptm_coherence_results[chosen_metric]['coherence_values'].index(\n",
        "    max(ptm_coherence_results[chosen_metric]['coherence_values'])\n",
        ")\n",
        "best_model = ptm_coherence_results[chosen_metric]['model_list'][best_index]\n",
        "\n",
        "# Gerar DataFrame com tópicos\n",
        "def get_topics_dataframe(model, top_n=10):\n",
        "    topics_data = []\n",
        "    for topic_id in range(model.k):\n",
        "        words_probs = model.get_topic_words(topic_id, top_n=top_n)\n",
        "        topic_words = [word for word, prob in words_probs]\n",
        "        topic_probs = [prob for word, prob in words_probs]\n",
        "        topics_data.append({\n",
        "            'Tópico': topic_id,\n",
        "            'Palavras': ', '.join(topic_words),\n",
        "            'Pesos': topic_probs\n",
        "        })\n",
        "    return pd.DataFrame(topics_data)\n",
        "\n",
        "df_topicos = get_topics_dataframe(best_model)\n",
        "\n",
        "df_topicos.to_csv('./resultados_pseudo/telegram/pseudo_telegram_c_uci.csv', index=False)\n",
        "df_topicos.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diversidade de Tópicos: 0.9\n",
            "IRBO médio entre tópicos: 0.9806\n"
          ]
        }
      ],
      "source": [
        "div = topic_diversity(best_model)\n",
        "print(f\"Diversidade de Tópicos: {round(div, 4)}\")\n",
        "\n",
        "irbo_score = compute_irbo_ptm(best_model)\n",
        "print(f\"IRBO médio entre tópicos: {round(irbo_score, 4)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tópico</th>\n",
              "      <th>Palavras</th>\n",
              "      <th>Pesos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>13, lula, rua, militar, bolsonaro, sp, vpn, in...</td>\n",
              "      <td>[0.02766376920044422, 0.009874071925878525, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>bolsonaro, brasil, grupo, todos, presidente, t...</td>\n",
              "      <td>[0.008986602537333965, 0.006484880577772856, 0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Tópico                                           Palavras  \\\n",
              "0       0  13, lula, rua, militar, bolsonaro, sp, vpn, in...   \n",
              "1       1  bolsonaro, brasil, grupo, todos, presidente, t...   \n",
              "\n",
              "                                               Pesos  \n",
              "0  [0.02766376920044422, 0.009874071925878525, 0....  \n",
              "1  [0.008986602537333965, 0.006484880577772856, 0...  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Escolha da métrica\n",
        "chosen_metric = 'u_mass'  # ou 'c_v', 'u_mass', 'c_uci'\n",
        "\n",
        "# Obter o melhor modelo treinado\n",
        "best_index = ptm_coherence_results[chosen_metric]['coherence_values'].index(\n",
        "    max(ptm_coherence_results[chosen_metric]['coherence_values'])\n",
        ")\n",
        "best_model = ptm_coherence_results[chosen_metric]['model_list'][best_index]\n",
        "\n",
        "# Gerar DataFrame com tópicos\n",
        "def get_topics_dataframe(model, top_n=10):\n",
        "    topics_data = []\n",
        "    for topic_id in range(model.k):\n",
        "        words_probs = model.get_topic_words(topic_id, top_n=top_n)\n",
        "        topic_words = [word for word, prob in words_probs]\n",
        "        topic_probs = [prob for word, prob in words_probs]\n",
        "        topics_data.append({\n",
        "            'Tópico': topic_id,\n",
        "            'Palavras': ', '.join(topic_words),\n",
        "            'Pesos': topic_probs\n",
        "        })\n",
        "    return pd.DataFrame(topics_data)\n",
        "\n",
        "df_topicos = get_topics_dataframe(best_model)\n",
        "\n",
        "df_topicos.to_csv('./resultados_pseudo/telegram/pseudo_telegram_u_mass.csv', index=False)\n",
        "df_topicos.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diversidade de Tópicos: 0.85\n",
            "IRBO médio entre tópicos: 0.8575\n"
          ]
        }
      ],
      "source": [
        "div = topic_diversity(best_model)\n",
        "print(f\"Diversidade de Tópicos: {round(div, 4)}\")\n",
        "\n",
        "irbo_score = compute_irbo_ptm(best_model)\n",
        "print(f\"IRBO médio entre tópicos: {round(irbo_score, 4)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modelagem de tópicos com filtro religioso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "palavras_religiosas = [\n",
        "    \"deus\", \"jesus\", \"misericordia\", \"davi\",\n",
        "    \"salomao\", \"reino\", \"templo\", \"conservador\",\n",
        "    \"pentecostal\", \"rcc\", \"renovacao\", \"carismatic\",\n",
        "    \"paulo ricardo\", \"bernardo kuster\", \"herege\", \"ateu\",\n",
        "    \"jerico\", \"heresia\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Função para verificar se uma palavra está relacionada à religião\n",
        "def relacionada_religiao(word):\n",
        "    word_lower = word.lower()\n",
        "    palavras_religiosas_lower = [palavra.lower() for palavra in palavras_religiosas]\n",
        "\n",
        "    # Verificando se alguma palavra da lista de palavras religiosas está presente\n",
        "    return any(palavra in word_lower for palavra in palavras_religiosas_lower)\n",
        "\n",
        "\n",
        "df_religiao = df_geral[df_geral['text_processed'].apply(lambda x: relacionada_religiao(x))]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "texto_processado_religiao = df_religiao['text_processed'].apply(processar_texto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Corpus e Dicionário (para CoherenceModel do gensim)\n",
        "id2word_religiao = corpora.Dictionary(texto_processado_religiao)\n",
        "corpus_religiao = [id2word.doc2bow(text) for text in texto_processado_religiao]\n",
        "texts_religiao = texto_processado_religiao.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Treinando PTModel (c_v):   0%|          | 0/14 [00:00<?, ?it/s]C:\\Users\\Melissa Felipe\\AppData\\Local\\Temp\\ipykernel_8628\\2436467606.py:10: RuntimeWarning: The training result may differ even with fixed seed if `workers` != 1.\n",
            "  model.train(100)\n",
            "Treinando PTModel (c_v): 100%|██████████| 14/14 [12:38<00:00, 54.20s/it]\n",
            "Treinando PTModel (u_mass): 100%|██████████| 14/14 [06:24<00:00, 27.43s/it]\n",
            "Treinando PTModel (c_uci): 100%|██████████| 14/14 [08:09<00:00, 34.95s/it]\n",
            "Treinando PTModel (c_npmi): 100%|██████████| 14/14 [06:06<00:00, 26.20s/it]\n"
          ]
        }
      ],
      "source": [
        "def calculate_ptm_coherence_for_metrics(texts_religiao, id2word_religiao, metrics, start=2, limit=30, step=2):\n",
        "    results = {}\n",
        "    for metric in metrics:\n",
        "        num_topics, model_list, coherence_values = compute_coherence_ptm(\n",
        "            texts=texts_religiao,\n",
        "            id2word=id2word_religiao,\n",
        "            coherence=metric,\n",
        "            start=start,\n",
        "            limit=limit,\n",
        "            step=step\n",
        "        )\n",
        "        results[metric] = {\n",
        "            'num_topics': num_topics,\n",
        "            'model_list': model_list,\n",
        "            'coherence_values': coherence_values\n",
        "        }\n",
        "    return results\n",
        "\n",
        "metrics = ['c_v', 'u_mass', 'c_uci', 'c_npmi']\n",
        "\n",
        "ptm_coherence_results = calculate_ptm_coherence_for_metrics(\n",
        "    texts_religiao=texto_processado_religiao.tolist(),\n",
        "    id2word_religiao=id2word_religiao,\n",
        "    metrics=metrics,\n",
        "    start=2,\n",
        "    limit=30,\n",
        "    step=2\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Resultados de Coerência para C_V:\n",
            "Qtd. tópicos = 2 -> Coerência = 0.3705\n",
            "Qtd. tópicos = 4 -> Coerência = 0.4472\n",
            "Qtd. tópicos = 6 -> Coerência = 0.4578\n",
            "Qtd. tópicos = 8 -> Coerência = 0.4977\n",
            "Qtd. tópicos = 10 -> Coerência = 0.5294\n",
            "Qtd. tópicos = 12 -> Coerência = 0.474\n",
            "Qtd. tópicos = 14 -> Coerência = 0.5626\n",
            "Qtd. tópicos = 16 -> Coerência = 0.5306\n",
            "Qtd. tópicos = 18 -> Coerência = 0.5804\n",
            "Qtd. tópicos = 20 -> Coerência = 0.558\n",
            "Qtd. tópicos = 22 -> Coerência = 0.5485\n",
            "Qtd. tópicos = 24 -> Coerência = 0.5386\n",
            "Qtd. tópicos = 26 -> Coerência = 0.5047\n",
            "Qtd. tópicos = 28 -> Coerência = 0.5651\n",
            "Melhor número de tópicos segundo C_V: 18\n",
            "\n",
            "Resultados de Coerência para U_MASS:\n",
            "Qtd. tópicos = 2 -> Coerência = -1.9174\n",
            "Qtd. tópicos = 4 -> Coerência = -2.0417\n",
            "Qtd. tópicos = 6 -> Coerência = -2.1842\n",
            "Qtd. tópicos = 8 -> Coerência = -2.0041\n",
            "Qtd. tópicos = 10 -> Coerência = -1.9605\n",
            "Qtd. tópicos = 12 -> Coerência = -2.1358\n",
            "Qtd. tópicos = 14 -> Coerência = -2.2907\n",
            "Qtd. tópicos = 16 -> Coerência = -2.6599\n",
            "Qtd. tópicos = 18 -> Coerência = -2.0806\n",
            "Qtd. tópicos = 20 -> Coerência = -2.3576\n",
            "Qtd. tópicos = 22 -> Coerência = -2.1285\n",
            "Qtd. tópicos = 24 -> Coerência = -2.426\n",
            "Qtd. tópicos = 26 -> Coerência = -2.8793\n",
            "Qtd. tópicos = 28 -> Coerência = -2.3117\n",
            "Melhor número de tópicos segundo U_MASS: 2\n",
            "\n",
            "Resultados de Coerência para C_UCI:\n",
            "Qtd. tópicos = 2 -> Coerência = -1.2178\n",
            "Qtd. tópicos = 4 -> Coerência = -0.9861\n",
            "Qtd. tópicos = 6 -> Coerência = -1.0757\n",
            "Qtd. tópicos = 8 -> Coerência = -1.1855\n",
            "Qtd. tópicos = 10 -> Coerência = -0.9537\n",
            "Qtd. tópicos = 12 -> Coerência = -1.6999\n",
            "Qtd. tópicos = 14 -> Coerência = -0.7591\n",
            "Qtd. tópicos = 16 -> Coerência = -1.6519\n",
            "Qtd. tópicos = 18 -> Coerência = -1.0008\n",
            "Qtd. tópicos = 20 -> Coerência = -1.3342\n",
            "Qtd. tópicos = 22 -> Coerência = -1.0753\n",
            "Qtd. tópicos = 24 -> Coerência = -1.3272\n",
            "Qtd. tópicos = 26 -> Coerência = -1.9081\n",
            "Qtd. tópicos = 28 -> Coerência = -1.3599\n",
            "Melhor número de tópicos segundo C_UCI: 14\n",
            "\n",
            "Resultados de Coerência para C_NPMI:\n",
            "Qtd. tópicos = 2 -> Coerência = -0.0481\n",
            "Qtd. tópicos = 4 -> Coerência = 0.004\n",
            "Qtd. tópicos = 6 -> Coerência = 0.0096\n",
            "Qtd. tópicos = 8 -> Coerência = -0.0034\n",
            "Qtd. tópicos = 10 -> Coerência = 0.0271\n",
            "Qtd. tópicos = 12 -> Coerência = -0.0196\n",
            "Qtd. tópicos = 14 -> Coerência = 0.0411\n",
            "Qtd. tópicos = 16 -> Coerência = -0.0026\n",
            "Qtd. tópicos = 18 -> Coerência = 0.0304\n",
            "Qtd. tópicos = 20 -> Coerência = 0.0149\n",
            "Qtd. tópicos = 22 -> Coerência = 0.0206\n",
            "Qtd. tópicos = 24 -> Coerência = 0.0174\n",
            "Qtd. tópicos = 26 -> Coerência = -0.0117\n",
            "Qtd. tópicos = 28 -> Coerência = 0.0143\n",
            "Melhor número de tópicos segundo C_NPMI: 14\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Mostrar resultados\n",
        "for metric in metrics:\n",
        "    print(f\"\\nResultados de Coerência para {metric.upper()}:\")\n",
        "    for m, cv in zip(range(2, 30, 2), ptm_coherence_results[metric]['coherence_values']):\n",
        "        print(f\"Qtd. tópicos = {m} -> Coerência = {round(cv, 4)}\")\n",
        "    print(f\"Melhor número de tópicos segundo {metric.upper()}: {ptm_coherence_results[metric]['num_topics']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diversidade de Tópicos: 0.7286\n",
            "IRBO médio entre tópicos: 0.921\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tópico</th>\n",
              "      <th>Palavras</th>\n",
              "      <th>Pesos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>deus, todos, vamos, bolsonaro, brasil, preside...</td>\n",
              "      <td>[0.041431836783885956, 0.02248387597501278, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>reino, sobre, senhor, unido, 1, diante, eua, d...</td>\n",
              "      <td>[0.009836978279054165, 0.008336170576512814, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>grupo, liberdade, fortes, familiares, amigos, ...</td>\n",
              "      <td>[0.06820601969957352, 0.06814093887805939, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>brasil, fez, liberdade, 2, turno, povo, maior,...</td>\n",
              "      <td>[0.019763322547078133, 0.010239998809993267, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>pl, governador, senador, ptb, 22, 222, bolsona...</td>\n",
              "      <td>[0.029257144778966904, 0.014770093373954296, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>deus, porque, vida, jesus, ainda, povo, senhor...</td>\n",
              "      <td>[0.016343414783477783, 0.01142631471157074, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>bolsonaro, grupo, eleitores, 22, brasil, verda...</td>\n",
              "      <td>[0.0443139411509037, 0.040897972881793976, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>republica, stf, brasil, tribunal, militar, pod...</td>\n",
              "      <td>[0.013632675632834435, 0.010680408217012882, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>lula, brasil, pt, porque, entenderam, governo,...</td>\n",
              "      <td>[0.07856515049934387, 0.029402367770671844, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>eterno, dus, rei, bendito, nome, todos, paz, b...</td>\n",
              "      <td>[0.015613953582942486, 0.011178207583725452, 0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Tópico                                           Palavras  \\\n",
              "0       0  deus, todos, vamos, bolsonaro, brasil, preside...   \n",
              "1       1  reino, sobre, senhor, unido, 1, diante, eua, d...   \n",
              "2       2  grupo, liberdade, fortes, familiares, amigos, ...   \n",
              "3       3  brasil, fez, liberdade, 2, turno, povo, maior,...   \n",
              "4       4  pl, governador, senador, ptb, 22, 222, bolsona...   \n",
              "5       5  deus, porque, vida, jesus, ainda, povo, senhor...   \n",
              "6       6  bolsonaro, grupo, eleitores, 22, brasil, verda...   \n",
              "7       7  republica, stf, brasil, tribunal, militar, pod...   \n",
              "8       8  lula, brasil, pt, porque, entenderam, governo,...   \n",
              "9       9  eterno, dus, rei, bendito, nome, todos, paz, b...   \n",
              "\n",
              "                                               Pesos  \n",
              "0  [0.041431836783885956, 0.02248387597501278, 0....  \n",
              "1  [0.009836978279054165, 0.008336170576512814, 0...  \n",
              "2  [0.06820601969957352, 0.06814093887805939, 0.0...  \n",
              "3  [0.019763322547078133, 0.010239998809993267, 0...  \n",
              "4  [0.029257144778966904, 0.014770093373954296, 0...  \n",
              "5  [0.016343414783477783, 0.01142631471157074, 0....  \n",
              "6  [0.0443139411509037, 0.040897972881793976, 0.0...  \n",
              "7  [0.013632675632834435, 0.010680408217012882, 0...  \n",
              "8  [0.07856515049934387, 0.029402367770671844, 0....  \n",
              "9  [0.015613953582942486, 0.011178207583725452, 0...  "
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Escolha da métrica\n",
        "chosen_metric = 'c_npmi'  # ou 'c_v', 'u_mass', 'c_uci'\n",
        "\n",
        "# Obter o melhor modelo treinado\n",
        "best_index = ptm_coherence_results[chosen_metric]['coherence_values'].index(\n",
        "    max(ptm_coherence_results[chosen_metric]['coherence_values'])\n",
        ")\n",
        "best_model = ptm_coherence_results[chosen_metric]['model_list'][best_index]\n",
        "\n",
        "# Gerar DataFrame com tópicos\n",
        "def get_topics_dataframe(model, top_n=10):\n",
        "    topics_data = []\n",
        "    for topic_id in range(model.k):\n",
        "        words_probs = model.get_topic_words(topic_id, top_n=top_n)\n",
        "        topic_words = [word for word, prob in words_probs]\n",
        "        topic_probs = [prob for word, prob in words_probs]\n",
        "        topics_data.append({\n",
        "            'Tópico': topic_id,\n",
        "            'Palavras': ', '.join(topic_words),\n",
        "            'Pesos': topic_probs\n",
        "        })\n",
        "    return pd.DataFrame(topics_data)\n",
        "\n",
        "df_topicos = get_topics_dataframe(best_model)\n",
        "\n",
        "df_topicos.to_csv('./resultados_pseudo/telegram/pseudo_telegram_religioso_c_npmi.csv', index=False)\n",
        "\n",
        "div = topic_diversity(best_model)\n",
        "print(f\"Diversidade de Tópicos: {round(div, 4)}\")\n",
        "\n",
        "irbo_score = compute_irbo_ptm(best_model)\n",
        "print(f\"IRBO médio entre tópicos: {round(irbo_score, 4)}\")\n",
        "\n",
        "df_topicos.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diversidade de Tópicos: 0.7389\n",
            "IRBO médio entre tópicos: 0.9438\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tópico</th>\n",
              "      <th>Palavras</th>\n",
              "      <th>Pesos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>deus, comigo, existe, repitam, porque, entende...</td>\n",
              "      <td>[0.06948002427816391, 0.05935677886009216, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>brasil, bolsonaro, anos, outro, poder, pt, sis...</td>\n",
              "      <td>[0.014896262437105179, 0.011328891851007938, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>senhor, jesus, nome, terra, pai, eterno, paz, ...</td>\n",
              "      <td>[0.021687233820557594, 0.012458330020308495, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>pl, ptb, bolsonaro, coronel, gov, sen, tenente...</td>\n",
              "      <td>[0.047786496579647064, 0.022010289132595062, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>brasil, fez, povo, br, coisas, 10, 2, deu, men...</td>\n",
              "      <td>[0.02202051691710949, 0.014850705862045288, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>lula, brasil, pt, favor, politica, sobre, quer...</td>\n",
              "      <td>[0.08825889229774475, 0.041373442858457565, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>grupo, liberdade, patria, familia, amigos, dir...</td>\n",
              "      <td>[0.07058853656053543, 0.06960321962833405, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>grupo, bolsonaro, eleitores, 22, brasil, verda...</td>\n",
              "      <td>[0.046749044209718704, 0.04629167169332504, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>direito, manifestacao, pode, caso, todos, inte...</td>\n",
              "      <td>[0.019073396921157837, 0.015212424099445343, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>presidente, bolsonaro, estao, deus, grupos, gr...</td>\n",
              "      <td>[0.020641479641199112, 0.02041035331785679, 0....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Tópico                                           Palavras  \\\n",
              "0       0  deus, comigo, existe, repitam, porque, entende...   \n",
              "1       1  brasil, bolsonaro, anos, outro, poder, pt, sis...   \n",
              "2       2  senhor, jesus, nome, terra, pai, eterno, paz, ...   \n",
              "3       3  pl, ptb, bolsonaro, coronel, gov, sen, tenente...   \n",
              "4       4  brasil, fez, povo, br, coisas, 10, 2, deu, men...   \n",
              "5       5  lula, brasil, pt, favor, politica, sobre, quer...   \n",
              "6       6  grupo, liberdade, patria, familia, amigos, dir...   \n",
              "7       7  grupo, bolsonaro, eleitores, 22, brasil, verda...   \n",
              "8       8  direito, manifestacao, pode, caso, todos, inte...   \n",
              "9       9  presidente, bolsonaro, estao, deus, grupos, gr...   \n",
              "\n",
              "                                               Pesos  \n",
              "0  [0.06948002427816391, 0.05935677886009216, 0.0...  \n",
              "1  [0.014896262437105179, 0.011328891851007938, 0...  \n",
              "2  [0.021687233820557594, 0.012458330020308495, 0...  \n",
              "3  [0.047786496579647064, 0.022010289132595062, 0...  \n",
              "4  [0.02202051691710949, 0.014850705862045288, 0....  \n",
              "5  [0.08825889229774475, 0.041373442858457565, 0....  \n",
              "6  [0.07058853656053543, 0.06960321962833405, 0.0...  \n",
              "7  [0.046749044209718704, 0.04629167169332504, 0....  \n",
              "8  [0.019073396921157837, 0.015212424099445343, 0...  \n",
              "9  [0.020641479641199112, 0.02041035331785679, 0....  "
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Escolha da métrica\n",
        "chosen_metric = 'c_v'  # ou 'c_v', 'u_mass', 'c_uci'\n",
        "\n",
        "# Obter o melhor modelo treinado\n",
        "best_index = ptm_coherence_results[chosen_metric]['coherence_values'].index(\n",
        "    max(ptm_coherence_results[chosen_metric]['coherence_values'])\n",
        ")\n",
        "best_model = ptm_coherence_results[chosen_metric]['model_list'][best_index]\n",
        "\n",
        "# Gerar DataFrame com tópicos\n",
        "def get_topics_dataframe(model, top_n=10):\n",
        "    topics_data = []\n",
        "    for topic_id in range(model.k):\n",
        "        words_probs = model.get_topic_words(topic_id, top_n=top_n)\n",
        "        topic_words = [word for word, prob in words_probs]\n",
        "        topic_probs = [prob for word, prob in words_probs]\n",
        "        topics_data.append({\n",
        "            'Tópico': topic_id,\n",
        "            'Palavras': ', '.join(topic_words),\n",
        "            'Pesos': topic_probs\n",
        "        })\n",
        "    return pd.DataFrame(topics_data)\n",
        "\n",
        "df_topicos = get_topics_dataframe(best_model)\n",
        "\n",
        "df_topicos.to_csv('./resultados_pseudo/telegram/pseudo_telegram_religioso_c_v.csv', index=False)\n",
        "\n",
        "div = topic_diversity(best_model)\n",
        "print(f\"Diversidade de Tópicos: {round(div, 4)}\")\n",
        "\n",
        "irbo_score = compute_irbo_ptm(best_model)\n",
        "print(f\"IRBO médio entre tópicos: {round(irbo_score, 4)}\")\n",
        "\n",
        "df_topicos.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diversidade de Tópicos: 0.85\n",
            "IRBO médio entre tópicos: 0.6125\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tópico</th>\n",
              "      <th>Palavras</th>\n",
              "      <th>Pesos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>deus, todos, senhor, pode, bolsonaro, sobre, v...</td>\n",
              "      <td>[0.007684251293540001, 0.0060497550293803215, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>deus, grupo, 55, bolsonaro, brasil, liberdade,...</td>\n",
              "      <td>[0.025675015524029732, 0.013673105277121067, 0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Tópico                                           Palavras  \\\n",
              "0       0  deus, todos, senhor, pode, bolsonaro, sobre, v...   \n",
              "1       1  deus, grupo, 55, bolsonaro, brasil, liberdade,...   \n",
              "\n",
              "                                               Pesos  \n",
              "0  [0.007684251293540001, 0.0060497550293803215, ...  \n",
              "1  [0.025675015524029732, 0.013673105277121067, 0...  "
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Escolha da métrica\n",
        "chosen_metric = 'u_mass'  # ou 'c_v', 'u_mass', 'c_uci'\n",
        "\n",
        "# Obter o melhor modelo treinado\n",
        "best_index = ptm_coherence_results[chosen_metric]['coherence_values'].index(\n",
        "    max(ptm_coherence_results[chosen_metric]['coherence_values'])\n",
        ")\n",
        "best_model = ptm_coherence_results[chosen_metric]['model_list'][best_index]\n",
        "\n",
        "# Gerar DataFrame com tópicos\n",
        "def get_topics_dataframe(model, top_n=10):\n",
        "    topics_data = []\n",
        "    for topic_id in range(model.k):\n",
        "        words_probs = model.get_topic_words(topic_id, top_n=top_n)\n",
        "        topic_words = [word for word, prob in words_probs]\n",
        "        topic_probs = [prob for word, prob in words_probs]\n",
        "        topics_data.append({\n",
        "            'Tópico': topic_id,\n",
        "            'Palavras': ', '.join(topic_words),\n",
        "            'Pesos': topic_probs\n",
        "        })\n",
        "    return pd.DataFrame(topics_data)\n",
        "\n",
        "df_topicos = get_topics_dataframe(best_model)\n",
        "\n",
        "df_topicos.to_csv('./resultados_pseudo/telegram/pseudo_telegram_religioso_u_mass.csv', index=False)\n",
        "\n",
        "div = topic_diversity(best_model)\n",
        "print(f\"Diversidade de Tópicos: {round(div, 4)}\")\n",
        "\n",
        "irbo_score = compute_irbo_ptm(best_model)\n",
        "print(f\"IRBO médio entre tópicos: {round(irbo_score, 4)}\")\n",
        "\n",
        "df_topicos.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diversidade de Tópicos: 0.7286\n",
            "IRBO médio entre tópicos: 0.921\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tópico</th>\n",
              "      <th>Palavras</th>\n",
              "      <th>Pesos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>deus, todos, vamos, bolsonaro, brasil, preside...</td>\n",
              "      <td>[0.041431836783885956, 0.02248387597501278, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>reino, sobre, senhor, unido, 1, diante, eua, d...</td>\n",
              "      <td>[0.009836978279054165, 0.008336170576512814, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>grupo, liberdade, fortes, familiares, amigos, ...</td>\n",
              "      <td>[0.06820601969957352, 0.06814093887805939, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>brasil, fez, liberdade, 2, turno, povo, maior,...</td>\n",
              "      <td>[0.019763322547078133, 0.010239998809993267, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>pl, governador, senador, ptb, 22, 222, bolsona...</td>\n",
              "      <td>[0.029257144778966904, 0.014770093373954296, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>deus, porque, vida, jesus, ainda, povo, senhor...</td>\n",
              "      <td>[0.016343414783477783, 0.01142631471157074, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>bolsonaro, grupo, eleitores, 22, brasil, verda...</td>\n",
              "      <td>[0.0443139411509037, 0.040897972881793976, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>republica, stf, brasil, tribunal, militar, pod...</td>\n",
              "      <td>[0.013632675632834435, 0.010680408217012882, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>lula, brasil, pt, porque, entenderam, governo,...</td>\n",
              "      <td>[0.07856515049934387, 0.029402367770671844, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>eterno, dus, rei, bendito, nome, todos, paz, b...</td>\n",
              "      <td>[0.015613953582942486, 0.011178207583725452, 0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Tópico                                           Palavras  \\\n",
              "0       0  deus, todos, vamos, bolsonaro, brasil, preside...   \n",
              "1       1  reino, sobre, senhor, unido, 1, diante, eua, d...   \n",
              "2       2  grupo, liberdade, fortes, familiares, amigos, ...   \n",
              "3       3  brasil, fez, liberdade, 2, turno, povo, maior,...   \n",
              "4       4  pl, governador, senador, ptb, 22, 222, bolsona...   \n",
              "5       5  deus, porque, vida, jesus, ainda, povo, senhor...   \n",
              "6       6  bolsonaro, grupo, eleitores, 22, brasil, verda...   \n",
              "7       7  republica, stf, brasil, tribunal, militar, pod...   \n",
              "8       8  lula, brasil, pt, porque, entenderam, governo,...   \n",
              "9       9  eterno, dus, rei, bendito, nome, todos, paz, b...   \n",
              "\n",
              "                                               Pesos  \n",
              "0  [0.041431836783885956, 0.02248387597501278, 0....  \n",
              "1  [0.009836978279054165, 0.008336170576512814, 0...  \n",
              "2  [0.06820601969957352, 0.06814093887805939, 0.0...  \n",
              "3  [0.019763322547078133, 0.010239998809993267, 0...  \n",
              "4  [0.029257144778966904, 0.014770093373954296, 0...  \n",
              "5  [0.016343414783477783, 0.01142631471157074, 0....  \n",
              "6  [0.0443139411509037, 0.040897972881793976, 0.0...  \n",
              "7  [0.013632675632834435, 0.010680408217012882, 0...  \n",
              "8  [0.07856515049934387, 0.029402367770671844, 0....  \n",
              "9  [0.015613953582942486, 0.011178207583725452, 0...  "
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Escolha da métrica\n",
        "chosen_metric = 'c_uci'  # ou 'c_v', 'u_mass', 'c_uci'\n",
        "\n",
        "# Obter o melhor modelo treinado\n",
        "best_index = ptm_coherence_results[chosen_metric]['coherence_values'].index(\n",
        "    max(ptm_coherence_results[chosen_metric]['coherence_values'])\n",
        ")\n",
        "best_model = ptm_coherence_results[chosen_metric]['model_list'][best_index]\n",
        "\n",
        "# Gerar DataFrame com tópicos\n",
        "def get_topics_dataframe(model, top_n=10):\n",
        "    topics_data = []\n",
        "    for topic_id in range(model.k):\n",
        "        words_probs = model.get_topic_words(topic_id, top_n=top_n)\n",
        "        topic_words = [word for word, prob in words_probs]\n",
        "        topic_probs = [prob for word, prob in words_probs]\n",
        "        topics_data.append({\n",
        "            'Tópico': topic_id,\n",
        "            'Palavras': ', '.join(topic_words),\n",
        "            'Pesos': topic_probs\n",
        "        })\n",
        "    return pd.DataFrame(topics_data)\n",
        "\n",
        "df_topicos = get_topics_dataframe(best_model)\n",
        "\n",
        "df_topicos.to_csv('./resultados_pseudo/telegram/pseudo_telegram_religioso_c_uci.csv', index=False)\n",
        "\n",
        "div = topic_diversity(best_model)\n",
        "print(f\"Diversidade de Tópicos: {round(div, 4)}\")\n",
        "\n",
        "irbo_score = compute_irbo_ptm(best_model)\n",
        "print(f\"IRBO médio entre tópicos: {round(irbo_score, 4)}\")\n",
        "\n",
        "df_topicos.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modelagem de tópicos com filtros religiosos e exclusão de político"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "palavras_politicas = [ \"lula\", \"bolsonaro\", \"pt\", \"pl\", \"stf\", \"patria\", \"55\", \"22\", \"13\", \"senadores\", \"lulaladrao\",\n",
        "                       \"urnas\", \"alexandre\", \"moraes\", \"comunismo\", \"eleicao\", \"eleicoes\", \"esquerda\", \"direita\",\n",
        "                         \"presidente\", \"tse\", \"fraude\", \"voto\", \"turno\", \"ministro\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "def retirar_mensagens_com_palavras_politicas(word):\n",
        "    word_lower = word.lower()\n",
        "    palavras_politica_lower = [palavra.lower() for palavra in palavras_politicas]\n",
        "\n",
        "    return any(palavra in word_lower for palavra in palavras_politica_lower)\n",
        "\n",
        "\n",
        "df_politico = df_religiao[~df_religiao['text_processed'].apply(lambda x: retirar_mensagens_com_palavras_politicas(x))]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "texto_processado_politico = df_politico['text_processed'].apply(processar_texto)\n",
        "\n",
        "# Corpus e Dicionário (para CoherenceModel do gensim)\n",
        "id2word_politico = corpora.Dictionary(texto_processado_politico)\n",
        "corpus_politico = [id2word.doc2bow(text) for text in texto_processado_politico]\n",
        "texts_politico = texto_processado_politico.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Treinando PTModel (c_v):   0%|          | 0/14 [00:00<?, ?it/s]C:\\Users\\Melissa Felipe\\AppData\\Local\\Temp\\ipykernel_8628\\2436467606.py:10: RuntimeWarning: The training result may differ even with fixed seed if `workers` != 1.\n",
            "  model.train(100)\n",
            "Treinando PTModel (c_v): 100%|██████████| 14/14 [03:59<00:00, 17.14s/it]\n",
            "Treinando PTModel (u_mass): 100%|██████████| 14/14 [01:42<00:00,  7.31s/it]\n",
            "Treinando PTModel (c_uci): 100%|██████████| 14/14 [03:42<00:00, 15.88s/it]\n",
            "Treinando PTModel (c_npmi): 100%|██████████| 14/14 [04:05<00:00, 17.51s/it]\n"
          ]
        }
      ],
      "source": [
        "def calculate_ptm_coherence_for_metrics(texts_politico, id2word_politico, metrics, start=2, limit=30, step=2):\n",
        "    results = {}\n",
        "    for metric in metrics:\n",
        "        num_topics, model_list, coherence_values = compute_coherence_ptm(\n",
        "            texts=texts_politico,\n",
        "            id2word=id2word_politico,\n",
        "            coherence=metric,\n",
        "            start=start,\n",
        "            limit=limit,\n",
        "            step=step\n",
        "        )\n",
        "        results[metric] = {\n",
        "            'num_topics': num_topics,\n",
        "            'model_list': model_list,\n",
        "            'coherence_values': coherence_values\n",
        "        }\n",
        "    return results\n",
        "\n",
        "metrics = ['c_v', 'u_mass', 'c_uci', 'c_npmi']\n",
        "\n",
        "ptm_coherence_results = calculate_ptm_coherence_for_metrics(\n",
        "    texts_politico=texto_processado_politico.tolist(),\n",
        "    id2word_politico=id2word_politico,\n",
        "    metrics=metrics,\n",
        "    start=2,\n",
        "    limit=30,\n",
        "    step=2\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Resultados de Coerência para C_V:\n",
            "Qtd. tópicos = 2 -> Coerência = 0.4188\n",
            "Qtd. tópicos = 4 -> Coerência = 0.5263\n",
            "Qtd. tópicos = 6 -> Coerência = 0.4945\n",
            "Qtd. tópicos = 8 -> Coerência = 0.4393\n",
            "Qtd. tópicos = 10 -> Coerência = 0.4762\n",
            "Qtd. tópicos = 12 -> Coerência = 0.4929\n",
            "Qtd. tópicos = 14 -> Coerência = 0.5086\n",
            "Qtd. tópicos = 16 -> Coerência = 0.4833\n",
            "Qtd. tópicos = 18 -> Coerência = 0.5459\n",
            "Qtd. tópicos = 20 -> Coerência = 0.553\n",
            "Qtd. tópicos = 22 -> Coerência = 0.5263\n",
            "Qtd. tópicos = 24 -> Coerência = 0.4587\n",
            "Qtd. tópicos = 26 -> Coerência = 0.5217\n",
            "Qtd. tópicos = 28 -> Coerência = 0.5633\n",
            "Melhor número de tópicos segundo C_V: 28\n",
            "\n",
            "Resultados de Coerência para U_MASS:\n",
            "Qtd. tópicos = 2 -> Coerência = -3.6458\n",
            "Qtd. tópicos = 4 -> Coerência = -5.1187\n",
            "Qtd. tópicos = 6 -> Coerência = -3.2921\n",
            "Qtd. tópicos = 8 -> Coerência = -6.0459\n",
            "Qtd. tópicos = 10 -> Coerência = -5.2286\n",
            "Qtd. tópicos = 12 -> Coerência = -5.7057\n",
            "Qtd. tópicos = 14 -> Coerência = -5.1599\n",
            "Qtd. tópicos = 16 -> Coerência = -4.9454\n",
            "Qtd. tópicos = 18 -> Coerência = -4.9839\n",
            "Qtd. tópicos = 20 -> Coerência = -4.7092\n",
            "Qtd. tópicos = 22 -> Coerência = -5.0709\n",
            "Qtd. tópicos = 24 -> Coerência = -5.5637\n",
            "Qtd. tópicos = 26 -> Coerência = -5.2935\n",
            "Qtd. tópicos = 28 -> Coerência = -4.3839\n",
            "Melhor número de tópicos segundo U_MASS: 6\n",
            "\n",
            "Resultados de Coerência para C_UCI:\n",
            "Qtd. tópicos = 2 -> Coerência = -1.8253\n",
            "Qtd. tópicos = 4 -> Coerência = -2.4063\n",
            "Qtd. tópicos = 6 -> Coerência = -0.9605\n",
            "Qtd. tópicos = 8 -> Coerência = -3.1452\n",
            "Qtd. tópicos = 10 -> Coerência = -2.7785\n",
            "Qtd. tópicos = 12 -> Coerência = -2.8454\n",
            "Qtd. tópicos = 14 -> Coerência = -2.3545\n",
            "Qtd. tópicos = 16 -> Coerência = -2.7066\n",
            "Qtd. tópicos = 18 -> Coerência = -2.3071\n",
            "Qtd. tópicos = 20 -> Coerência = -2.1807\n",
            "Qtd. tópicos = 22 -> Coerência = -2.6528\n",
            "Qtd. tópicos = 24 -> Coerência = -3.1809\n",
            "Qtd. tópicos = 26 -> Coerência = -3.4266\n",
            "Qtd. tópicos = 28 -> Coerência = -2.3361\n",
            "Melhor número de tópicos segundo C_UCI: 6\n",
            "\n",
            "Resultados de Coerência para C_NPMI:\n",
            "Qtd. tópicos = 2 -> Coerência = -0.0452\n",
            "Qtd. tópicos = 4 -> Coerência = -0.0647\n",
            "Qtd. tópicos = 6 -> Coerência = 0.0245\n",
            "Qtd. tópicos = 8 -> Coerência = -0.0785\n",
            "Qtd. tópicos = 10 -> Coerência = -0.0303\n",
            "Qtd. tópicos = 12 -> Coerência = -0.0271\n",
            "Qtd. tópicos = 14 -> Coerência = -0.0095\n",
            "Qtd. tópicos = 16 -> Coerência = -0.0353\n",
            "Qtd. tópicos = 18 -> Coerência = 0.0121\n",
            "Qtd. tópicos = 20 -> Coerência = 0.0189\n",
            "Qtd. tópicos = 22 -> Coerência = 0.0013\n",
            "Qtd. tópicos = 24 -> Coerência = -0.0409\n",
            "Qtd. tópicos = 26 -> Coerência = -0.0445\n",
            "Qtd. tópicos = 28 -> Coerência = 0.0208\n",
            "Melhor número de tópicos segundo C_NPMI: 6\n"
          ]
        }
      ],
      "source": [
        "# Mostrar resultados\n",
        "for metric in metrics:\n",
        "    print(f\"\\nResultados de Coerência para {metric.upper()}:\")\n",
        "    for m, cv in zip(range(2, 30, 2), ptm_coherence_results[metric]['coherence_values']):\n",
        "        print(f\"Qtd. tópicos = {m} -> Coerência = {round(cv, 4)}\")\n",
        "    print(f\"Melhor número de tópicos segundo {metric.upper()}: {ptm_coherence_results[metric]['num_topics']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diversidade de Tópicos: 0.8333\n",
            "IRBO médio entre tópicos: 0.784\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tópico</th>\n",
              "      <th>Palavras</th>\n",
              "      <th>Pesos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>deus, obrigado, vida, nunca, hoje, porque, mim...</td>\n",
              "      <td>[0.045057445764541626, 0.01908472739160061, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>deus, povo, jesus, vamos, estao, brasil, agora...</td>\n",
              "      <td>[0.08858043700456619, 0.017645973712205887, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>deus, comigo, existe, repitam, pode, ganhar, d...</td>\n",
              "      <td>[0.16829875111579895, 0.1621929109096527, 0.15...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>deus, senhor, todos, jesus, cristo, mundo, sob...</td>\n",
              "      <td>[0.02486061304807663, 0.024773763492703438, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>deus, grupo, brasil, acima, todos, canal, irma...</td>\n",
              "      <td>[0.01701209880411625, 0.016739599406719208, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>nada, reino, amor, amem, novo, unido, frente, ...</td>\n",
              "      <td>[0.01434880681335926, 0.012644341215491295, 0....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Tópico                                           Palavras  \\\n",
              "0       0  deus, obrigado, vida, nunca, hoje, porque, mim...   \n",
              "1       1  deus, povo, jesus, vamos, estao, brasil, agora...   \n",
              "2       2  deus, comigo, existe, repitam, pode, ganhar, d...   \n",
              "3       3  deus, senhor, todos, jesus, cristo, mundo, sob...   \n",
              "4       4  deus, grupo, brasil, acima, todos, canal, irma...   \n",
              "5       5  nada, reino, amor, amem, novo, unido, frente, ...   \n",
              "\n",
              "                                               Pesos  \n",
              "0  [0.045057445764541626, 0.01908472739160061, 0....  \n",
              "1  [0.08858043700456619, 0.017645973712205887, 0....  \n",
              "2  [0.16829875111579895, 0.1621929109096527, 0.15...  \n",
              "3  [0.02486061304807663, 0.024773763492703438, 0....  \n",
              "4  [0.01701209880411625, 0.016739599406719208, 0....  \n",
              "5  [0.01434880681335926, 0.012644341215491295, 0....  "
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Escolha da métrica\n",
        "chosen_metric = 'c_npmi'  # ou 'c_v', 'u_mass', 'c_uci'\n",
        "\n",
        "# Obter o melhor modelo treinado\n",
        "best_index = ptm_coherence_results[chosen_metric]['coherence_values'].index(\n",
        "    max(ptm_coherence_results[chosen_metric]['coherence_values'])\n",
        ")\n",
        "best_model = ptm_coherence_results[chosen_metric]['model_list'][best_index]\n",
        "\n",
        "# Gerar DataFrame com tópicos\n",
        "def get_topics_dataframe(model, top_n=10):\n",
        "    topics_data = []\n",
        "    for topic_id in range(model.k):\n",
        "        words_probs = model.get_topic_words(topic_id, top_n=top_n)\n",
        "        topic_words = [word for word, prob in words_probs]\n",
        "        topic_probs = [prob for word, prob in words_probs]\n",
        "        topics_data.append({\n",
        "            'Tópico': topic_id,\n",
        "            'Palavras': ', '.join(topic_words),\n",
        "            'Pesos': topic_probs\n",
        "        })\n",
        "    return pd.DataFrame(topics_data)\n",
        "\n",
        "df_topicos = get_topics_dataframe(best_model)\n",
        "\n",
        "df_topicos.to_csv('./resultados_pseudo/telegram/pseudo_telegram_politico_c_npmi.csv', index=False)\n",
        "\n",
        "div = topic_diversity(best_model)\n",
        "print(f\"Diversidade de Tópicos: {round(div, 4)}\")\n",
        "\n",
        "irbo_score = compute_irbo_ptm(best_model)\n",
        "print(f\"IRBO médio entre tópicos: {round(irbo_score, 4)}\")\n",
        "\n",
        "df_topicos.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diversidade de Tópicos: 0.7393\n",
            "IRBO médio entre tópicos: 0.9435\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tópico</th>\n",
              "      <th>Palavras</th>\n",
              "      <th>Pesos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>general, comando, militar, bsb, adeus, chefe, ...</td>\n",
              "      <td>[0.057559117674827576, 0.03683922067284584, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>el, en, pais, brasil, su, entrada, argentina, ...</td>\n",
              "      <td>[0.025346433743834496, 0.02112249843776226, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>jesus, biblia, nunca, deus, cristo, salva, esq...</td>\n",
              "      <td>[0.06531991064548492, 0.028874173760414124, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>deus, vamos, brasil, fe, todos, fazer, vitoria...</td>\n",
              "      <td>[0.0818667858839035, 0.06584196537733078, 0.03...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>enquanto, pe, jejum, esperar, sp, dizia, envia...</td>\n",
              "      <td>[0.02156415767967701, 0.01319317426532507, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>feedback, pode, comigo, dinheiro, bot, ganhar,...</td>\n",
              "      <td>[0.041292306035757065, 0.03921627253293991, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>hoje, novo, vida, alcancar, objetivos, poder, ...</td>\n",
              "      <td>[0.059319380670785904, 0.048707686364650726, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>deus, todos, brasil, acima, pais, amor, estao,...</td>\n",
              "      <td>[0.10897503793239594, 0.03354981169104576, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>dias, deus, liberdade, familia, 15, data, ucra...</td>\n",
              "      <td>[0.050779588520526886, 0.02316383086144924, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>acima, dentro, c, s, coronel, daniel, poder, r...</td>\n",
              "      <td>[0.025962961837649345, 0.014162687584757805, 0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Tópico                                           Palavras  \\\n",
              "0       0  general, comando, militar, bsb, adeus, chefe, ...   \n",
              "1       1  el, en, pais, brasil, su, entrada, argentina, ...   \n",
              "2       2  jesus, biblia, nunca, deus, cristo, salva, esq...   \n",
              "3       3  deus, vamos, brasil, fe, todos, fazer, vitoria...   \n",
              "4       4  enquanto, pe, jejum, esperar, sp, dizia, envia...   \n",
              "5       5  feedback, pode, comigo, dinheiro, bot, ganhar,...   \n",
              "6       6  hoje, novo, vida, alcancar, objetivos, poder, ...   \n",
              "7       7  deus, todos, brasil, acima, pais, amor, estao,...   \n",
              "8       8  dias, deus, liberdade, familia, 15, data, ucra...   \n",
              "9       9  acima, dentro, c, s, coronel, daniel, poder, r...   \n",
              "\n",
              "                                               Pesos  \n",
              "0  [0.057559117674827576, 0.03683922067284584, 0....  \n",
              "1  [0.025346433743834496, 0.02112249843776226, 0....  \n",
              "2  [0.06531991064548492, 0.028874173760414124, 0....  \n",
              "3  [0.0818667858839035, 0.06584196537733078, 0.03...  \n",
              "4  [0.02156415767967701, 0.01319317426532507, 0.0...  \n",
              "5  [0.041292306035757065, 0.03921627253293991, 0....  \n",
              "6  [0.059319380670785904, 0.048707686364650726, 0...  \n",
              "7  [0.10897503793239594, 0.03354981169104576, 0.0...  \n",
              "8  [0.050779588520526886, 0.02316383086144924, 0....  \n",
              "9  [0.025962961837649345, 0.014162687584757805, 0...  "
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Escolha da métrica\n",
        "chosen_metric = 'c_v'  # ou 'c_v', 'u_mass', 'c_uci'\n",
        "\n",
        "# Obter o melhor modelo treinado\n",
        "best_index = ptm_coherence_results[chosen_metric]['coherence_values'].index(\n",
        "    max(ptm_coherence_results[chosen_metric]['coherence_values'])\n",
        ")\n",
        "best_model = ptm_coherence_results[chosen_metric]['model_list'][best_index]\n",
        "\n",
        "# Gerar DataFrame com tópicos\n",
        "def get_topics_dataframe(model, top_n=10):\n",
        "    topics_data = []\n",
        "    for topic_id in range(model.k):\n",
        "        words_probs = model.get_topic_words(topic_id, top_n=top_n)\n",
        "        topic_words = [word for word, prob in words_probs]\n",
        "        topic_probs = [prob for word, prob in words_probs]\n",
        "        topics_data.append({\n",
        "            'Tópico': topic_id,\n",
        "            'Palavras': ', '.join(topic_words),\n",
        "            'Pesos': topic_probs\n",
        "        })\n",
        "    return pd.DataFrame(topics_data)\n",
        "\n",
        "df_topicos = get_topics_dataframe(best_model)\n",
        "\n",
        "df_topicos.to_csv('./resultados_pseudo/telegram/pseudo_telegram_politico_c_v.csv', index=False)\n",
        "\n",
        "div = topic_diversity(best_model)\n",
        "print(f\"Diversidade de Tópicos: {round(div, 4)}\")\n",
        "\n",
        "irbo_score = compute_irbo_ptm(best_model)\n",
        "print(f\"IRBO médio entre tópicos: {round(irbo_score, 4)}\")\n",
        "\n",
        "df_topicos.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diversidade de Tópicos: 0.8333\n",
            "IRBO médio entre tópicos: 0.784\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tópico</th>\n",
              "      <th>Palavras</th>\n",
              "      <th>Pesos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>deus, obrigado, vida, nunca, hoje, porque, mim...</td>\n",
              "      <td>[0.045057445764541626, 0.01908472739160061, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>deus, povo, jesus, vamos, estao, brasil, agora...</td>\n",
              "      <td>[0.08858043700456619, 0.017645973712205887, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>deus, comigo, existe, repitam, pode, ganhar, d...</td>\n",
              "      <td>[0.16829875111579895, 0.1621929109096527, 0.15...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>deus, senhor, todos, jesus, cristo, mundo, sob...</td>\n",
              "      <td>[0.02486061304807663, 0.024773763492703438, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>deus, grupo, brasil, acima, todos, canal, irma...</td>\n",
              "      <td>[0.01701209880411625, 0.016739599406719208, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>nada, reino, amor, amem, novo, unido, frente, ...</td>\n",
              "      <td>[0.01434880681335926, 0.012644341215491295, 0....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Tópico                                           Palavras  \\\n",
              "0       0  deus, obrigado, vida, nunca, hoje, porque, mim...   \n",
              "1       1  deus, povo, jesus, vamos, estao, brasil, agora...   \n",
              "2       2  deus, comigo, existe, repitam, pode, ganhar, d...   \n",
              "3       3  deus, senhor, todos, jesus, cristo, mundo, sob...   \n",
              "4       4  deus, grupo, brasil, acima, todos, canal, irma...   \n",
              "5       5  nada, reino, amor, amem, novo, unido, frente, ...   \n",
              "\n",
              "                                               Pesos  \n",
              "0  [0.045057445764541626, 0.01908472739160061, 0....  \n",
              "1  [0.08858043700456619, 0.017645973712205887, 0....  \n",
              "2  [0.16829875111579895, 0.1621929109096527, 0.15...  \n",
              "3  [0.02486061304807663, 0.024773763492703438, 0....  \n",
              "4  [0.01701209880411625, 0.016739599406719208, 0....  \n",
              "5  [0.01434880681335926, 0.012644341215491295, 0....  "
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Escolha da métrica\n",
        "chosen_metric = 'u_mass'  # ou 'c_v', 'u_mass', 'c_uci'\n",
        "\n",
        "# Obter o melhor modelo treinado\n",
        "best_index = ptm_coherence_results[chosen_metric]['coherence_values'].index(\n",
        "    max(ptm_coherence_results[chosen_metric]['coherence_values'])\n",
        ")\n",
        "best_model = ptm_coherence_results[chosen_metric]['model_list'][best_index]\n",
        "\n",
        "# Gerar DataFrame com tópicos\n",
        "def get_topics_dataframe(model, top_n=10):\n",
        "    topics_data = []\n",
        "    for topic_id in range(model.k):\n",
        "        words_probs = model.get_topic_words(topic_id, top_n=top_n)\n",
        "        topic_words = [word for word, prob in words_probs]\n",
        "        topic_probs = [prob for word, prob in words_probs]\n",
        "        topics_data.append({\n",
        "            'Tópico': topic_id,\n",
        "            'Palavras': ', '.join(topic_words),\n",
        "            'Pesos': topic_probs\n",
        "        })\n",
        "    return pd.DataFrame(topics_data)\n",
        "\n",
        "df_topicos = get_topics_dataframe(best_model)\n",
        "\n",
        "df_topicos.to_csv('./resultados_pseudo/telegram/pseudo_telegram_politico_u_mass.csv', index=False)\n",
        "\n",
        "div = topic_diversity(best_model)\n",
        "print(f\"Diversidade de Tópicos: {round(div, 4)}\")\n",
        "\n",
        "irbo_score = compute_irbo_ptm(best_model)\n",
        "print(f\"IRBO médio entre tópicos: {round(irbo_score, 4)}\")\n",
        "\n",
        "df_topicos.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diversidade de Tópicos: 0.8333\n",
            "IRBO médio entre tópicos: 0.784\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tópico</th>\n",
              "      <th>Palavras</th>\n",
              "      <th>Pesos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>deus, obrigado, vida, nunca, hoje, porque, mim...</td>\n",
              "      <td>[0.045057445764541626, 0.01908472739160061, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>deus, povo, jesus, vamos, estao, brasil, agora...</td>\n",
              "      <td>[0.08858043700456619, 0.017645973712205887, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>deus, comigo, existe, repitam, pode, ganhar, d...</td>\n",
              "      <td>[0.16829875111579895, 0.1621929109096527, 0.15...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>deus, senhor, todos, jesus, cristo, mundo, sob...</td>\n",
              "      <td>[0.02486061304807663, 0.024773763492703438, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>deus, grupo, brasil, acima, todos, canal, irma...</td>\n",
              "      <td>[0.01701209880411625, 0.016739599406719208, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>nada, reino, amor, amem, novo, unido, frente, ...</td>\n",
              "      <td>[0.01434880681335926, 0.012644341215491295, 0....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Tópico                                           Palavras  \\\n",
              "0       0  deus, obrigado, vida, nunca, hoje, porque, mim...   \n",
              "1       1  deus, povo, jesus, vamos, estao, brasil, agora...   \n",
              "2       2  deus, comigo, existe, repitam, pode, ganhar, d...   \n",
              "3       3  deus, senhor, todos, jesus, cristo, mundo, sob...   \n",
              "4       4  deus, grupo, brasil, acima, todos, canal, irma...   \n",
              "5       5  nada, reino, amor, amem, novo, unido, frente, ...   \n",
              "\n",
              "                                               Pesos  \n",
              "0  [0.045057445764541626, 0.01908472739160061, 0....  \n",
              "1  [0.08858043700456619, 0.017645973712205887, 0....  \n",
              "2  [0.16829875111579895, 0.1621929109096527, 0.15...  \n",
              "3  [0.02486061304807663, 0.024773763492703438, 0....  \n",
              "4  [0.01701209880411625, 0.016739599406719208, 0....  \n",
              "5  [0.01434880681335926, 0.012644341215491295, 0....  "
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Escolha da métrica\n",
        "chosen_metric = 'c_uci'  # ou 'c_v', 'u_mass', 'c_uci'\n",
        "\n",
        "# Obter o melhor modelo treinado\n",
        "best_index = ptm_coherence_results[chosen_metric]['coherence_values'].index(\n",
        "    max(ptm_coherence_results[chosen_metric]['coherence_values'])\n",
        ")\n",
        "best_model = ptm_coherence_results[chosen_metric]['model_list'][best_index]\n",
        "\n",
        "# Gerar DataFrame com tópicos\n",
        "def get_topics_dataframe(model, top_n=10):\n",
        "    topics_data = []\n",
        "    for topic_id in range(model.k):\n",
        "        words_probs = model.get_topic_words(topic_id, top_n=top_n)\n",
        "        topic_words = [word for word, prob in words_probs]\n",
        "        topic_probs = [prob for word, prob in words_probs]\n",
        "        topics_data.append({\n",
        "            'Tópico': topic_id,\n",
        "            'Palavras': ', '.join(topic_words),\n",
        "            'Pesos': topic_probs\n",
        "        })\n",
        "    return pd.DataFrame(topics_data)\n",
        "\n",
        "df_topicos = get_topics_dataframe(best_model)\n",
        "\n",
        "df_topicos.to_csv('./resultados_pseudo/telegram/pseudo_telegram_politico_c_uci.csv', index=False)\n",
        "\n",
        "div = topic_diversity(best_model)\n",
        "print(f\"Diversidade de Tópicos: {round(div, 4)}\")\n",
        "\n",
        "irbo_score = compute_irbo_ptm(best_model)\n",
        "print(f\"IRBO médio entre tópicos: {round(irbo_score, 4)}\")\n",
        "\n",
        "df_topicos.head(10)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "topics_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
