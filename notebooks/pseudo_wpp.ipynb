{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tomotopy as tp\n",
        "from gensim import corpora\n",
        "from gensim.models import CoherenceModel\n",
        "from tqdm import tqdm\n",
        "#plot\n",
        "import matplotlib\n",
        "matplotlib.use(\"TkAgg\")  # Define o backend ANTES de importar pyplot\n",
        "\n",
        "import matplotlib.pyplot as plt  # Só importar depois de definir o backend\n",
        "\n",
        "from nltk import tokenize\n",
        "import pandas as pd\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "from unidecode import unidecode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('../datasets/fakeWhatsApp.BR_2022.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "598971"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date_message</th>\n",
              "      <th>id_member_anonymous</th>\n",
              "      <th>id_group_anonymous</th>\n",
              "      <th>media</th>\n",
              "      <th>media_type</th>\n",
              "      <th>media_url</th>\n",
              "      <th>has_media</th>\n",
              "      <th>has_media_url</th>\n",
              "      <th>trava_zap</th>\n",
              "      <th>text_content_anonymous</th>\n",
              "      <th>dataset_info_id</th>\n",
              "      <th>date_system</th>\n",
              "      <th>score_sentiment</th>\n",
              "      <th>score_misinformation</th>\n",
              "      <th>id_message</th>\n",
              "      <th>id_persona</th>\n",
              "      <th>message_type</th>\n",
              "      <th>messenger</th>\n",
              "      <th>media_name</th>\n",
              "      <th>media_md5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-10-10 18:20:24</td>\n",
              "      <td>9d737b3c9387855139bbad2311cc5709</td>\n",
              "      <td>0638569ee76dac58f59dcac20463c955</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>☝️\\nHoje que eu fique sabendo do CANAL LULA FL...</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-10-10 18:20:25.000937</td>\n",
              "      <td>-0.7003</td>\n",
              "      <td>0.843775</td>\n",
              "      <td>F7023FFB06C429A2C166922849A35ED8</td>\n",
              "      <td>558594228826.0:12@s.whatsapp.net</td>\n",
              "      <td>Texto</td>\n",
              "      <td>whatsapp</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-10-10 22:02:58</td>\n",
              "      <td>1660a60f661754d2802ca53296e25be8</td>\n",
              "      <td>a5910d5cc1c830ade9eb4dd00f15ff6a</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Mais pra que isso não aconteça nois temos quê ...</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-10-10 22:02:58.4682</td>\n",
              "      <td>-0.2960</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A9FAC78070C144890D181EF415B90CAD</td>\n",
              "      <td>558594228826.0:12@s.whatsapp.net</td>\n",
              "      <td>TextoExtendido</td>\n",
              "      <td>whatsapp</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-10-11 00:39:31</td>\n",
              "      <td>c882172d447798d74915973ac83eba68</td>\n",
              "      <td>b84dfe2d1599b82768dcdecce7e6bb23</td>\n",
              "      <td>d2e0ec59ffd9f84764f5b147725d7196.oga</td>\n",
              "      <td>audio/ogg; codecs=opus</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-10-11 00:39:33.445125</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>737948BE86D450A426470794F91BC80D</td>\n",
              "      <td>558594228826.0:12@s.whatsapp.net</td>\n",
              "      <td>Audio</td>\n",
              "      <td>whatsapp</td>\n",
              "      <td>NaN</td>\n",
              "      <td>d2e0ec59ffd9f84764f5b147725d7196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-10-10 23:36:19</td>\n",
              "      <td>91e3c22c08b24ba01ac4524d77bcb1da</td>\n",
              "      <td>addb88a34374d43aa9ecd4df7359ce39</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>‎Acesse este link para entrar no meu grupo do ...</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-10-10 23:36:19.724987</td>\n",
              "      <td>-0.1531</td>\n",
              "      <td>NaN</td>\n",
              "      <td>439A91ADD8F355CD23C4BB107A5E88BB</td>\n",
              "      <td>558594228826.0:12@s.whatsapp.net</td>\n",
              "      <td>TextoExtendido</td>\n",
              "      <td>whatsapp</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-10-10 23:40:12</td>\n",
              "      <td>77c1a8a31fee269db258a028a61f0b88</td>\n",
              "      <td>a5831b109d4d95fae8ee0ce464e48a6a</td>\n",
              "      <td>bb80cd530332bb6b95c34e719992d249.f4v</td>\n",
              "      <td>video/mp4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-10-10 23:40:14.397495</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>092203A082AC3DFB2A4933F60453AEB8</td>\n",
              "      <td>558594228826.0:12@s.whatsapp.net</td>\n",
              "      <td>Video</td>\n",
              "      <td>whatsapp</td>\n",
              "      <td>NaN</td>\n",
              "      <td>bb80cd530332bb6b95c34e719992d249</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          date_message               id_member_anonymous  \\\n",
              "0  2022-10-10 18:20:24  9d737b3c9387855139bbad2311cc5709   \n",
              "1  2022-10-10 22:02:58  1660a60f661754d2802ca53296e25be8   \n",
              "2  2022-10-11 00:39:31  c882172d447798d74915973ac83eba68   \n",
              "3  2022-10-10 23:36:19  91e3c22c08b24ba01ac4524d77bcb1da   \n",
              "4  2022-10-10 23:40:12  77c1a8a31fee269db258a028a61f0b88   \n",
              "\n",
              "                 id_group_anonymous                                 media  \\\n",
              "0  0638569ee76dac58f59dcac20463c955                                   NaN   \n",
              "1  a5910d5cc1c830ade9eb4dd00f15ff6a                                   NaN   \n",
              "2  b84dfe2d1599b82768dcdecce7e6bb23  d2e0ec59ffd9f84764f5b147725d7196.oga   \n",
              "3  addb88a34374d43aa9ecd4df7359ce39                                   NaN   \n",
              "4  a5831b109d4d95fae8ee0ce464e48a6a  bb80cd530332bb6b95c34e719992d249.f4v   \n",
              "\n",
              "               media_type media_url  has_media  has_media_url  trava_zap  \\\n",
              "0                     NaN       NaN      False          False      False   \n",
              "1                     NaN       NaN      False          False      False   \n",
              "2  audio/ogg; codecs=opus       NaN       True          False      False   \n",
              "3                     NaN       NaN      False          False      False   \n",
              "4               video/mp4       NaN       True          False      False   \n",
              "\n",
              "                              text_content_anonymous  dataset_info_id  \\\n",
              "0  ☝️\\nHoje que eu fique sabendo do CANAL LULA FL...                5   \n",
              "1  Mais pra que isso não aconteça nois temos quê ...                5   \n",
              "2                                                NaN                5   \n",
              "3  ‎Acesse este link para entrar no meu grupo do ...                5   \n",
              "4                                                NaN                5   \n",
              "\n",
              "                  date_system  score_sentiment  score_misinformation  \\\n",
              "0  2022-10-10 18:20:25.000937          -0.7003              0.843775   \n",
              "1    2022-10-10 22:02:58.4682          -0.2960                   NaN   \n",
              "2  2022-10-11 00:39:33.445125              NaN                   NaN   \n",
              "3  2022-10-10 23:36:19.724987          -0.1531                   NaN   \n",
              "4  2022-10-10 23:40:14.397495              NaN                   NaN   \n",
              "\n",
              "                         id_message                        id_persona  \\\n",
              "0  F7023FFB06C429A2C166922849A35ED8  558594228826.0:12@s.whatsapp.net   \n",
              "1  A9FAC78070C144890D181EF415B90CAD  558594228826.0:12@s.whatsapp.net   \n",
              "2  737948BE86D450A426470794F91BC80D  558594228826.0:12@s.whatsapp.net   \n",
              "3  439A91ADD8F355CD23C4BB107A5E88BB  558594228826.0:12@s.whatsapp.net   \n",
              "4  092203A082AC3DFB2A4933F60453AEB8  558594228826.0:12@s.whatsapp.net   \n",
              "\n",
              "     message_type messenger media_name                         media_md5  \n",
              "0           Texto  whatsapp        NaN                               NaN  \n",
              "1  TextoExtendido  whatsapp        NaN                               NaN  \n",
              "2           Audio  whatsapp        NaN  d2e0ec59ffd9f84764f5b147725d7196  \n",
              "3  TextoExtendido  whatsapp        NaN                               NaN  \n",
              "4           Video  whatsapp        NaN  bb80cd530332bb6b95c34e719992d249  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "ids_para_remover = ['6ef561ec0f448afcd7b3751124bb0712','d3e678a0ba0e1485548260a7c4599152',\n",
        "                    'ac5703154484de05336af617455ca55e','a39edbd64d378226ffa60433649a0acf',\n",
        "                    'c66d0d4ae5a4b281bff67e1fa4fbd6ba','819bbc872ed6d81f44d746b710eecf06',\n",
        "                    'ec94da4d54f9a5693e88fa582926be53','6a38c72316d87c028dfd66c10442476b',\n",
        "                    '94099e1e46f129856541e2b3640896d1','8f367d1693fff47218603fa47ded525c',\n",
        "                    'c09caffee0d1bd30926dea9df25dc88f']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date_message</th>\n",
              "      <th>id_member_anonymous</th>\n",
              "      <th>id_group_anonymous</th>\n",
              "      <th>media</th>\n",
              "      <th>media_type</th>\n",
              "      <th>media_url</th>\n",
              "      <th>has_media</th>\n",
              "      <th>has_media_url</th>\n",
              "      <th>trava_zap</th>\n",
              "      <th>text_content_anonymous</th>\n",
              "      <th>dataset_info_id</th>\n",
              "      <th>date_system</th>\n",
              "      <th>score_sentiment</th>\n",
              "      <th>score_misinformation</th>\n",
              "      <th>id_message</th>\n",
              "      <th>id_persona</th>\n",
              "      <th>message_type</th>\n",
              "      <th>messenger</th>\n",
              "      <th>media_name</th>\n",
              "      <th>media_md5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-10-10 18:20:24</td>\n",
              "      <td>9d737b3c9387855139bbad2311cc5709</td>\n",
              "      <td>0638569ee76dac58f59dcac20463c955</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>☝️\\nHoje que eu fique sabendo do CANAL LULA FL...</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-10-10 18:20:25.000937</td>\n",
              "      <td>-0.7003</td>\n",
              "      <td>0.843775</td>\n",
              "      <td>F7023FFB06C429A2C166922849A35ED8</td>\n",
              "      <td>558594228826.0:12@s.whatsapp.net</td>\n",
              "      <td>Texto</td>\n",
              "      <td>whatsapp</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-10-10 22:02:58</td>\n",
              "      <td>1660a60f661754d2802ca53296e25be8</td>\n",
              "      <td>a5910d5cc1c830ade9eb4dd00f15ff6a</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Mais pra que isso não aconteça nois temos quê ...</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-10-10 22:02:58.4682</td>\n",
              "      <td>-0.2960</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A9FAC78070C144890D181EF415B90CAD</td>\n",
              "      <td>558594228826.0:12@s.whatsapp.net</td>\n",
              "      <td>TextoExtendido</td>\n",
              "      <td>whatsapp</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-10-11 00:39:31</td>\n",
              "      <td>c882172d447798d74915973ac83eba68</td>\n",
              "      <td>b84dfe2d1599b82768dcdecce7e6bb23</td>\n",
              "      <td>d2e0ec59ffd9f84764f5b147725d7196.oga</td>\n",
              "      <td>audio/ogg; codecs=opus</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-10-11 00:39:33.445125</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>737948BE86D450A426470794F91BC80D</td>\n",
              "      <td>558594228826.0:12@s.whatsapp.net</td>\n",
              "      <td>Audio</td>\n",
              "      <td>whatsapp</td>\n",
              "      <td>NaN</td>\n",
              "      <td>d2e0ec59ffd9f84764f5b147725d7196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-10-10 23:36:19</td>\n",
              "      <td>91e3c22c08b24ba01ac4524d77bcb1da</td>\n",
              "      <td>addb88a34374d43aa9ecd4df7359ce39</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>‎Acesse este link para entrar no meu grupo do ...</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-10-10 23:36:19.724987</td>\n",
              "      <td>-0.1531</td>\n",
              "      <td>NaN</td>\n",
              "      <td>439A91ADD8F355CD23C4BB107A5E88BB</td>\n",
              "      <td>558594228826.0:12@s.whatsapp.net</td>\n",
              "      <td>TextoExtendido</td>\n",
              "      <td>whatsapp</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-10-10 23:40:12</td>\n",
              "      <td>77c1a8a31fee269db258a028a61f0b88</td>\n",
              "      <td>a5831b109d4d95fae8ee0ce464e48a6a</td>\n",
              "      <td>bb80cd530332bb6b95c34e719992d249.f4v</td>\n",
              "      <td>video/mp4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>2022-10-10 23:40:14.397495</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>092203A082AC3DFB2A4933F60453AEB8</td>\n",
              "      <td>558594228826.0:12@s.whatsapp.net</td>\n",
              "      <td>Video</td>\n",
              "      <td>whatsapp</td>\n",
              "      <td>NaN</td>\n",
              "      <td>bb80cd530332bb6b95c34e719992d249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>598966</th>\n",
              "      <td>2022-11-13 00:46:56</td>\n",
              "      <td>b1b419f54664f6cd4fcdb40425862d36</td>\n",
              "      <td>b1b419f54664f6cd4fcdb40425862d36</td>\n",
              "      <td>7719ba57cbe74eb5c8059d6b1a14d1ca.f4v</td>\n",
              "      <td>video/mp4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>2023-01-30 18:20:22.262572</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>08E682716448AB06DEE126A30E7AAA77</td>\n",
              "      <td>558594228826.0:17@s.whatsapp.net</td>\n",
              "      <td>Video</td>\n",
              "      <td>whatsapp</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7719ba57cbe74eb5c8059d6b1a14d1ca</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>598967</th>\n",
              "      <td>2022-11-13 13:37:03</td>\n",
              "      <td>2ad743e9ff831a75911a983b42205845</td>\n",
              "      <td>64c9a7c8ac338faa258e5aea9a1c2ae3</td>\n",
              "      <td>c6d59f0b86e63dbcce7fc682a1eaea50.f4v</td>\n",
              "      <td>video/mp4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>2023-01-30 18:20:22.269632</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3EB0259ED9B8FACF18A9</td>\n",
              "      <td>558594228826.0:17@s.whatsapp.net</td>\n",
              "      <td>Video</td>\n",
              "      <td>whatsapp</td>\n",
              "      <td>NaN</td>\n",
              "      <td>c6d59f0b86e63dbcce7fc682a1eaea50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>598968</th>\n",
              "      <td>2022-11-13 17:43:22</td>\n",
              "      <td>b1b419f54664f6cd4fcdb40425862d36</td>\n",
              "      <td>b1b419f54664f6cd4fcdb40425862d36</td>\n",
              "      <td>003ace942d9665adc9647df9d9526c0c.jpeg</td>\n",
              "      <td>image/jpeg</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>2023-01-30 18:20:22.277283</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5CD9F23CD07BEE38693E68E11F9C6A55</td>\n",
              "      <td>558594228826.0:17@s.whatsapp.net</td>\n",
              "      <td>Imagem</td>\n",
              "      <td>whatsapp</td>\n",
              "      <td>NaN</td>\n",
              "      <td>003ace942d9665adc9647df9d9526c0c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>598969</th>\n",
              "      <td>2022-11-13 21:40:47</td>\n",
              "      <td>b1b419f54664f6cd4fcdb40425862d36</td>\n",
              "      <td>b1b419f54664f6cd4fcdb40425862d36</td>\n",
              "      <td>bab5653a94b097404739a061dbbc7407.f4v</td>\n",
              "      <td>video/mp4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>2023-01-30 18:20:22.284021</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>D3BDE4A5C68E7148C0925F6C582C99A9</td>\n",
              "      <td>558594228826.0:17@s.whatsapp.net</td>\n",
              "      <td>Video</td>\n",
              "      <td>whatsapp</td>\n",
              "      <td>NaN</td>\n",
              "      <td>bab5653a94b097404739a061dbbc7407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>598970</th>\n",
              "      <td>2022-11-14 09:13:45</td>\n",
              "      <td>b1b419f54664f6cd4fcdb40425862d36</td>\n",
              "      <td>b1b419f54664f6cd4fcdb40425862d36</td>\n",
              "      <td>d3a17e60018676514372915cfc30d491.f4v</td>\n",
              "      <td>video/mp4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5</td>\n",
              "      <td>2023-01-30 18:20:22.292213</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>93FCF8B5D3AE9B9D2B996027CE930B61</td>\n",
              "      <td>558594228826.0:17@s.whatsapp.net</td>\n",
              "      <td>Video</td>\n",
              "      <td>whatsapp</td>\n",
              "      <td>NaN</td>\n",
              "      <td>d3a17e60018676514372915cfc30d491</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>597403 rows × 20 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               date_message               id_member_anonymous  \\\n",
              "0       2022-10-10 18:20:24  9d737b3c9387855139bbad2311cc5709   \n",
              "1       2022-10-10 22:02:58  1660a60f661754d2802ca53296e25be8   \n",
              "2       2022-10-11 00:39:31  c882172d447798d74915973ac83eba68   \n",
              "3       2022-10-10 23:36:19  91e3c22c08b24ba01ac4524d77bcb1da   \n",
              "4       2022-10-10 23:40:12  77c1a8a31fee269db258a028a61f0b88   \n",
              "...                     ...                               ...   \n",
              "598966  2022-11-13 00:46:56  b1b419f54664f6cd4fcdb40425862d36   \n",
              "598967  2022-11-13 13:37:03  2ad743e9ff831a75911a983b42205845   \n",
              "598968  2022-11-13 17:43:22  b1b419f54664f6cd4fcdb40425862d36   \n",
              "598969  2022-11-13 21:40:47  b1b419f54664f6cd4fcdb40425862d36   \n",
              "598970  2022-11-14 09:13:45  b1b419f54664f6cd4fcdb40425862d36   \n",
              "\n",
              "                      id_group_anonymous  \\\n",
              "0       0638569ee76dac58f59dcac20463c955   \n",
              "1       a5910d5cc1c830ade9eb4dd00f15ff6a   \n",
              "2       b84dfe2d1599b82768dcdecce7e6bb23   \n",
              "3       addb88a34374d43aa9ecd4df7359ce39   \n",
              "4       a5831b109d4d95fae8ee0ce464e48a6a   \n",
              "...                                  ...   \n",
              "598966  b1b419f54664f6cd4fcdb40425862d36   \n",
              "598967  64c9a7c8ac338faa258e5aea9a1c2ae3   \n",
              "598968  b1b419f54664f6cd4fcdb40425862d36   \n",
              "598969  b1b419f54664f6cd4fcdb40425862d36   \n",
              "598970  b1b419f54664f6cd4fcdb40425862d36   \n",
              "\n",
              "                                        media              media_type  \\\n",
              "0                                         NaN                     NaN   \n",
              "1                                         NaN                     NaN   \n",
              "2        d2e0ec59ffd9f84764f5b147725d7196.oga  audio/ogg; codecs=opus   \n",
              "3                                         NaN                     NaN   \n",
              "4        bb80cd530332bb6b95c34e719992d249.f4v               video/mp4   \n",
              "...                                       ...                     ...   \n",
              "598966   7719ba57cbe74eb5c8059d6b1a14d1ca.f4v               video/mp4   \n",
              "598967   c6d59f0b86e63dbcce7fc682a1eaea50.f4v               video/mp4   \n",
              "598968  003ace942d9665adc9647df9d9526c0c.jpeg              image/jpeg   \n",
              "598969   bab5653a94b097404739a061dbbc7407.f4v               video/mp4   \n",
              "598970   d3a17e60018676514372915cfc30d491.f4v               video/mp4   \n",
              "\n",
              "       media_url  has_media  has_media_url  trava_zap  \\\n",
              "0            NaN      False          False      False   \n",
              "1            NaN      False          False      False   \n",
              "2            NaN       True          False      False   \n",
              "3            NaN      False          False      False   \n",
              "4            NaN       True          False      False   \n",
              "...          ...        ...            ...        ...   \n",
              "598966       NaN       True          False      False   \n",
              "598967       NaN       True          False      False   \n",
              "598968       NaN       True          False      False   \n",
              "598969       NaN       True          False      False   \n",
              "598970       NaN       True          False      False   \n",
              "\n",
              "                                   text_content_anonymous  dataset_info_id  \\\n",
              "0       ☝️\\nHoje que eu fique sabendo do CANAL LULA FL...                5   \n",
              "1       Mais pra que isso não aconteça nois temos quê ...                5   \n",
              "2                                                     NaN                5   \n",
              "3       ‎Acesse este link para entrar no meu grupo do ...                5   \n",
              "4                                                     NaN                5   \n",
              "...                                                   ...              ...   \n",
              "598966                                                NaN                5   \n",
              "598967                                                NaN                5   \n",
              "598968                                                NaN                5   \n",
              "598969                                                NaN                5   \n",
              "598970                                                NaN                5   \n",
              "\n",
              "                       date_system  score_sentiment  score_misinformation  \\\n",
              "0       2022-10-10 18:20:25.000937          -0.7003              0.843775   \n",
              "1         2022-10-10 22:02:58.4682          -0.2960                   NaN   \n",
              "2       2022-10-11 00:39:33.445125              NaN                   NaN   \n",
              "3       2022-10-10 23:36:19.724987          -0.1531                   NaN   \n",
              "4       2022-10-10 23:40:14.397495              NaN                   NaN   \n",
              "...                            ...              ...                   ...   \n",
              "598966  2023-01-30 18:20:22.262572              NaN                   NaN   \n",
              "598967  2023-01-30 18:20:22.269632              NaN                   NaN   \n",
              "598968  2023-01-30 18:20:22.277283              NaN                   NaN   \n",
              "598969  2023-01-30 18:20:22.284021              NaN                   NaN   \n",
              "598970  2023-01-30 18:20:22.292213              NaN                   NaN   \n",
              "\n",
              "                              id_message                        id_persona  \\\n",
              "0       F7023FFB06C429A2C166922849A35ED8  558594228826.0:12@s.whatsapp.net   \n",
              "1       A9FAC78070C144890D181EF415B90CAD  558594228826.0:12@s.whatsapp.net   \n",
              "2       737948BE86D450A426470794F91BC80D  558594228826.0:12@s.whatsapp.net   \n",
              "3       439A91ADD8F355CD23C4BB107A5E88BB  558594228826.0:12@s.whatsapp.net   \n",
              "4       092203A082AC3DFB2A4933F60453AEB8  558594228826.0:12@s.whatsapp.net   \n",
              "...                                  ...                               ...   \n",
              "598966  08E682716448AB06DEE126A30E7AAA77  558594228826.0:17@s.whatsapp.net   \n",
              "598967              3EB0259ED9B8FACF18A9  558594228826.0:17@s.whatsapp.net   \n",
              "598968  5CD9F23CD07BEE38693E68E11F9C6A55  558594228826.0:17@s.whatsapp.net   \n",
              "598969  D3BDE4A5C68E7148C0925F6C582C99A9  558594228826.0:17@s.whatsapp.net   \n",
              "598970  93FCF8B5D3AE9B9D2B996027CE930B61  558594228826.0:17@s.whatsapp.net   \n",
              "\n",
              "          message_type messenger media_name                         media_md5  \n",
              "0                Texto  whatsapp        NaN                               NaN  \n",
              "1       TextoExtendido  whatsapp        NaN                               NaN  \n",
              "2                Audio  whatsapp        NaN  d2e0ec59ffd9f84764f5b147725d7196  \n",
              "3       TextoExtendido  whatsapp        NaN                               NaN  \n",
              "4                Video  whatsapp        NaN  bb80cd530332bb6b95c34e719992d249  \n",
              "...                ...       ...        ...                               ...  \n",
              "598966           Video  whatsapp        NaN  7719ba57cbe74eb5c8059d6b1a14d1ca  \n",
              "598967           Video  whatsapp        NaN  c6d59f0b86e63dbcce7fc682a1eaea50  \n",
              "598968          Imagem  whatsapp        NaN  003ace942d9665adc9647df9d9526c0c  \n",
              "598969           Video  whatsapp        NaN  bab5653a94b097404739a061dbbc7407  \n",
              "598970           Video  whatsapp        NaN  d3a17e60018676514372915cfc30d491  \n",
              "\n",
              "[597403 rows x 20 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Filtrar o DataFrame para remover as linhas com esses IDs\n",
        "df_filtrado = df[~df['id_member_anonymous'].isin(ids_para_remover)]\n",
        "df_filtrado"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "254480"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Removendo linhas com valores NaN na coluna 'text_content_anonymous'\n",
        "df_filtrado = df_filtrado.dropna(subset=['text_content_anonymous'])\n",
        "\n",
        "# Removendo trava_zap\n",
        "df_filtrado = df_filtrado[df_filtrado['trava_zap'] == False]\n",
        "\n",
        "\n",
        "\n",
        "#df_filtrado = df_filtrado[0:100]\n",
        "len(df_filtrado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to C:\\Users\\Melissa\n",
            "[nltk_data]     Felipe\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to C:\\Users\\Melissa\n",
            "[nltk_data]     Felipe\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to C:\\Users\\Melissa\n",
            "[nltk_data]     Felipe\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('portuguese'))\n",
        "\n",
        "custom_stopwords = {\n",
        "    't', 'be', 'nao', 'youtu', 'vai', 'av', 'ja', 'to', 'the', 'this', 'i', 'and', \n",
        "    'you', 'y', 'www', 'sao', 'pois', 'contra', 'user', 'ai', 'so', 'gente', 'voce', 'of', \n",
        "    'ola', 'gift', 'card', 'kwaivideo', 'r', 'bom', 'q', 'vc', 'vcs', 'pra','ta', 'phone', 'ok', 'la',\n",
        "    'sera', 'ha', 'aqui', 'ate', 'dia', 'mc', 'im', 'tmj', 'pix', 'g', 'diz', 'ti', 'etc', 'tudo', \n",
        "    'todo', 'toda', 'youtube', 'g1', 'm', 'instagram', 'fb', 'in', 'link', 'was', 'blocked', 'kk'\n",
        "}\n",
        "\n",
        "stop_words.update(custom_stopwords)\n",
        "\n",
        "def preprocess_text(text):\n",
        "\n",
        "    # Função para extrair e substituir o domínio da URL\n",
        "    def substituir_dominios(texto):\n",
        "        # Função para extrair e substituir o domínio da URL\n",
        "        def extrair_dominio(url):\n",
        "            # Remove o protocolo (http://, https://, etc.) e o \"www.\" se presente\n",
        "            dominio = re.sub(r'^https?://(?:www\\.)?|www\\.', '', url)\n",
        "            # Remove o caminho e parâmetros da URL\n",
        "            dominio = re.split(r'[/?#]', dominio)[0]\n",
        "            # Retorna a parte principal do domínio (antes do primeiro ponto)\n",
        "            return dominio.split('.')[0]\n",
        "\n",
        "        # Substitui URLs por seus domínios principais\n",
        "        return re.sub(r'https?://(?:www\\.)?\\S+|www\\.\\S+', lambda match: extrair_dominio(match.group(0)), texto)\n",
        "\n",
        "    # Substituir domínios\n",
        "    text = substituir_dominios(text)\n",
        "\n",
        "    # Converte para minúsculas\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove acentos\n",
        "    text = unidecode(text)\n",
        "\n",
        "    #Remover Pontuação\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    # Remove URLs e menções\n",
        "    #text = re.sub(r'http\\S+|www\\S+|https\\S+|@\\w+', '', text)\n",
        "\n",
        "    # Substitui emojis repetidos por apenas um\n",
        "    text = re.sub(r'([\\U00010000-\\U0010FFFF])\\1+', r'\\1', text)\n",
        "    text = re.sub(r'([\\U0001F600-\\U0001F64F]|[\\U0001F300-\\U0001F5FF]|[\\U0001F680-\\U0001F6FF]|[\\U0001F700-\\U0001F77F]|[\\U0001F780-\\U0001F7FF]|[\\U0001F800-\\U0001F8FF]|[\\U0001F900-\\U0001F9FF]|[\\U0001FA00-\\U0001FA6F]|[\\U0001FA70-\\U0001FAFF])\\1+', r'\\1', text)\n",
        "\n",
        "\n",
        "    # Remove espaços em branco extras (início ou final) e múltiplos espaços no meio do texto\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # Remove pontuações e caracteres especiais\n",
        "    #text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    # Ajusta risadas \"kkk\" ou mais para \"kk\"\n",
        "    text = re.sub(r'k{2,}|K{2,}', 'kk', text)\n",
        "\n",
        "    # Ajusta risadas \"haha\" ou mais para \"haha\"\n",
        "    text = re.sub(r'(ha){2,}', 'haha', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Ajusta risadas \"kaka\" ou mais para \"kaka\"\n",
        "    text = re.sub(r'(ka){2,}', 'kaka', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Remove as stopwords\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
        "\n",
        "\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date_message</th>\n",
              "      <th>id_member_anonymous</th>\n",
              "      <th>id_group_anonymous</th>\n",
              "      <th>media</th>\n",
              "      <th>media_type</th>\n",
              "      <th>media_url</th>\n",
              "      <th>has_media</th>\n",
              "      <th>has_media_url</th>\n",
              "      <th>trava_zap</th>\n",
              "      <th>text_content_anonymous</th>\n",
              "      <th>...</th>\n",
              "      <th>date_system</th>\n",
              "      <th>score_sentiment</th>\n",
              "      <th>score_misinformation</th>\n",
              "      <th>id_message</th>\n",
              "      <th>id_persona</th>\n",
              "      <th>message_type</th>\n",
              "      <th>messenger</th>\n",
              "      <th>media_name</th>\n",
              "      <th>media_md5</th>\n",
              "      <th>text_processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-10-10 18:20:24</td>\n",
              "      <td>9d737b3c9387855139bbad2311cc5709</td>\n",
              "      <td>0638569ee76dac58f59dcac20463c955</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>☝️\\nHoje que eu fique sabendo do CANAL LULA FL...</td>\n",
              "      <td>...</td>\n",
              "      <td>2022-10-10 18:20:25.000937</td>\n",
              "      <td>-0.7003</td>\n",
              "      <td>0.843775</td>\n",
              "      <td>F7023FFB06C429A2C166922849A35ED8</td>\n",
              "      <td>558594228826.0:12@s.whatsapp.net</td>\n",
              "      <td>Texto</td>\n",
              "      <td>whatsapp</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>hoje fique sabendo canal lula flix vi pt entro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-10-10 22:02:58</td>\n",
              "      <td>1660a60f661754d2802ca53296e25be8</td>\n",
              "      <td>a5910d5cc1c830ade9eb4dd00f15ff6a</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Mais pra que isso não aconteça nois temos quê ...</td>\n",
              "      <td>...</td>\n",
              "      <td>2022-10-10 22:02:58.4682</td>\n",
              "      <td>-0.2960</td>\n",
              "      <td>NaN</td>\n",
              "      <td>A9FAC78070C144890D181EF415B90CAD</td>\n",
              "      <td>558594228826.0:12@s.whatsapp.net</td>\n",
              "      <td>TextoExtendido</td>\n",
              "      <td>whatsapp</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>aconteca nois fazer anossa parte</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-10-10 23:36:19</td>\n",
              "      <td>91e3c22c08b24ba01ac4524d77bcb1da</td>\n",
              "      <td>addb88a34374d43aa9ecd4df7359ce39</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>‎Acesse este link para entrar no meu grupo do ...</td>\n",
              "      <td>...</td>\n",
              "      <td>2022-10-10 23:36:19.724987</td>\n",
              "      <td>-0.1531</td>\n",
              "      <td>NaN</td>\n",
              "      <td>439A91ADD8F355CD23C4BB107A5E88BB</td>\n",
              "      <td>558594228826.0:12@s.whatsapp.net</td>\n",
              "      <td>TextoExtendido</td>\n",
              "      <td>whatsapp</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>acesse entrar grupo whatsapp chat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2022-10-10 16:49:48</td>\n",
              "      <td>325720ed3339a91b8076df12c1e95c45</td>\n",
              "      <td>0e345813dcb62b0fe4d8537f311af0f1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://m.kwai.com/photo/150000006567403/52240...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>Fortes palavras da Pastora Damares!\\nhttps://k...</td>\n",
              "      <td>...</td>\n",
              "      <td>2022-10-10 16:49:50.051126</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>F18BADED5AFA8FB0C33FE36625872DB8</td>\n",
              "      <td>558594228826.0:12@s.whatsapp.net</td>\n",
              "      <td>TextoExtendido</td>\n",
              "      <td>whatsapp</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>fortes palavras pastora damares</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2022-10-10 16:49:53</td>\n",
              "      <td>8ed44a70a011285622e2b8919c2c8c3e</td>\n",
              "      <td>3b3e64e81c3e3f3bfc5ba76ddb90fb2d</td>\n",
              "      <td>0d6f2896e5941ef1933e69bbd7a32f69.jpeg</td>\n",
              "      <td>image/jpeg</td>\n",
              "      <td>NaN</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>🤣🤣🤣🤣🤣🤣🤣🤣</td>\n",
              "      <td>...</td>\n",
              "      <td>2022-10-10 16:49:54.713831</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>724C233591C3A62A5231B47FF22ADE4B</td>\n",
              "      <td>558594228826.0:12@s.whatsapp.net</td>\n",
              "      <td>Imagem</td>\n",
              "      <td>whatsapp</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0d6f2896e5941ef1933e69bbd7a32f69</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          date_message               id_member_anonymous  \\\n",
              "0  2022-10-10 18:20:24  9d737b3c9387855139bbad2311cc5709   \n",
              "1  2022-10-10 22:02:58  1660a60f661754d2802ca53296e25be8   \n",
              "3  2022-10-10 23:36:19  91e3c22c08b24ba01ac4524d77bcb1da   \n",
              "7  2022-10-10 16:49:48  325720ed3339a91b8076df12c1e95c45   \n",
              "8  2022-10-10 16:49:53  8ed44a70a011285622e2b8919c2c8c3e   \n",
              "\n",
              "                 id_group_anonymous                                  media  \\\n",
              "0  0638569ee76dac58f59dcac20463c955                                    NaN   \n",
              "1  a5910d5cc1c830ade9eb4dd00f15ff6a                                    NaN   \n",
              "3  addb88a34374d43aa9ecd4df7359ce39                                    NaN   \n",
              "7  0e345813dcb62b0fe4d8537f311af0f1                                    NaN   \n",
              "8  3b3e64e81c3e3f3bfc5ba76ddb90fb2d  0d6f2896e5941ef1933e69bbd7a32f69.jpeg   \n",
              "\n",
              "   media_type                                          media_url  has_media  \\\n",
              "0         NaN                                                NaN      False   \n",
              "1         NaN                                                NaN      False   \n",
              "3         NaN                                                NaN      False   \n",
              "7         NaN  https://m.kwai.com/photo/150000006567403/52240...      False   \n",
              "8  image/jpeg                                                NaN       True   \n",
              "\n",
              "   has_media_url  trava_zap  \\\n",
              "0          False      False   \n",
              "1          False      False   \n",
              "3          False      False   \n",
              "7           True      False   \n",
              "8          False      False   \n",
              "\n",
              "                              text_content_anonymous  ...  \\\n",
              "0  ☝️\\nHoje que eu fique sabendo do CANAL LULA FL...  ...   \n",
              "1  Mais pra que isso não aconteça nois temos quê ...  ...   \n",
              "3  ‎Acesse este link para entrar no meu grupo do ...  ...   \n",
              "7  Fortes palavras da Pastora Damares!\\nhttps://k...  ...   \n",
              "8                                           🤣🤣🤣🤣🤣🤣🤣🤣  ...   \n",
              "\n",
              "                  date_system score_sentiment  score_misinformation  \\\n",
              "0  2022-10-10 18:20:25.000937         -0.7003              0.843775   \n",
              "1    2022-10-10 22:02:58.4682         -0.2960                   NaN   \n",
              "3  2022-10-10 23:36:19.724987         -0.1531                   NaN   \n",
              "7  2022-10-10 16:49:50.051126          0.0000                   NaN   \n",
              "8  2022-10-10 16:49:54.713831          0.0000                   NaN   \n",
              "\n",
              "                         id_message                        id_persona  \\\n",
              "0  F7023FFB06C429A2C166922849A35ED8  558594228826.0:12@s.whatsapp.net   \n",
              "1  A9FAC78070C144890D181EF415B90CAD  558594228826.0:12@s.whatsapp.net   \n",
              "3  439A91ADD8F355CD23C4BB107A5E88BB  558594228826.0:12@s.whatsapp.net   \n",
              "7  F18BADED5AFA8FB0C33FE36625872DB8  558594228826.0:12@s.whatsapp.net   \n",
              "8  724C233591C3A62A5231B47FF22ADE4B  558594228826.0:12@s.whatsapp.net   \n",
              "\n",
              "     message_type messenger media_name                         media_md5  \\\n",
              "0           Texto  whatsapp        NaN                               NaN   \n",
              "1  TextoExtendido  whatsapp        NaN                               NaN   \n",
              "3  TextoExtendido  whatsapp        NaN                               NaN   \n",
              "7  TextoExtendido  whatsapp        NaN                               NaN   \n",
              "8          Imagem  whatsapp        NaN  0d6f2896e5941ef1933e69bbd7a32f69   \n",
              "\n",
              "                                      text_processed  \n",
              "0  hoje fique sabendo canal lula flix vi pt entro...  \n",
              "1                   aconteca nois fazer anossa parte  \n",
              "3                  acesse entrar grupo whatsapp chat  \n",
              "7                    fortes palavras pastora damares  \n",
              "8                                                     \n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "df_geral = df_filtrado.copy()\n",
        "\n",
        "# Aplicar o pré-processamento à coluna de texto\n",
        "df_geral['text_processed'] = df_geral['text_content_anonymous'].apply(preprocess_text)\n",
        "df_geral.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calculando a diversidade dos tópicos\n",
        "A diversidade de tópicos mede quantas palavras únicas existem entre os top-N termos de todos os tópicos. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def topic_diversity(model, top_n=10):\n",
        "    topic_words = []\n",
        "    for k in range(model.k):  \n",
        "        words = [word for word, _ in model.get_topic_words(k, top_n=top_n)]  \n",
        "        topic_words.extend(words)\n",
        "    unique_words = set(topic_words)\n",
        "    return len(unique_words) / (top_n * model.k)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### IRBO \n",
        "\n",
        "IRBO avalia quanto os tópicos são distintos entre si, usando o Rank-Biased Overlap (RBO) invertido. Quanto maior o IRBO, mais diferentes são os tópicos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import rbo\n",
        "\n",
        "def compute_irbo_ptm(model, top_n=10):\n",
        "    topics = []\n",
        "    for k in range(model.k):\n",
        "        topic_terms = [word for word, _ in model.get_topic_words(k, top_n=top_n)]\n",
        "        topics.append(topic_terms)\n",
        "\n",
        "    n = len(topics)\n",
        "    total_irbo = 0\n",
        "    count = 0\n",
        "\n",
        "    for i in range(n):\n",
        "        for j in range(i + 1, n):\n",
        "            rbo_score = rbo.RankingSimilarity(topics[i], topics[j]).rbo()\n",
        "            total_irbo += (1 - rbo_score)  # IRBO = 1 - RBO\n",
        "            count += 1\n",
        "\n",
        "    return total_irbo / count if count > 0 else 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Processamento\n",
        "token_espaco = tokenize.WhitespaceTokenizer()\n",
        "token_pontuacao = tokenize.WordPunctTokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_coherence_ptm(texts, id2word, coherence, start=2, limit=30, step=2):\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    topic_range = list(range(start, limit, step))\n",
        "\n",
        "    for num_topics in tqdm(topic_range, desc=f\"Treinando PTModel ({coherence})\"):\n",
        "        model = tp.PTModel(k=num_topics, seed=42)\n",
        "        for doc in texts:\n",
        "            model.add_doc(doc)\n",
        "        model.train(100)\n",
        "        model_list.append(model)\n",
        "\n",
        "        # Coherence do gensim precisa de tópicos no formato: lista de listas de palavras\n",
        "        topics = []\n",
        "        for k in range(model.k):\n",
        "            topic_words = [word for word, _ in model.get_topic_words(k, top_n=10)]\n",
        "            topics.append(topic_words)\n",
        "\n",
        "        coh_model = CoherenceModel(topics=topics, texts=texts, dictionary=id2word, coherence=coherence)\n",
        "        coherence_score = coh_model.get_coherence()\n",
        "        coherence_values.append(coherence_score)\n",
        "\n",
        "    optimal_index = coherence_values.index(max(coherence_values))\n",
        "    optimal_num_topics = topic_range[optimal_index]\n",
        "\n",
        "    return optimal_num_topics, model_list, coherence_values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def processar_texto(texto):\n",
        "    texto = texto.lower()\n",
        "    palavras_texto = token_espaco.tokenize(texto)\n",
        "    palavras_texto = token_pontuacao.tokenize(' '.join(palavras_texto))\n",
        "    return [palavra for palavra in palavras_texto]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modelando os Tópicos sem filtro "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "texto_processado = df_geral['text_processed'].apply(processar_texto)\n",
        "\n",
        "# Corpus e Dicionário (para CoherenceModel do gensim)\n",
        "id2word = corpora.Dictionary(texto_processado)\n",
        "corpus = [id2word.doc2bow(text) for text in texto_processado]\n",
        "texts = texto_processado.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Treinando PTModel (c_v):   0%|          | 0/14 [00:00<?, ?it/s]C:\\Users\\Melissa Felipe\\AppData\\Local\\Temp\\ipykernel_26484\\2436467606.py:10: RuntimeWarning: The training result may differ even with fixed seed if `workers` != 1.\n",
            "  model.train(100)\n",
            "Treinando PTModel (c_v): 100%|██████████| 14/14 [27:59<00:00, 119.94s/it]\n",
            "Treinando PTModel (u_mass): 100%|██████████| 14/14 [29:39<00:00, 127.08s/it]\n",
            "Treinando PTModel (c_uci): 100%|██████████| 14/14 [37:58<00:00, 162.74s/it]\n",
            "Treinando PTModel (c_npmi): 100%|██████████| 14/14 [33:42<00:00, 144.47s/it]\n"
          ]
        }
      ],
      "source": [
        "def calculate_ptm_coherence_for_metrics(texts, id2word, metrics, start=2, limit=30, step=2):\n",
        "    results = {}\n",
        "    for metric in metrics:\n",
        "        num_topics, model_list, coherence_values = compute_coherence_ptm(\n",
        "            texts=texts,\n",
        "            id2word=id2word,\n",
        "            coherence=metric,\n",
        "            start=start,\n",
        "            limit=limit,\n",
        "            step=step\n",
        "        )\n",
        "        results[metric] = {\n",
        "            'num_topics': num_topics,\n",
        "            'model_list': model_list,\n",
        "            'coherence_values': coherence_values\n",
        "        }\n",
        "    return results\n",
        "\n",
        "metrics = ['c_v', 'u_mass', 'c_uci', 'c_npmi']\n",
        "\n",
        "ptm_coherence_results = calculate_ptm_coherence_for_metrics(\n",
        "    texts=texto_processado.tolist(),\n",
        "    id2word=id2word,\n",
        "    metrics=metrics,\n",
        "    start=2,\n",
        "    limit=30,\n",
        "    step=2\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Resultados de Coerência para C_V:\n",
            "Qtd. tópicos = 2 -> Coerência = 0.4838\n",
            "Qtd. tópicos = 4 -> Coerência = 0.4564\n",
            "Qtd. tópicos = 6 -> Coerência = 0.4733\n",
            "Qtd. tópicos = 8 -> Coerência = 0.5115\n",
            "Qtd. tópicos = 10 -> Coerência = 0.5222\n",
            "Qtd. tópicos = 12 -> Coerência = 0.511\n",
            "Qtd. tópicos = 14 -> Coerência = 0.5195\n",
            "Qtd. tópicos = 16 -> Coerência = 0.5575\n",
            "Qtd. tópicos = 18 -> Coerência = 0.4994\n",
            "Qtd. tópicos = 20 -> Coerência = 0.5579\n",
            "Qtd. tópicos = 22 -> Coerência = 0.548\n",
            "Qtd. tópicos = 24 -> Coerência = 0.5455\n",
            "Qtd. tópicos = 26 -> Coerência = 0.5716\n",
            "Qtd. tópicos = 28 -> Coerência = 0.5514\n",
            "Melhor número de tópicos segundo C_V: 26\n",
            "\n",
            "Resultados de Coerência para U_MASS:\n",
            "Qtd. tópicos = 2 -> Coerência = -5.1244\n",
            "Qtd. tópicos = 4 -> Coerência = -7.8644\n",
            "Qtd. tópicos = 6 -> Coerência = -5.4186\n",
            "Qtd. tópicos = 8 -> Coerência = -4.7261\n",
            "Qtd. tópicos = 10 -> Coerência = -5.14\n",
            "Qtd. tópicos = 12 -> Coerência = -5.0656\n",
            "Qtd. tópicos = 14 -> Coerência = -4.6248\n",
            "Qtd. tópicos = 16 -> Coerência = -3.907\n",
            "Qtd. tópicos = 18 -> Coerência = -4.23\n",
            "Qtd. tópicos = 20 -> Coerência = -3.549\n",
            "Qtd. tópicos = 22 -> Coerência = -3.9227\n",
            "Qtd. tópicos = 24 -> Coerência = -3.3206\n",
            "Qtd. tópicos = 26 -> Coerência = -3.5411\n",
            "Qtd. tópicos = 28 -> Coerência = -3.8597\n",
            "Melhor número de tópicos segundo U_MASS: 24\n",
            "\n",
            "Resultados de Coerência para C_UCI:\n",
            "Qtd. tópicos = 2 -> Coerência = -5.8344\n",
            "Qtd. tópicos = 4 -> Coerência = -6.1919\n",
            "Qtd. tópicos = 6 -> Coerência = -3.9677\n",
            "Qtd. tópicos = 8 -> Coerência = -4.2738\n",
            "Qtd. tópicos = 10 -> Coerência = -3.7024\n",
            "Qtd. tópicos = 12 -> Coerência = -3.722\n",
            "Qtd. tópicos = 14 -> Coerência = -2.916\n",
            "Qtd. tópicos = 16 -> Coerência = -2.4571\n",
            "Qtd. tópicos = 18 -> Coerência = -2.4708\n",
            "Qtd. tópicos = 20 -> Coerência = -1.7799\n",
            "Qtd. tópicos = 22 -> Coerência = -2.1309\n",
            "Qtd. tópicos = 24 -> Coerência = -1.9386\n",
            "Qtd. tópicos = 26 -> Coerência = -1.834\n",
            "Qtd. tópicos = 28 -> Coerência = -1.9489\n",
            "Melhor número de tópicos segundo C_UCI: 20\n",
            "\n",
            "Resultados de Coerência para C_NPMI:\n",
            "Qtd. tópicos = 2 -> Coerência = -0.2155\n",
            "Qtd. tópicos = 4 -> Coerência = -0.2073\n",
            "Qtd. tópicos = 6 -> Coerência = -0.1146\n",
            "Qtd. tópicos = 8 -> Coerência = -0.1178\n",
            "Qtd. tópicos = 10 -> Coerência = -0.0538\n",
            "Qtd. tópicos = 12 -> Coerência = -0.0802\n",
            "Qtd. tópicos = 14 -> Coerência = -0.041\n",
            "Qtd. tópicos = 16 -> Coerência = -0.0095\n",
            "Qtd. tópicos = 18 -> Coerência = -0.0187\n",
            "Qtd. tópicos = 20 -> Coerência = 0.0065\n",
            "Qtd. tópicos = 22 -> Coerência = -0.0014\n",
            "Qtd. tópicos = 24 -> Coerência = -0.0029\n",
            "Qtd. tópicos = 26 -> Coerência = 0.0104\n",
            "Qtd. tópicos = 28 -> Coerência = -0.0038\n",
            "Melhor número de tópicos segundo C_NPMI: 26\n"
          ]
        }
      ],
      "source": [
        "# Mostrar resultados\n",
        "for metric in metrics:\n",
        "    print(f\"\\nResultados de Coerência para {metric.upper()}:\")\n",
        "    for m, cv in zip(range(2, 30, 2), ptm_coherence_results[metric]['coherence_values']):\n",
        "        print(f\"Qtd. tópicos = {m} -> Coerência = {round(cv, 4)}\")\n",
        "    print(f\"Melhor número de tópicos segundo {metric.upper()}: {ptm_coherence_results[metric]['num_topics']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tópico</th>\n",
              "      <th>Palavras</th>\n",
              "      <th>Pesos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>99999999999999, excluir, studio, grupo, adm, b...</td>\n",
              "      <td>[0.7779877185821533, 0.02684282884001732, 0.02...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>lula, bolsonaro, moraes, todos, alexandre, vol...</td>\n",
              "      <td>[0.016064640134572983, 0.012980114668607712, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>pag, pt, emprestimo, item, todos, entrada, 160...</td>\n",
              "      <td>[0.011205372400581837, 0.010022246278822422, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>bocahomens, cagando, bosta, carae, vomitando, ...</td>\n",
              "      <td>[0.18525643646717072, 0.13916648924350739, 0.1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>bolsonaro, todos, povo, estados, presidente, r...</td>\n",
              "      <td>[0.010354984551668167, 0.007956349290907383, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>lula, proibido, dizer, tse, sobre, pt, stf, br...</td>\n",
              "      <td>[0.17831216752529144, 0.0439273975789547, 0.03...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>55, 20, 1, 91, 92, 127, 155, 111, 128, 101</td>\n",
              "      <td>[0.23404990136623383, 0.062362492084503174, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>terrabrasilnoticias, stf, estao, presidente, p...</td>\n",
              "      <td>[0.008691192604601383, 0.00766870379447937, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>8l8l8l8l8l8l8l8l8l8lli, brasil, fez, revolta, ...</td>\n",
              "      <td>[0.013670983724296093, 0.011046798899769783, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>gazetabrasil, anos, noticias, 2022, brasil, ap...</td>\n",
              "      <td>[0.012686355970799923, 0.00932218600064516, 0....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Tópico                                           Palavras  \\\n",
              "0       0  99999999999999, excluir, studio, grupo, adm, b...   \n",
              "1       1  lula, bolsonaro, moraes, todos, alexandre, vol...   \n",
              "2       2  pag, pt, emprestimo, item, todos, entrada, 160...   \n",
              "3       3  bocahomens, cagando, bosta, carae, vomitando, ...   \n",
              "4       4  bolsonaro, todos, povo, estados, presidente, r...   \n",
              "5       5  lula, proibido, dizer, tse, sobre, pt, stf, br...   \n",
              "6       6         55, 20, 1, 91, 92, 127, 155, 111, 128, 101   \n",
              "7       7  terrabrasilnoticias, stf, estao, presidente, p...   \n",
              "8       8  8l8l8l8l8l8l8l8l8l8lli, brasil, fez, revolta, ...   \n",
              "9       9  gazetabrasil, anos, noticias, 2022, brasil, ap...   \n",
              "\n",
              "                                               Pesos  \n",
              "0  [0.7779877185821533, 0.02684282884001732, 0.02...  \n",
              "1  [0.016064640134572983, 0.012980114668607712, 0...  \n",
              "2  [0.011205372400581837, 0.010022246278822422, 0...  \n",
              "3  [0.18525643646717072, 0.13916648924350739, 0.1...  \n",
              "4  [0.010354984551668167, 0.007956349290907383, 0...  \n",
              "5  [0.17831216752529144, 0.0439273975789547, 0.03...  \n",
              "6  [0.23404990136623383, 0.062362492084503174, 0....  \n",
              "7  [0.008691192604601383, 0.00766870379447937, 0....  \n",
              "8  [0.013670983724296093, 0.011046798899769783, 0...  \n",
              "9  [0.012686355970799923, 0.00932218600064516, 0....  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Escolha da métrica\n",
        "chosen_metric = 'c_npmi'  # ou 'c_v', 'u_mass', 'c_uci'\n",
        "\n",
        "# Obter o melhor modelo treinado\n",
        "best_index = ptm_coherence_results[chosen_metric]['coherence_values'].index(\n",
        "    max(ptm_coherence_results[chosen_metric]['coherence_values'])\n",
        ")\n",
        "best_model = ptm_coherence_results[chosen_metric]['model_list'][best_index]\n",
        "\n",
        "# Gerar DataFrame com tópicos\n",
        "def get_topics_dataframe(model, top_n=10):\n",
        "    topics_data = []\n",
        "    for topic_id in range(model.k):\n",
        "        words_probs = model.get_topic_words(topic_id, top_n=top_n)\n",
        "        topic_words = [word for word, prob in words_probs]\n",
        "        topic_probs = [prob for word, prob in words_probs]\n",
        "        topics_data.append({\n",
        "            'Tópico': topic_id,\n",
        "            'Palavras': ', '.join(topic_words),\n",
        "            'Pesos': topic_probs\n",
        "        })\n",
        "    return pd.DataFrame(topics_data)\n",
        "\n",
        "df_topicos = get_topics_dataframe(best_model)\n",
        "\n",
        "df_topicos.to_csv('./resultados_pseudo/wpp/pseudo_wpp_c_npmi.csv', index=False)\n",
        "df_topicos.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diversidade de Tópicos: 0.7808\n",
            "IRBO médio entre tópicos: 0.9591\n"
          ]
        }
      ],
      "source": [
        "div = topic_diversity(best_model)\n",
        "print(f\"Diversidade de Tópicos: {round(div, 4)}\")\n",
        "\n",
        "irbo_score = compute_irbo_ptm(best_model)\n",
        "print(f\"IRBO médio entre tópicos: {round(irbo_score, 4)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tópico</th>\n",
              "      <th>Palavras</th>\n",
              "      <th>Pesos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>99999999999999, excluir, studio, grupo, adm, b...</td>\n",
              "      <td>[0.7779877185821533, 0.02684282884001732, 0.02...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>lula, bolsonaro, moraes, todos, alexandre, vol...</td>\n",
              "      <td>[0.016064640134572983, 0.012980114668607712, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>pag, pt, emprestimo, item, todos, entrada, 160...</td>\n",
              "      <td>[0.011205372400581837, 0.010022246278822422, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>bocahomens, cagando, bosta, carae, vomitando, ...</td>\n",
              "      <td>[0.18525643646717072, 0.13916648924350739, 0.1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>bolsonaro, todos, povo, estados, presidente, r...</td>\n",
              "      <td>[0.010354984551668167, 0.007956349290907383, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>lula, proibido, dizer, tse, sobre, pt, stf, br...</td>\n",
              "      <td>[0.17831216752529144, 0.0439273975789547, 0.03...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>55, 20, 1, 91, 92, 127, 155, 111, 128, 101</td>\n",
              "      <td>[0.23404990136623383, 0.062362492084503174, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>terrabrasilnoticias, stf, estao, presidente, p...</td>\n",
              "      <td>[0.008691192604601383, 0.00766870379447937, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>8l8l8l8l8l8l8l8l8l8lli, brasil, fez, revolta, ...</td>\n",
              "      <td>[0.013670983724296093, 0.011046798899769783, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>gazetabrasil, anos, noticias, 2022, brasil, ap...</td>\n",
              "      <td>[0.012686355970799923, 0.00932218600064516, 0....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Tópico                                           Palavras  \\\n",
              "0       0  99999999999999, excluir, studio, grupo, adm, b...   \n",
              "1       1  lula, bolsonaro, moraes, todos, alexandre, vol...   \n",
              "2       2  pag, pt, emprestimo, item, todos, entrada, 160...   \n",
              "3       3  bocahomens, cagando, bosta, carae, vomitando, ...   \n",
              "4       4  bolsonaro, todos, povo, estados, presidente, r...   \n",
              "5       5  lula, proibido, dizer, tse, sobre, pt, stf, br...   \n",
              "6       6         55, 20, 1, 91, 92, 127, 155, 111, 128, 101   \n",
              "7       7  terrabrasilnoticias, stf, estao, presidente, p...   \n",
              "8       8  8l8l8l8l8l8l8l8l8l8lli, brasil, fez, revolta, ...   \n",
              "9       9  gazetabrasil, anos, noticias, 2022, brasil, ap...   \n",
              "\n",
              "                                               Pesos  \n",
              "0  [0.7779877185821533, 0.02684282884001732, 0.02...  \n",
              "1  [0.016064640134572983, 0.012980114668607712, 0...  \n",
              "2  [0.011205372400581837, 0.010022246278822422, 0...  \n",
              "3  [0.18525643646717072, 0.13916648924350739, 0.1...  \n",
              "4  [0.010354984551668167, 0.007956349290907383, 0...  \n",
              "5  [0.17831216752529144, 0.0439273975789547, 0.03...  \n",
              "6  [0.23404990136623383, 0.062362492084503174, 0....  \n",
              "7  [0.008691192604601383, 0.00766870379447937, 0....  \n",
              "8  [0.013670983724296093, 0.011046798899769783, 0...  \n",
              "9  [0.012686355970799923, 0.00932218600064516, 0....  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Escolha da métrica\n",
        "chosen_metric = 'c_v'  # ou 'c_v', 'u_mass', 'c_uci'\n",
        "\n",
        "# Obter o melhor modelo treinado\n",
        "best_index = ptm_coherence_results[chosen_metric]['coherence_values'].index(\n",
        "    max(ptm_coherence_results[chosen_metric]['coherence_values'])\n",
        ")\n",
        "best_model = ptm_coherence_results[chosen_metric]['model_list'][best_index]\n",
        "\n",
        "# Gerar DataFrame com tópicos\n",
        "def get_topics_dataframe(model, top_n=10):\n",
        "    topics_data = []\n",
        "    for topic_id in range(model.k):\n",
        "        words_probs = model.get_topic_words(topic_id, top_n=top_n)\n",
        "        topic_words = [word for word, prob in words_probs]\n",
        "        topic_probs = [prob for word, prob in words_probs]\n",
        "        topics_data.append({\n",
        "            'Tópico': topic_id,\n",
        "            'Palavras': ', '.join(topic_words),\n",
        "            'Pesos': topic_probs\n",
        "        })\n",
        "    return pd.DataFrame(topics_data)\n",
        "\n",
        "df_topicos = get_topics_dataframe(best_model)\n",
        "\n",
        "df_topicos.to_csv('./resultados_pseudo/wpp/pseudo_wpp_c_v.csv', index=False)\n",
        "df_topicos.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diversidade de Tópicos: 0.7808\n",
            "IRBO médio entre tópicos: 0.9591\n"
          ]
        }
      ],
      "source": [
        "div = topic_diversity(best_model)\n",
        "print(f\"Diversidade de Tópicos: {round(div, 4)}\")\n",
        "\n",
        "irbo_score = compute_irbo_ptm(best_model)\n",
        "print(f\"IRBO médio entre tópicos: {round(irbo_score, 4)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tópico</th>\n",
              "      <th>Palavras</th>\n",
              "      <th>Pesos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>lula, vamos, brasil, bolsonaro, povo, presiden...</td>\n",
              "      <td>[0.01962336152791977, 0.013131478801369667, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>joao, saymon, homessexual, divirtace, km, br, ...</td>\n",
              "      <td>[0.05603599548339844, 0.046925708651542664, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>99999999999999, r, wr273ymrnwbddyrblwch, ezgz,...</td>\n",
              "      <td>[0.9532402753829956, 0.0008700666367076337, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>grupos, silva, 11, brasil, bolsonaro, 14, 24, ...</td>\n",
              "      <td>[0.01112956553697586, 0.010227174498140812, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>bocahomens, cagando, bosta, carae, vomitando, ...</td>\n",
              "      <td>[0.182708740234375, 0.13762100040912628, 0.107...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>milhoes, caso, escandalo, pt, bilhoes, 2018, l...</td>\n",
              "      <td>[0.0235182773321867, 0.01338708121329546, 0.01...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>brasil, 2022, portaltocanews, anos, mil, sobre...</td>\n",
              "      <td>[0.007906096056103706, 0.006553787738084793, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>lula, volta, todos, eleicoes, bolsonaro, brasi...</td>\n",
              "      <td>[0.012261259369552135, 0.011130464263260365, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>janja, robo, proibido, dizer, lula, stf, tse, ...</td>\n",
              "      <td>[0.09918999671936035, 0.09720946848392487, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>sim, voto, 22, porque, concorda, grupo, pais, ...</td>\n",
              "      <td>[0.018109342083334923, 0.012574584223330021, 0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Tópico                                           Palavras  \\\n",
              "0       0  lula, vamos, brasil, bolsonaro, povo, presiden...   \n",
              "1       1  joao, saymon, homessexual, divirtace, km, br, ...   \n",
              "2       2  99999999999999, r, wr273ymrnwbddyrblwch, ezgz,...   \n",
              "3       3  grupos, silva, 11, brasil, bolsonaro, 14, 24, ...   \n",
              "4       4  bocahomens, cagando, bosta, carae, vomitando, ...   \n",
              "5       5  milhoes, caso, escandalo, pt, bilhoes, 2018, l...   \n",
              "6       6  brasil, 2022, portaltocanews, anos, mil, sobre...   \n",
              "7       7  lula, volta, todos, eleicoes, bolsonaro, brasi...   \n",
              "8       8  janja, robo, proibido, dizer, lula, stf, tse, ...   \n",
              "9       9  sim, voto, 22, porque, concorda, grupo, pais, ...   \n",
              "\n",
              "                                               Pesos  \n",
              "0  [0.01962336152791977, 0.013131478801369667, 0....  \n",
              "1  [0.05603599548339844, 0.046925708651542664, 0....  \n",
              "2  [0.9532402753829956, 0.0008700666367076337, 0....  \n",
              "3  [0.01112956553697586, 0.010227174498140812, 0....  \n",
              "4  [0.182708740234375, 0.13762100040912628, 0.107...  \n",
              "5  [0.0235182773321867, 0.01338708121329546, 0.01...  \n",
              "6  [0.007906096056103706, 0.006553787738084793, 0...  \n",
              "7  [0.012261259369552135, 0.011130464263260365, 0...  \n",
              "8  [0.09918999671936035, 0.09720946848392487, 0.0...  \n",
              "9  [0.018109342083334923, 0.012574584223330021, 0...  "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Escolha da métrica\n",
        "chosen_metric = 'c_uci'  # ou 'c_v', 'u_mass', 'c_uci'\n",
        "\n",
        "# Obter o melhor modelo treinado\n",
        "best_index = ptm_coherence_results[chosen_metric]['coherence_values'].index(\n",
        "    max(ptm_coherence_results[chosen_metric]['coherence_values'])\n",
        ")\n",
        "best_model = ptm_coherence_results[chosen_metric]['model_list'][best_index]\n",
        "\n",
        "# Gerar DataFrame com tópicos\n",
        "def get_topics_dataframe(model, top_n=10):\n",
        "    topics_data = []\n",
        "    for topic_id in range(model.k):\n",
        "        words_probs = model.get_topic_words(topic_id, top_n=top_n)\n",
        "        topic_words = [word for word, prob in words_probs]\n",
        "        topic_probs = [prob for word, prob in words_probs]\n",
        "        topics_data.append({\n",
        "            'Tópico': topic_id,\n",
        "            'Palavras': ', '.join(topic_words),\n",
        "            'Pesos': topic_probs\n",
        "        })\n",
        "    return pd.DataFrame(topics_data)\n",
        "\n",
        "df_topicos = get_topics_dataframe(best_model)\n",
        "\n",
        "df_topicos.to_csv('./resultados_pseudo/wpp/pseudo_wpp_c_uci.csv', index=False)\n",
        "df_topicos.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diversidade de Tópicos: 0.77\n",
            "IRBO médio entre tópicos: 0.9496\n"
          ]
        }
      ],
      "source": [
        "div = topic_diversity(best_model)\n",
        "print(f\"Diversidade de Tópicos: {round(div, 4)}\")\n",
        "\n",
        "irbo_score = compute_irbo_ptm(best_model)\n",
        "print(f\"IRBO médio entre tópicos: {round(irbo_score, 4)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tópico</th>\n",
              "      <th>Palavras</th>\n",
              "      <th>Pesos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>stf, moraes, alexandre, qualquer, direito, min...</td>\n",
              "      <td>[0.011127772741019726, 0.01059278566390276, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>divirtace, internet, 25, 2, valor, fortaleza, ...</td>\n",
              "      <td>[0.009107273072004318, 0.005588032305240631, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>55, 20, 1, 91, 92, 127, 155, 115, 128, 101</td>\n",
              "      <td>[0.149518683552742, 0.10145100951194763, 0.043...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>bolsonaro, brasil, rio, estados, 3, pesquisa, ...</td>\n",
              "      <td>[0.03183000162243843, 0.019425008445978165, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>bocahomens, cagando, bosta, carae, vomitando, ...</td>\n",
              "      <td>[0.18141232430934906, 0.1366688758134842, 0.11...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>gazetabrasil, brasil, noticias, grupo, apos, a...</td>\n",
              "      <td>[0.014604044146835804, 0.013515135273337364, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>lula, escandalo, milhoes, habitantes, votaram,...</td>\n",
              "      <td>[0.04103682562708855, 0.021463025361299515, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>fazendo, olha, tao, covardia, pronuncie, franc...</td>\n",
              "      <td>[0.03546610847115517, 0.035082414746284485, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>lula, bolsonaro, pt, brasil, votos, tse, video...</td>\n",
              "      <td>[0.06241956725716591, 0.041065555065870285, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>eleicoes, bolsonaro, porque, urnas, tse, turno...</td>\n",
              "      <td>[0.013579479418694973, 0.010746631771326065, 0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Tópico                                           Palavras  \\\n",
              "0       0  stf, moraes, alexandre, qualquer, direito, min...   \n",
              "1       1  divirtace, internet, 25, 2, valor, fortaleza, ...   \n",
              "2       2         55, 20, 1, 91, 92, 127, 155, 115, 128, 101   \n",
              "3       3  bolsonaro, brasil, rio, estados, 3, pesquisa, ...   \n",
              "4       4  bocahomens, cagando, bosta, carae, vomitando, ...   \n",
              "5       5  gazetabrasil, brasil, noticias, grupo, apos, a...   \n",
              "6       6  lula, escandalo, milhoes, habitantes, votaram,...   \n",
              "7       7  fazendo, olha, tao, covardia, pronuncie, franc...   \n",
              "8       8  lula, bolsonaro, pt, brasil, votos, tse, video...   \n",
              "9       9  eleicoes, bolsonaro, porque, urnas, tse, turno...   \n",
              "\n",
              "                                               Pesos  \n",
              "0  [0.011127772741019726, 0.01059278566390276, 0....  \n",
              "1  [0.009107273072004318, 0.005588032305240631, 0...  \n",
              "2  [0.149518683552742, 0.10145100951194763, 0.043...  \n",
              "3  [0.03183000162243843, 0.019425008445978165, 0....  \n",
              "4  [0.18141232430934906, 0.1366688758134842, 0.11...  \n",
              "5  [0.014604044146835804, 0.013515135273337364, 0...  \n",
              "6  [0.04103682562708855, 0.021463025361299515, 0....  \n",
              "7  [0.03546610847115517, 0.035082414746284485, 0....  \n",
              "8  [0.06241956725716591, 0.041065555065870285, 0....  \n",
              "9  [0.013579479418694973, 0.010746631771326065, 0...  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Escolha da métrica\n",
        "chosen_metric = 'u_mass'  # ou 'c_v', 'u_mass', 'c_uci'\n",
        "\n",
        "# Obter o melhor modelo treinado\n",
        "best_index = ptm_coherence_results[chosen_metric]['coherence_values'].index(\n",
        "    max(ptm_coherence_results[chosen_metric]['coherence_values'])\n",
        ")\n",
        "best_model = ptm_coherence_results[chosen_metric]['model_list'][best_index]\n",
        "\n",
        "# Gerar DataFrame com tópicos\n",
        "def get_topics_dataframe(model, top_n=10):\n",
        "    topics_data = []\n",
        "    for topic_id in range(model.k):\n",
        "        words_probs = model.get_topic_words(topic_id, top_n=top_n)\n",
        "        topic_words = [word for word, prob in words_probs]\n",
        "        topic_probs = [prob for word, prob in words_probs]\n",
        "        topics_data.append({\n",
        "            'Tópico': topic_id,\n",
        "            'Palavras': ', '.join(topic_words),\n",
        "            'Pesos': topic_probs\n",
        "        })\n",
        "    return pd.DataFrame(topics_data)\n",
        "\n",
        "df_topicos = get_topics_dataframe(best_model)\n",
        "\n",
        "df_topicos.to_csv('./resultados_pseudo/wpp/pseudo_wpp_u_mass.csv', index=False)\n",
        "df_topicos.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diversidade de Tópicos: 0.7458\n",
            "IRBO médio entre tópicos: 0.9585\n"
          ]
        }
      ],
      "source": [
        "div = topic_diversity(best_model)\n",
        "print(f\"Diversidade de Tópicos: {round(div, 4)}\")\n",
        "\n",
        "irbo_score = compute_irbo_ptm(best_model)\n",
        "print(f\"IRBO médio entre tópicos: {round(irbo_score, 4)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modelagem de tópicos com filtro religioso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "palavras_religiosas = [\n",
        "    \"deus\", \"jesus\", \"misericordia\", \"davi\",\n",
        "    \"salomao\", \"reino\", \"templo\", \"conservador\",\n",
        "    \"pentecostal\", \"rcc\", \"renovacao\", \"carismatic\",\n",
        "    \"paulo ricardo\", \"bernardo kuster\", \"herege\", \"ateu\",\n",
        "    \"jerico\", \"heresia\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Função para verificar se uma palavra está relacionada à religião\n",
        "def relacionada_religiao(word):\n",
        "    word_lower = word.lower()\n",
        "    palavras_religiosas_lower = [palavra.lower() for palavra in palavras_religiosas]\n",
        "\n",
        "    # Verificando se alguma palavra da lista de palavras religiosas está presente\n",
        "    return any(palavra in word_lower for palavra in palavras_religiosas_lower)\n",
        "\n",
        "\n",
        "df_religiao = df_geral[df_geral['text_processed'].apply(lambda x: relacionada_religiao(x))]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "texto_processado_religiao = df_religiao['text_processed'].apply(processar_texto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Corpus e Dicionário (para CoherenceModel do gensim)\n",
        "id2word_religiao = corpora.Dictionary(texto_processado_religiao)\n",
        "corpus_religiao = [id2word.doc2bow(text) for text in texto_processado_religiao]\n",
        "texts_religiao = texto_processado_religiao.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Treinando PTModel (c_v):   0%|          | 0/14 [00:00<?, ?it/s]C:\\Users\\Melissa Felipe\\AppData\\Local\\Temp\\ipykernel_26484\\2436467606.py:10: RuntimeWarning: The training result may differ even with fixed seed if `workers` != 1.\n",
            "  model.train(100)\n",
            "Treinando PTModel (c_v): 100%|██████████| 14/14 [04:49<00:00, 20.67s/it]\n",
            "Treinando PTModel (u_mass): 100%|██████████| 14/14 [02:23<00:00, 10.23s/it]\n",
            "Treinando PTModel (c_uci): 100%|██████████| 14/14 [04:41<00:00, 20.11s/it]\n",
            "Treinando PTModel (c_npmi): 100%|██████████| 14/14 [04:39<00:00, 19.97s/it]\n"
          ]
        }
      ],
      "source": [
        "def calculate_ptm_coherence_for_metrics(texts_religiao, id2word_religiao, metrics, start=2, limit=30, step=2):\n",
        "    results = {}\n",
        "    for metric in metrics:\n",
        "        num_topics, model_list, coherence_values = compute_coherence_ptm(\n",
        "            texts=texts_religiao,\n",
        "            id2word=id2word_religiao,\n",
        "            coherence=metric,\n",
        "            start=start,\n",
        "            limit=limit,\n",
        "            step=step\n",
        "        )\n",
        "        results[metric] = {\n",
        "            'num_topics': num_topics,\n",
        "            'model_list': model_list,\n",
        "            'coherence_values': coherence_values\n",
        "        }\n",
        "    return results\n",
        "\n",
        "metrics = ['c_v', 'u_mass', 'c_uci', 'c_npmi']\n",
        "\n",
        "ptm_coherence_results = calculate_ptm_coherence_for_metrics(\n",
        "    texts_religiao=texto_processado_religiao.tolist(),\n",
        "    id2word_religiao=id2word_religiao,\n",
        "    metrics=metrics,\n",
        "    start=2,\n",
        "    limit=30,\n",
        "    step=2\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Resultados de Coerência para C_V:\n",
            "Qtd. tópicos = 2 -> Coerência = 0.4559\n",
            "Qtd. tópicos = 4 -> Coerência = 0.5554\n",
            "Qtd. tópicos = 6 -> Coerência = 0.5611\n",
            "Qtd. tópicos = 8 -> Coerência = 0.6496\n",
            "Qtd. tópicos = 10 -> Coerência = 0.5808\n",
            "Qtd. tópicos = 12 -> Coerência = 0.541\n",
            "Qtd. tópicos = 14 -> Coerência = 0.6015\n",
            "Qtd. tópicos = 16 -> Coerência = 0.5493\n",
            "Qtd. tópicos = 18 -> Coerência = 0.5622\n",
            "Qtd. tópicos = 20 -> Coerência = 0.5785\n",
            "Qtd. tópicos = 22 -> Coerência = 0.6058\n",
            "Qtd. tópicos = 24 -> Coerência = 0.5712\n",
            "Qtd. tópicos = 26 -> Coerência = 0.5965\n",
            "Qtd. tópicos = 28 -> Coerência = 0.6057\n",
            "Melhor número de tópicos segundo C_V: 8\n",
            "\n",
            "Resultados de Coerência para U_MASS:\n",
            "Qtd. tópicos = 2 -> Coerência = -3.8858\n",
            "Qtd. tópicos = 4 -> Coerência = -1.6734\n",
            "Qtd. tópicos = 6 -> Coerência = -1.8377\n",
            "Qtd. tópicos = 8 -> Coerência = -1.7746\n",
            "Qtd. tópicos = 10 -> Coerência = -1.5814\n",
            "Qtd. tópicos = 12 -> Coerência = -1.7741\n",
            "Qtd. tópicos = 14 -> Coerência = -1.6836\n",
            "Qtd. tópicos = 16 -> Coerência = -1.7514\n",
            "Qtd. tópicos = 18 -> Coerência = -2.0233\n",
            "Qtd. tópicos = 20 -> Coerência = -1.7752\n",
            "Qtd. tópicos = 22 -> Coerência = -1.5452\n",
            "Qtd. tópicos = 24 -> Coerência = -1.8003\n",
            "Qtd. tópicos = 26 -> Coerência = -1.5157\n",
            "Qtd. tópicos = 28 -> Coerência = -1.6834\n",
            "Melhor número de tópicos segundo U_MASS: 26\n",
            "\n",
            "Resultados de Coerência para C_UCI:\n",
            "Qtd. tópicos = 2 -> Coerência = -5.3582\n",
            "Qtd. tópicos = 4 -> Coerência = -3.0325\n",
            "Qtd. tópicos = 6 -> Coerência = -1.9406\n",
            "Qtd. tópicos = 8 -> Coerência = -1.3829\n",
            "Qtd. tópicos = 10 -> Coerência = -2.3602\n",
            "Qtd. tópicos = 12 -> Coerência = -2.2774\n",
            "Qtd. tópicos = 14 -> Coerência = -1.8171\n",
            "Qtd. tópicos = 16 -> Coerência = -2.1898\n",
            "Qtd. tópicos = 18 -> Coerência = -1.7489\n",
            "Qtd. tópicos = 20 -> Coerência = -1.5767\n",
            "Qtd. tópicos = 22 -> Coerência = -1.309\n",
            "Qtd. tópicos = 24 -> Coerência = -1.8979\n",
            "Qtd. tópicos = 26 -> Coerência = -1.4995\n",
            "Qtd. tópicos = 28 -> Coerência = -1.2642\n",
            "Melhor número de tópicos segundo C_UCI: 28\n",
            "\n",
            "Resultados de Coerência para C_NPMI:\n",
            "Qtd. tópicos = 2 -> Coerência = -0.1743\n",
            "Qtd. tópicos = 4 -> Coerência = -0.0768\n",
            "Qtd. tópicos = 6 -> Coerência = -0.0399\n",
            "Qtd. tópicos = 8 -> Coerência = 0.0157\n",
            "Qtd. tópicos = 10 -> Coerência = -0.042\n",
            "Qtd. tópicos = 12 -> Coerência = -0.0419\n",
            "Qtd. tópicos = 14 -> Coerência = -0.0065\n",
            "Qtd. tópicos = 16 -> Coerência = -0.0362\n",
            "Qtd. tópicos = 18 -> Coerência = -0.0094\n",
            "Qtd. tópicos = 20 -> Coerência = -0.0017\n",
            "Qtd. tópicos = 22 -> Coerência = 0.0063\n",
            "Qtd. tópicos = 24 -> Coerência = -0.0108\n",
            "Qtd. tópicos = 26 -> Coerência = 0.0054\n",
            "Qtd. tópicos = 28 -> Coerência = 0.0164\n",
            "Melhor número de tópicos segundo C_NPMI: 28\n"
          ]
        }
      ],
      "source": [
        "# Mostrar resultados\n",
        "for metric in metrics:\n",
        "    print(f\"\\nResultados de Coerência para {metric.upper()}:\")\n",
        "    for m, cv in zip(range(2, 30, 2), ptm_coherence_results[metric]['coherence_values']):\n",
        "        print(f\"Qtd. tópicos = {m} -> Coerência = {round(cv, 4)}\")\n",
        "    print(f\"Melhor número de tópicos segundo {metric.upper()}: {ptm_coherence_results[metric]['num_topics']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diversidade de Tópicos: 0.7036\n",
            "IRBO médio entre tópicos: 0.9516\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tópico</th>\n",
              "      <th>Palavras</th>\n",
              "      <th>Pesos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>drive, brasil, bolsonaro, povo, todos, video, ...</td>\n",
              "      <td>[0.020388666540384293, 0.010153494775295258, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>lula, urnas, eleicoes, bolsonaro, vitoria, pt,...</td>\n",
              "      <td>[0.021928688511252403, 0.020492324605584145, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>pessoas, mil, errou, gazetabrasil, milhoes, qu...</td>\n",
              "      <td>[0.01068599708378315, 0.00648313295096159, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3, 2, 1, 10, 5, brasil, 15, 22, 8, 16</td>\n",
              "      <td>[0.02451811544597149, 0.023244017735123634, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>turno, alexandre, arruda, roberto, assim, jose...</td>\n",
              "      <td>[0.01781422831118107, 0.013747712597250938, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>direito, pode, manifestacao, todos, caso, enta...</td>\n",
              "      <td>[0.01690850220620632, 0.01619306020438671, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>fez, brasil, ferrovia, br, deu, coisas, agua, ...</td>\n",
              "      <td>[0.025215422734618187, 0.021936312317848206, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>tribunal, republica, stf, supremo, geral, acao...</td>\n",
              "      <td>[0.025822211056947708, 0.019148360937833786, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>lula, brasil, pt, pode, governo, sobre, defend...</td>\n",
              "      <td>[0.07110974192619324, 0.03516508638858795, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>presidente, liberdade, todos, patria, direito,...</td>\n",
              "      <td>[0.03478185087442398, 0.0267342459410429, 0.02...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Tópico                                           Palavras  \\\n",
              "0       0  drive, brasil, bolsonaro, povo, todos, video, ...   \n",
              "1       1  lula, urnas, eleicoes, bolsonaro, vitoria, pt,...   \n",
              "2       2  pessoas, mil, errou, gazetabrasil, milhoes, qu...   \n",
              "3       3              3, 2, 1, 10, 5, brasil, 15, 22, 8, 16   \n",
              "4       4  turno, alexandre, arruda, roberto, assim, jose...   \n",
              "5       5  direito, pode, manifestacao, todos, caso, enta...   \n",
              "6       6  fez, brasil, ferrovia, br, deu, coisas, agua, ...   \n",
              "7       7  tribunal, republica, stf, supremo, geral, acao...   \n",
              "8       8  lula, brasil, pt, pode, governo, sobre, defend...   \n",
              "9       9  presidente, liberdade, todos, patria, direito,...   \n",
              "\n",
              "                                               Pesos  \n",
              "0  [0.020388666540384293, 0.010153494775295258, 0...  \n",
              "1  [0.021928688511252403, 0.020492324605584145, 0...  \n",
              "2  [0.01068599708378315, 0.00648313295096159, 0.0...  \n",
              "3  [0.02451811544597149, 0.023244017735123634, 0....  \n",
              "4  [0.01781422831118107, 0.013747712597250938, 0....  \n",
              "5  [0.01690850220620632, 0.01619306020438671, 0.0...  \n",
              "6  [0.025215422734618187, 0.021936312317848206, 0...  \n",
              "7  [0.025822211056947708, 0.019148360937833786, 0...  \n",
              "8  [0.07110974192619324, 0.03516508638858795, 0.0...  \n",
              "9  [0.03478185087442398, 0.0267342459410429, 0.02...  "
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Escolha da métrica\n",
        "chosen_metric = 'c_npmi'  # ou 'c_v', 'u_mass', 'c_uci'\n",
        "\n",
        "# Obter o melhor modelo treinado\n",
        "best_index = ptm_coherence_results[chosen_metric]['coherence_values'].index(\n",
        "    max(ptm_coherence_results[chosen_metric]['coherence_values'])\n",
        ")\n",
        "best_model = ptm_coherence_results[chosen_metric]['model_list'][best_index]\n",
        "\n",
        "# Gerar DataFrame com tópicos\n",
        "def get_topics_dataframe(model, top_n=10):\n",
        "    topics_data = []\n",
        "    for topic_id in range(model.k):\n",
        "        words_probs = model.get_topic_words(topic_id, top_n=top_n)\n",
        "        topic_words = [word for word, prob in words_probs]\n",
        "        topic_probs = [prob for word, prob in words_probs]\n",
        "        topics_data.append({\n",
        "            'Tópico': topic_id,\n",
        "            'Palavras': ', '.join(topic_words),\n",
        "            'Pesos': topic_probs\n",
        "        })\n",
        "    return pd.DataFrame(topics_data)\n",
        "\n",
        "df_topicos = get_topics_dataframe(best_model)\n",
        "\n",
        "df_topicos.to_csv('./resultados_pseudo/wpp/pseudo_wpp_religioso_c_npmi.csv', index=False)\n",
        "\n",
        "div = topic_diversity(best_model)\n",
        "print(f\"Diversidade de Tópicos: {round(div, 4)}\")\n",
        "\n",
        "irbo_score = compute_irbo_ptm(best_model)\n",
        "print(f\"IRBO médio entre tópicos: {round(irbo_score, 4)}\")\n",
        "\n",
        "df_topicos.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diversidade de Tópicos: 0.7875\n",
            "IRBO médio entre tópicos: 0.8939\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tópico</th>\n",
              "      <th>Palavras</th>\n",
              "      <th>Pesos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>pl, bolsonaro, deputado, governador, 22, senad...</td>\n",
              "      <td>[0.03423726186156273, 0.015543557703495026, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>bolsonaro, grupos, 22, deus, brasil, grupo, ap...</td>\n",
              "      <td>[0.01913987658917904, 0.008895935490727425, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>lula, brasil, deus, bolsonaro, porque, preside...</td>\n",
              "      <td>[0.025525715202093124, 0.01919322833418846, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>deus, todos, senhor, jesus, bem, vida, povo, p...</td>\n",
              "      <td>[0.026477796956896782, 0.009984838776290417, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>55, 20, 1, 91, 92, 127, 155, 101, 128, 115</td>\n",
              "      <td>[0.2426958829164505, 0.06488315016031265, 0.03...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>anos, brasil, 2022, noticias, apos, jrmunews, ...</td>\n",
              "      <td>[0.008514058776199818, 0.004735302180051804, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>brasil, bolsonaro, ok, todos, 22, fez, dizer, ...</td>\n",
              "      <td>[0.01728217490017414, 0.014552361331880093, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>eleicoes, lula, urnas, stf, turno, roberto, ts...</td>\n",
              "      <td>[0.013431498780846596, 0.013159469701349735, 0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Tópico                                           Palavras  \\\n",
              "0       0  pl, bolsonaro, deputado, governador, 22, senad...   \n",
              "1       1  bolsonaro, grupos, 22, deus, brasil, grupo, ap...   \n",
              "2       2  lula, brasil, deus, bolsonaro, porque, preside...   \n",
              "3       3  deus, todos, senhor, jesus, bem, vida, povo, p...   \n",
              "4       4         55, 20, 1, 91, 92, 127, 155, 101, 128, 115   \n",
              "5       5  anos, brasil, 2022, noticias, apos, jrmunews, ...   \n",
              "6       6  brasil, bolsonaro, ok, todos, 22, fez, dizer, ...   \n",
              "7       7  eleicoes, lula, urnas, stf, turno, roberto, ts...   \n",
              "\n",
              "                                               Pesos  \n",
              "0  [0.03423726186156273, 0.015543557703495026, 0....  \n",
              "1  [0.01913987658917904, 0.008895935490727425, 0....  \n",
              "2  [0.025525715202093124, 0.01919322833418846, 0....  \n",
              "3  [0.026477796956896782, 0.009984838776290417, 0...  \n",
              "4  [0.2426958829164505, 0.06488315016031265, 0.03...  \n",
              "5  [0.008514058776199818, 0.004735302180051804, 0...  \n",
              "6  [0.01728217490017414, 0.014552361331880093, 0....  \n",
              "7  [0.013431498780846596, 0.013159469701349735, 0...  "
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Escolha da métrica\n",
        "chosen_metric = 'c_v'  # ou 'c_v', 'u_mass', 'c_uci'\n",
        "\n",
        "# Obter o melhor modelo treinado\n",
        "best_index = ptm_coherence_results[chosen_metric]['coherence_values'].index(\n",
        "    max(ptm_coherence_results[chosen_metric]['coherence_values'])\n",
        ")\n",
        "best_model = ptm_coherence_results[chosen_metric]['model_list'][best_index]\n",
        "\n",
        "# Gerar DataFrame com tópicos\n",
        "def get_topics_dataframe(model, top_n=10):\n",
        "    topics_data = []\n",
        "    for topic_id in range(model.k):\n",
        "        words_probs = model.get_topic_words(topic_id, top_n=top_n)\n",
        "        topic_words = [word for word, prob in words_probs]\n",
        "        topic_probs = [prob for word, prob in words_probs]\n",
        "        topics_data.append({\n",
        "            'Tópico': topic_id,\n",
        "            'Palavras': ', '.join(topic_words),\n",
        "            'Pesos': topic_probs\n",
        "        })\n",
        "    return pd.DataFrame(topics_data)\n",
        "\n",
        "df_topicos = get_topics_dataframe(best_model)\n",
        "\n",
        "df_topicos.to_csv('./resultados_pseudo/wpp/pseudo_wpp_religioso_c_v.csv', index=False)\n",
        "\n",
        "div = topic_diversity(best_model)\n",
        "print(f\"Diversidade de Tópicos: {round(div, 4)}\")\n",
        "\n",
        "irbo_score = compute_irbo_ptm(best_model)\n",
        "print(f\"IRBO médio entre tópicos: {round(irbo_score, 4)}\")\n",
        "\n",
        "df_topicos.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diversidade de Tópicos: 0.7346\n",
            "IRBO médio entre tópicos: 0.9485\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tópico</th>\n",
              "      <th>Palavras</th>\n",
              "      <th>Pesos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>porque, entenderam, esquerda, pais, anos, demo...</td>\n",
              "      <td>[0.07183302938938141, 0.047818128019571304, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>estao, lei, dentro, algo, fogo, onde, nome, tr...</td>\n",
              "      <td>[0.006019809748977423, 0.00592648284509778, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>brasil, deus, bolsonaro, todos, presidente, ag...</td>\n",
              "      <td>[0.021332817152142525, 0.021316369995474815, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>noticias, pais, rio, apos, policia, sobre, pes...</td>\n",
              "      <td>[0.00921702291816473, 0.006201962009072304, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>coisas, agua, dinheiro, anos, 2, 3, 13, 10, 5,...</td>\n",
              "      <td>[0.018107086420059204, 0.01573595218360424, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>segundo, federal, brasil, milhoes, anos, brasi...</td>\n",
              "      <td>[0.015116135589778423, 0.015116135589778423, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>sr, eleicoes, alexandre, assim, roberto, turno...</td>\n",
              "      <td>[0.012554574757814407, 0.01106806006282568, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>lula, bolsonaro, estados, presidente, hoje, va...</td>\n",
              "      <td>[0.028039971366524696, 0.022211939096450806, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>agora, bem, pais, poder, militar, fazer, direi...</td>\n",
              "      <td>[0.016884535551071167, 0.013121739961206913, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>cand, brasileiro, brasil, enquanto, linha, lid...</td>\n",
              "      <td>[0.014604990370571613, 0.009701501578092575, 0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Tópico                                           Palavras  \\\n",
              "0       0  porque, entenderam, esquerda, pais, anos, demo...   \n",
              "1       1  estao, lei, dentro, algo, fogo, onde, nome, tr...   \n",
              "2       2  brasil, deus, bolsonaro, todos, presidente, ag...   \n",
              "3       3  noticias, pais, rio, apos, policia, sobre, pes...   \n",
              "4       4  coisas, agua, dinheiro, anos, 2, 3, 13, 10, 5,...   \n",
              "5       5  segundo, federal, brasil, milhoes, anos, brasi...   \n",
              "6       6  sr, eleicoes, alexandre, assim, roberto, turno...   \n",
              "7       7  lula, bolsonaro, estados, presidente, hoje, va...   \n",
              "8       8  agora, bem, pais, poder, militar, fazer, direi...   \n",
              "9       9  cand, brasileiro, brasil, enquanto, linha, lid...   \n",
              "\n",
              "                                               Pesos  \n",
              "0  [0.07183302938938141, 0.047818128019571304, 0....  \n",
              "1  [0.006019809748977423, 0.00592648284509778, 0....  \n",
              "2  [0.021332817152142525, 0.021316369995474815, 0...  \n",
              "3  [0.00921702291816473, 0.006201962009072304, 0....  \n",
              "4  [0.018107086420059204, 0.01573595218360424, 0....  \n",
              "5  [0.015116135589778423, 0.015116135589778423, 0...  \n",
              "6  [0.012554574757814407, 0.01106806006282568, 0....  \n",
              "7  [0.028039971366524696, 0.022211939096450806, 0...  \n",
              "8  [0.016884535551071167, 0.013121739961206913, 0...  \n",
              "9  [0.014604990370571613, 0.009701501578092575, 0...  "
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Escolha da métrica\n",
        "chosen_metric = 'u_mass'  # ou 'c_v', 'u_mass', 'c_uci'\n",
        "\n",
        "# Obter o melhor modelo treinado\n",
        "best_index = ptm_coherence_results[chosen_metric]['coherence_values'].index(\n",
        "    max(ptm_coherence_results[chosen_metric]['coherence_values'])\n",
        ")\n",
        "best_model = ptm_coherence_results[chosen_metric]['model_list'][best_index]\n",
        "\n",
        "# Gerar DataFrame com tópicos\n",
        "def get_topics_dataframe(model, top_n=10):\n",
        "    topics_data = []\n",
        "    for topic_id in range(model.k):\n",
        "        words_probs = model.get_topic_words(topic_id, top_n=top_n)\n",
        "        topic_words = [word for word, prob in words_probs]\n",
        "        topic_probs = [prob for word, prob in words_probs]\n",
        "        topics_data.append({\n",
        "            'Tópico': topic_id,\n",
        "            'Palavras': ', '.join(topic_words),\n",
        "            'Pesos': topic_probs\n",
        "        })\n",
        "    return pd.DataFrame(topics_data)\n",
        "\n",
        "df_topicos = get_topics_dataframe(best_model)\n",
        "\n",
        "df_topicos.to_csv('./resultados_pseudo/wpp/pseudo_wpp_religioso_u_mass.csv', index=False)\n",
        "\n",
        "div = topic_diversity(best_model)\n",
        "print(f\"Diversidade de Tópicos: {round(div, 4)}\")\n",
        "\n",
        "irbo_score = compute_irbo_ptm(best_model)\n",
        "print(f\"IRBO médio entre tópicos: {round(irbo_score, 4)}\")\n",
        "\n",
        "df_topicos.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diversidade de Tópicos: 0.7036\n",
            "IRBO médio entre tópicos: 0.9516\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tópico</th>\n",
              "      <th>Palavras</th>\n",
              "      <th>Pesos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>drive, brasil, bolsonaro, povo, todos, video, ...</td>\n",
              "      <td>[0.020388666540384293, 0.010153494775295258, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>lula, urnas, eleicoes, bolsonaro, vitoria, pt,...</td>\n",
              "      <td>[0.021928688511252403, 0.020492324605584145, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>pessoas, mil, errou, gazetabrasil, milhoes, qu...</td>\n",
              "      <td>[0.01068599708378315, 0.00648313295096159, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3, 2, 1, 10, 5, brasil, 15, 22, 8, 16</td>\n",
              "      <td>[0.02451811544597149, 0.023244017735123634, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>turno, alexandre, arruda, roberto, assim, jose...</td>\n",
              "      <td>[0.01781422831118107, 0.013747712597250938, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>direito, pode, manifestacao, todos, caso, enta...</td>\n",
              "      <td>[0.01690850220620632, 0.01619306020438671, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>fez, brasil, ferrovia, br, deu, coisas, agua, ...</td>\n",
              "      <td>[0.025215422734618187, 0.021936312317848206, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>tribunal, republica, stf, supremo, geral, acao...</td>\n",
              "      <td>[0.025822211056947708, 0.019148360937833786, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>lula, brasil, pt, pode, governo, sobre, defend...</td>\n",
              "      <td>[0.07110974192619324, 0.03516508638858795, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>presidente, liberdade, todos, patria, direito,...</td>\n",
              "      <td>[0.03478185087442398, 0.0267342459410429, 0.02...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Tópico                                           Palavras  \\\n",
              "0       0  drive, brasil, bolsonaro, povo, todos, video, ...   \n",
              "1       1  lula, urnas, eleicoes, bolsonaro, vitoria, pt,...   \n",
              "2       2  pessoas, mil, errou, gazetabrasil, milhoes, qu...   \n",
              "3       3              3, 2, 1, 10, 5, brasil, 15, 22, 8, 16   \n",
              "4       4  turno, alexandre, arruda, roberto, assim, jose...   \n",
              "5       5  direito, pode, manifestacao, todos, caso, enta...   \n",
              "6       6  fez, brasil, ferrovia, br, deu, coisas, agua, ...   \n",
              "7       7  tribunal, republica, stf, supremo, geral, acao...   \n",
              "8       8  lula, brasil, pt, pode, governo, sobre, defend...   \n",
              "9       9  presidente, liberdade, todos, patria, direito,...   \n",
              "\n",
              "                                               Pesos  \n",
              "0  [0.020388666540384293, 0.010153494775295258, 0...  \n",
              "1  [0.021928688511252403, 0.020492324605584145, 0...  \n",
              "2  [0.01068599708378315, 0.00648313295096159, 0.0...  \n",
              "3  [0.02451811544597149, 0.023244017735123634, 0....  \n",
              "4  [0.01781422831118107, 0.013747712597250938, 0....  \n",
              "5  [0.01690850220620632, 0.01619306020438671, 0.0...  \n",
              "6  [0.025215422734618187, 0.021936312317848206, 0...  \n",
              "7  [0.025822211056947708, 0.019148360937833786, 0...  \n",
              "8  [0.07110974192619324, 0.03516508638858795, 0.0...  \n",
              "9  [0.03478185087442398, 0.0267342459410429, 0.02...  "
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Escolha da métrica\n",
        "chosen_metric = 'c_uci'  # ou 'c_v', 'u_mass', 'c_uci'\n",
        "\n",
        "# Obter o melhor modelo treinado\n",
        "best_index = ptm_coherence_results[chosen_metric]['coherence_values'].index(\n",
        "    max(ptm_coherence_results[chosen_metric]['coherence_values'])\n",
        ")\n",
        "best_model = ptm_coherence_results[chosen_metric]['model_list'][best_index]\n",
        "\n",
        "# Gerar DataFrame com tópicos\n",
        "def get_topics_dataframe(model, top_n=10):\n",
        "    topics_data = []\n",
        "    for topic_id in range(model.k):\n",
        "        words_probs = model.get_topic_words(topic_id, top_n=top_n)\n",
        "        topic_words = [word for word, prob in words_probs]\n",
        "        topic_probs = [prob for word, prob in words_probs]\n",
        "        topics_data.append({\n",
        "            'Tópico': topic_id,\n",
        "            'Palavras': ', '.join(topic_words),\n",
        "            'Pesos': topic_probs\n",
        "        })\n",
        "    return pd.DataFrame(topics_data)\n",
        "\n",
        "df_topicos = get_topics_dataframe(best_model)\n",
        "\n",
        "df_topicos.to_csv('./resultados_pseudo/wpp/pseudo_wpp_religioso_c_uci.csv', index=False)\n",
        "\n",
        "div = topic_diversity(best_model)\n",
        "print(f\"Diversidade de Tópicos: {round(div, 4)}\")\n",
        "\n",
        "irbo_score = compute_irbo_ptm(best_model)\n",
        "print(f\"IRBO médio entre tópicos: {round(irbo_score, 4)}\")\n",
        "\n",
        "df_topicos.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modelagem de tópicos com filtros religiosos e exclusão de político"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "palavras_politicas = [ \"lula\", \"bolsonaro\", \"pt\", \"pl\", \"stf\", \"patria\", \"55\", \"22\", \"13\", \"senadores\", \"lulaladrao\",\n",
        "                       \"urnas\", \"alexandre\", \"moraes\", \"comunismo\", \"eleicao\", \"eleicoes\", \"esquerda\", \"direita\",\n",
        "                         \"presidente\", \"tse\", \"fraude\", \"voto\", \"turno\", \"ministro\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "def retirar_mensagens_com_palavras_politicas(word):\n",
        "    word_lower = word.lower()\n",
        "    palavras_politica_lower = [palavra.lower() for palavra in palavras_politicas]\n",
        "\n",
        "    return any(palavra in word_lower for palavra in palavras_politica_lower)\n",
        "\n",
        "\n",
        "df_politico = df_religiao[~df_religiao['text_processed'].apply(lambda x: retirar_mensagens_com_palavras_politicas(x))]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "texto_processado_politico = df_politico['text_processed'].apply(processar_texto)\n",
        "\n",
        "# Corpus e Dicionário (para CoherenceModel do gensim)\n",
        "id2word_politico = corpora.Dictionary(texto_processado_politico)\n",
        "corpus_politico = [id2word.doc2bow(text) for text in texto_processado_politico]\n",
        "texts_politico = texto_processado_politico.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Treinando PTModel (c_v):   0%|          | 0/14 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Melissa Felipe\\AppData\\Local\\Temp\\ipykernel_26484\\2436467606.py:10: RuntimeWarning: The training result may differ even with fixed seed if `workers` != 1.\n",
            "  model.train(100)\n",
            "Treinando PTModel (c_v): 100%|██████████| 14/14 [02:37<00:00, 11.26s/it]\n",
            "Treinando PTModel (u_mass): 100%|██████████| 14/14 [00:35<00:00,  2.51s/it]\n",
            "Treinando PTModel (c_uci): 100%|██████████| 14/14 [02:41<00:00, 11.56s/it]\n",
            "Treinando PTModel (c_npmi): 100%|██████████| 14/14 [02:40<00:00, 11.43s/it]\n"
          ]
        }
      ],
      "source": [
        "def calculate_ptm_coherence_for_metrics(texts_politico, id2word_politico, metrics, start=2, limit=30, step=2):\n",
        "    results = {}\n",
        "    for metric in metrics:\n",
        "        num_topics, model_list, coherence_values = compute_coherence_ptm(\n",
        "            texts=texts_politico,\n",
        "            id2word=id2word_politico,\n",
        "            coherence=metric,\n",
        "            start=start,\n",
        "            limit=limit,\n",
        "            step=step\n",
        "        )\n",
        "        results[metric] = {\n",
        "            'num_topics': num_topics,\n",
        "            'model_list': model_list,\n",
        "            'coherence_values': coherence_values\n",
        "        }\n",
        "    return results\n",
        "\n",
        "metrics = ['c_v', 'u_mass', 'c_uci', 'c_npmi']\n",
        "\n",
        "ptm_coherence_results = calculate_ptm_coherence_for_metrics(\n",
        "    texts_politico=texto_processado_politico.tolist(),\n",
        "    id2word_politico=id2word_politico,\n",
        "    metrics=metrics,\n",
        "    start=2,\n",
        "    limit=30,\n",
        "    step=2\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Resultados de Coerência para C_V:\n",
            "Qtd. tópicos = 2 -> Coerência = 0.6109\n",
            "Qtd. tópicos = 4 -> Coerência = 0.4975\n",
            "Qtd. tópicos = 6 -> Coerência = 0.4948\n",
            "Qtd. tópicos = 8 -> Coerência = 0.5287\n",
            "Qtd. tópicos = 10 -> Coerência = 0.5389\n",
            "Qtd. tópicos = 12 -> Coerência = 0.4428\n",
            "Qtd. tópicos = 14 -> Coerência = 0.5075\n",
            "Qtd. tópicos = 16 -> Coerência = 0.5261\n",
            "Qtd. tópicos = 18 -> Coerência = 0.4865\n",
            "Qtd. tópicos = 20 -> Coerência = 0.5028\n",
            "Qtd. tópicos = 22 -> Coerência = 0.4841\n",
            "Qtd. tópicos = 24 -> Coerência = 0.5057\n",
            "Qtd. tópicos = 26 -> Coerência = 0.5027\n",
            "Qtd. tópicos = 28 -> Coerência = 0.4736\n",
            "Melhor número de tópicos segundo C_V: 2\n",
            "\n",
            "Resultados de Coerência para U_MASS:\n",
            "Qtd. tópicos = 2 -> Coerência = -2.1423\n",
            "Qtd. tópicos = 4 -> Coerência = -2.587\n",
            "Qtd. tópicos = 6 -> Coerência = -3.9789\n",
            "Qtd. tópicos = 8 -> Coerência = -3.2976\n",
            "Qtd. tópicos = 10 -> Coerência = -3.5563\n",
            "Qtd. tópicos = 12 -> Coerência = -5.2403\n",
            "Qtd. tópicos = 14 -> Coerência = -4.4918\n",
            "Qtd. tópicos = 16 -> Coerência = -3.9689\n",
            "Qtd. tópicos = 18 -> Coerência = -4.5278\n",
            "Qtd. tópicos = 20 -> Coerência = -4.7872\n",
            "Qtd. tópicos = 22 -> Coerência = -5.1601\n",
            "Qtd. tópicos = 24 -> Coerência = -4.3934\n",
            "Qtd. tópicos = 26 -> Coerência = -4.6468\n",
            "Qtd. tópicos = 28 -> Coerência = -5.0554\n",
            "Melhor número de tópicos segundo U_MASS: 2\n",
            "\n",
            "Resultados de Coerência para C_UCI:\n",
            "Qtd. tópicos = 2 -> Coerência = 0.2585\n",
            "Qtd. tópicos = 4 -> Coerência = -0.2436\n",
            "Qtd. tópicos = 6 -> Coerência = -2.1184\n",
            "Qtd. tópicos = 8 -> Coerência = -2.1974\n",
            "Qtd. tópicos = 10 -> Coerência = -1.6277\n",
            "Qtd. tópicos = 12 -> Coerência = -3.4003\n",
            "Qtd. tópicos = 14 -> Coerência = -2.9833\n",
            "Qtd. tópicos = 16 -> Coerência = -2.9674\n",
            "Qtd. tópicos = 18 -> Coerência = -2.9226\n",
            "Qtd. tópicos = 20 -> Coerência = -3.35\n",
            "Qtd. tópicos = 22 -> Coerência = -3.7217\n",
            "Qtd. tópicos = 24 -> Coerência = -3.5011\n",
            "Qtd. tópicos = 26 -> Coerência = -3.8929\n",
            "Qtd. tópicos = 28 -> Coerência = -3.79\n",
            "Melhor número de tópicos segundo C_UCI: 2\n",
            "\n",
            "Resultados de Coerência para C_NPMI:\n",
            "Qtd. tópicos = 2 -> Coerência = 0.0617\n",
            "Qtd. tópicos = 4 -> Coerência = 0.0159\n",
            "Qtd. tópicos = 6 -> Coerência = -0.0433\n",
            "Qtd. tópicos = 8 -> Coerência = -0.0134\n",
            "Qtd. tópicos = 10 -> Coerência = 0.008\n",
            "Qtd. tópicos = 12 -> Coerência = -0.0897\n",
            "Qtd. tópicos = 14 -> Coerência = -0.0456\n",
            "Qtd. tópicos = 16 -> Coerência = -0.0453\n",
            "Qtd. tópicos = 18 -> Coerência = -0.0391\n",
            "Qtd. tópicos = 20 -> Coerência = -0.0565\n",
            "Qtd. tópicos = 22 -> Coerência = -0.0715\n",
            "Qtd. tópicos = 24 -> Coerência = -0.0592\n",
            "Qtd. tópicos = 26 -> Coerência = -0.0729\n",
            "Qtd. tópicos = 28 -> Coerência = -0.0795\n",
            "Melhor número de tópicos segundo C_NPMI: 2\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Mostrar resultados\n",
        "for metric in metrics:\n",
        "    print(f\"\\nResultados de Coerência para {metric.upper()}:\")\n",
        "    for m, cv in zip(range(2, 30, 2), ptm_coherence_results[metric]['coherence_values']):\n",
        "        print(f\"Qtd. tópicos = {m} -> Coerência = {round(cv, 4)}\")\n",
        "    print(f\"Melhor número de tópicos segundo {metric.upper()}: {ptm_coherence_results[metric]['num_topics']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diversidade de Tópicos: 0.95\n",
            "IRBO médio entre tópicos: 0.7071\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tópico</th>\n",
              "      <th>Palavras</th>\n",
              "      <th>Pesos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>deus, senhor, jesus, nome, vida, cristo, porqu...</td>\n",
              "      <td>[0.037812601774930954, 0.024820925667881966, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>deus, todos, vamos, brasil, fe, acima, amor, f...</td>\n",
              "      <td>[0.06376680731773376, 0.017140470445156097, 0....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Tópico                                           Palavras  \\\n",
              "0       0  deus, senhor, jesus, nome, vida, cristo, porqu...   \n",
              "1       1  deus, todos, vamos, brasil, fe, acima, amor, f...   \n",
              "\n",
              "                                               Pesos  \n",
              "0  [0.037812601774930954, 0.024820925667881966, 0...  \n",
              "1  [0.06376680731773376, 0.017140470445156097, 0....  "
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Escolha da métrica\n",
        "chosen_metric = 'c_npmi'  # ou 'c_v', 'u_mass', 'c_uci'\n",
        "\n",
        "# Obter o melhor modelo treinado\n",
        "best_index = ptm_coherence_results[chosen_metric]['coherence_values'].index(\n",
        "    max(ptm_coherence_results[chosen_metric]['coherence_values'])\n",
        ")\n",
        "best_model = ptm_coherence_results[chosen_metric]['model_list'][best_index]\n",
        "\n",
        "# Gerar DataFrame com tópicos\n",
        "def get_topics_dataframe(model, top_n=10):\n",
        "    topics_data = []\n",
        "    for topic_id in range(model.k):\n",
        "        words_probs = model.get_topic_words(topic_id, top_n=top_n)\n",
        "        topic_words = [word for word, prob in words_probs]\n",
        "        topic_probs = [prob for word, prob in words_probs]\n",
        "        topics_data.append({\n",
        "            'Tópico': topic_id,\n",
        "            'Palavras': ', '.join(topic_words),\n",
        "            'Pesos': topic_probs\n",
        "        })\n",
        "    return pd.DataFrame(topics_data)\n",
        "\n",
        "df_topicos = get_topics_dataframe(best_model)\n",
        "\n",
        "df_topicos.to_csv('./resultados_pseudo/wpp/pseudo_wpp_politico_c_npmi.csv', index=False)\n",
        "\n",
        "div = topic_diversity(best_model)\n",
        "print(f\"Diversidade de Tópicos: {round(div, 4)}\")\n",
        "\n",
        "irbo_score = compute_irbo_ptm(best_model)\n",
        "print(f\"IRBO médio entre tópicos: {round(irbo_score, 4)}\")\n",
        "\n",
        "df_topicos.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diversidade de Tópicos: 0.95\n",
            "IRBO médio entre tópicos: 0.7071\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tópico</th>\n",
              "      <th>Palavras</th>\n",
              "      <th>Pesos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>deus, senhor, jesus, nome, vida, cristo, porqu...</td>\n",
              "      <td>[0.037812601774930954, 0.024820925667881966, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>deus, todos, vamos, brasil, fe, acima, amor, f...</td>\n",
              "      <td>[0.06376680731773376, 0.017140470445156097, 0....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Tópico                                           Palavras  \\\n",
              "0       0  deus, senhor, jesus, nome, vida, cristo, porqu...   \n",
              "1       1  deus, todos, vamos, brasil, fe, acima, amor, f...   \n",
              "\n",
              "                                               Pesos  \n",
              "0  [0.037812601774930954, 0.024820925667881966, 0...  \n",
              "1  [0.06376680731773376, 0.017140470445156097, 0....  "
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Escolha da métrica\n",
        "chosen_metric = 'c_v'  # ou 'c_v', 'u_mass', 'c_uci'\n",
        "\n",
        "# Obter o melhor modelo treinado\n",
        "best_index = ptm_coherence_results[chosen_metric]['coherence_values'].index(\n",
        "    max(ptm_coherence_results[chosen_metric]['coherence_values'])\n",
        ")\n",
        "best_model = ptm_coherence_results[chosen_metric]['model_list'][best_index]\n",
        "\n",
        "# Gerar DataFrame com tópicos\n",
        "def get_topics_dataframe(model, top_n=10):\n",
        "    topics_data = []\n",
        "    for topic_id in range(model.k):\n",
        "        words_probs = model.get_topic_words(topic_id, top_n=top_n)\n",
        "        topic_words = [word for word, prob in words_probs]\n",
        "        topic_probs = [prob for word, prob in words_probs]\n",
        "        topics_data.append({\n",
        "            'Tópico': topic_id,\n",
        "            'Palavras': ', '.join(topic_words),\n",
        "            'Pesos': topic_probs\n",
        "        })\n",
        "    return pd.DataFrame(topics_data)\n",
        "\n",
        "df_topicos = get_topics_dataframe(best_model)\n",
        "\n",
        "df_topicos.to_csv('./resultados_pseudo/wpp/pseudo_wpp_politico_c_v.csv', index=False)\n",
        "\n",
        "div = topic_diversity(best_model)\n",
        "print(f\"Diversidade de Tópicos: {round(div, 4)}\")\n",
        "\n",
        "irbo_score = compute_irbo_ptm(best_model)\n",
        "print(f\"IRBO médio entre tópicos: {round(irbo_score, 4)}\")\n",
        "\n",
        "df_topicos.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diversidade de Tópicos: 0.95\n",
            "IRBO médio entre tópicos: 0.7071\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tópico</th>\n",
              "      <th>Palavras</th>\n",
              "      <th>Pesos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>deus, senhor, jesus, nome, vida, cristo, porqu...</td>\n",
              "      <td>[0.037812601774930954, 0.024820925667881966, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>deus, todos, vamos, brasil, fe, acima, amor, f...</td>\n",
              "      <td>[0.06376680731773376, 0.017140470445156097, 0....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Tópico                                           Palavras  \\\n",
              "0       0  deus, senhor, jesus, nome, vida, cristo, porqu...   \n",
              "1       1  deus, todos, vamos, brasil, fe, acima, amor, f...   \n",
              "\n",
              "                                               Pesos  \n",
              "0  [0.037812601774930954, 0.024820925667881966, 0...  \n",
              "1  [0.06376680731773376, 0.017140470445156097, 0....  "
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Escolha da métrica\n",
        "chosen_metric = 'u_mass'  # ou 'c_v', 'u_mass', 'c_uci'\n",
        "\n",
        "# Obter o melhor modelo treinado\n",
        "best_index = ptm_coherence_results[chosen_metric]['coherence_values'].index(\n",
        "    max(ptm_coherence_results[chosen_metric]['coherence_values'])\n",
        ")\n",
        "best_model = ptm_coherence_results[chosen_metric]['model_list'][best_index]\n",
        "\n",
        "# Gerar DataFrame com tópicos\n",
        "def get_topics_dataframe(model, top_n=10):\n",
        "    topics_data = []\n",
        "    for topic_id in range(model.k):\n",
        "        words_probs = model.get_topic_words(topic_id, top_n=top_n)\n",
        "        topic_words = [word for word, prob in words_probs]\n",
        "        topic_probs = [prob for word, prob in words_probs]\n",
        "        topics_data.append({\n",
        "            'Tópico': topic_id,\n",
        "            'Palavras': ', '.join(topic_words),\n",
        "            'Pesos': topic_probs\n",
        "        })\n",
        "    return pd.DataFrame(topics_data)\n",
        "\n",
        "df_topicos = get_topics_dataframe(best_model)\n",
        "\n",
        "df_topicos.to_csv('./resultados_pseudo/wpp/pseudo_wpp_politico_u_mass.csv', index=False)\n",
        "\n",
        "div = topic_diversity(best_model)\n",
        "print(f\"Diversidade de Tópicos: {round(div, 4)}\")\n",
        "\n",
        "irbo_score = compute_irbo_ptm(best_model)\n",
        "print(f\"IRBO médio entre tópicos: {round(irbo_score, 4)}\")\n",
        "\n",
        "df_topicos.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diversidade de Tópicos: 0.95\n",
            "IRBO médio entre tópicos: 0.7071\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tópico</th>\n",
              "      <th>Palavras</th>\n",
              "      <th>Pesos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>deus, senhor, jesus, nome, vida, cristo, porqu...</td>\n",
              "      <td>[0.037812601774930954, 0.024820925667881966, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>deus, todos, vamos, brasil, fe, acima, amor, f...</td>\n",
              "      <td>[0.06376680731773376, 0.017140470445156097, 0....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Tópico                                           Palavras  \\\n",
              "0       0  deus, senhor, jesus, nome, vida, cristo, porqu...   \n",
              "1       1  deus, todos, vamos, brasil, fe, acima, amor, f...   \n",
              "\n",
              "                                               Pesos  \n",
              "0  [0.037812601774930954, 0.024820925667881966, 0...  \n",
              "1  [0.06376680731773376, 0.017140470445156097, 0....  "
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Escolha da métrica\n",
        "chosen_metric = 'c_uci'  # ou 'c_v', 'u_mass', 'c_uci'\n",
        "\n",
        "# Obter o melhor modelo treinado\n",
        "best_index = ptm_coherence_results[chosen_metric]['coherence_values'].index(\n",
        "    max(ptm_coherence_results[chosen_metric]['coherence_values'])\n",
        ")\n",
        "best_model = ptm_coherence_results[chosen_metric]['model_list'][best_index]\n",
        "\n",
        "# Gerar DataFrame com tópicos\n",
        "def get_topics_dataframe(model, top_n=10):\n",
        "    topics_data = []\n",
        "    for topic_id in range(model.k):\n",
        "        words_probs = model.get_topic_words(topic_id, top_n=top_n)\n",
        "        topic_words = [word for word, prob in words_probs]\n",
        "        topic_probs = [prob for word, prob in words_probs]\n",
        "        topics_data.append({\n",
        "            'Tópico': topic_id,\n",
        "            'Palavras': ', '.join(topic_words),\n",
        "            'Pesos': topic_probs\n",
        "        })\n",
        "    return pd.DataFrame(topics_data)\n",
        "\n",
        "df_topicos = get_topics_dataframe(best_model)\n",
        "\n",
        "df_topicos.to_csv('./resultados_pseudo/wpp/pseudo_wpp_politico_c_uci.csv', index=False)\n",
        "\n",
        "div = topic_diversity(best_model)\n",
        "print(f\"Diversidade de Tópicos: {round(div, 4)}\")\n",
        "\n",
        "irbo_score = compute_irbo_ptm(best_model)\n",
        "print(f\"IRBO médio entre tópicos: {round(irbo_score, 4)}\")\n",
        "\n",
        "df_topicos.head(10)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "topics_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
